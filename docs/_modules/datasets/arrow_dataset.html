
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>datasets.arrow_dataset &#8212; Datasets 4.4.2.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=564b2b0d" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=62d5458c"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=fd10adb8"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/datasets/arrow_dataset';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="4.4.2.dev0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">ðŸ¤— Datasets</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../howto.html">
    How-to Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../concepts.html">
    Conceptual Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/huggingface/datasets" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://huggingface.co/datasets" title="Hugging Face" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Hugging Face</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../howto.html">
    How-to Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../concepts.html">
    Conceptual Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/huggingface/datasets" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://huggingface.co/datasets" title="Hugging Face" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Hugging Face</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">datasets.arrow_dataset</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for datasets.arrow_dataset</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020 The HuggingFace Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="c1"># Lint as: python3</span>
<span class="sd">&quot;&quot;&quot;Simple Dataset wrapping an Arrow Table.&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">fnmatch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">glob</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">posixpath</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">string</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">weakref</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Mapping</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span> <span class="k">as</span> <span class="n">Sequence_</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span><span class="p">,</span> <span class="n">wraps</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">floor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">BinaryIO</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">overload</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">fsspec</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.compute</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fsspec.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">url_to_fs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CommitInfo</span><span class="p">,</span>
    <span class="n">CommitOperationAdd</span><span class="p">,</span>
    <span class="n">CommitOperationDelete</span><span class="p">,</span>
    <span class="n">DatasetCard</span><span class="p">,</span>
    <span class="n">DatasetCardData</span><span class="p">,</span>
    <span class="n">HfApi</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub.hf_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">RepoFile</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfHubHTTPError</span><span class="p">,</span> <span class="n">RepositoryNotFoundError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">multiprocess</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.contrib.concurrent</span><span class="w"> </span><span class="kn">import</span> <span class="n">thread_map</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.arrow_reader</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArrowReader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.arrow_writer</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArrowWriter</span><span class="p">,</span> <span class="n">OptimizedTypedSequence</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.data_files</span><span class="w"> </span><span class="kn">import</span> <span class="n">sanitize_patterns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.download.streaming_download_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">xgetsize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.features</span><span class="w"> </span><span class="kn">import</span> <span class="n">Audio</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">,</span> <span class="n">Features</span><span class="p">,</span> <span class="n">Image</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Value</span><span class="p">,</span> <span class="n">Video</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.features.features</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">FeatureType</span><span class="p">,</span>
    <span class="n">_align_features</span><span class="p">,</span>
    <span class="n">_check_if_features_can_be_aligned</span><span class="p">,</span>
    <span class="n">_fix_for_backward_compatible_features</span><span class="p">,</span>
    <span class="n">generate_from_arrow_type</span><span class="p">,</span>
    <span class="n">pandas_types_mapper</span><span class="p">,</span>
    <span class="n">require_decoding</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.filesystems</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_remote_filesystem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.fingerprint</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">fingerprint_transform</span><span class="p">,</span>
    <span class="n">format_kwargs_for_fingerprint</span><span class="p">,</span>
    <span class="n">format_transform_for_fingerprint</span><span class="p">,</span>
    <span class="n">generate_fingerprint</span><span class="p">,</span>
    <span class="n">generate_random_fingerprint</span><span class="p">,</span>
    <span class="n">get_temporary_cache_files_directory</span><span class="p">,</span>
    <span class="n">is_caching_enabled</span><span class="p">,</span>
    <span class="n">maybe_register_dataset_for_temp_dir_deletion</span><span class="p">,</span>
    <span class="n">update_fingerprint</span><span class="p">,</span>
    <span class="n">validate_fingerprint</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.formatting</span><span class="w"> </span><span class="kn">import</span> <span class="n">format_table</span><span class="p">,</span> <span class="n">get_format_type_from_alias</span><span class="p">,</span> <span class="n">get_formatter</span><span class="p">,</span> <span class="n">query_table</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.formatting.formatting</span><span class="w"> </span><span class="kn">import</span> <span class="n">LazyDict</span><span class="p">,</span> <span class="n">_is_range_contiguous</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.info</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetInfo</span><span class="p">,</span> <span class="n">DatasetInfosDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.naming</span><span class="w"> </span><span class="kn">import</span> <span class="n">_split_re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.search</span><span class="w"> </span><span class="kn">import</span> <span class="n">IndexableMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.splits</span><span class="w"> </span><span class="kn">import</span> <span class="n">NamedSplit</span><span class="p">,</span> <span class="n">Split</span><span class="p">,</span> <span class="n">SplitDict</span><span class="p">,</span> <span class="n">SplitInfo</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.table</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">InMemoryTable</span><span class="p">,</span>
    <span class="n">MemoryMappedTable</span><span class="p">,</span>
    <span class="n">Table</span><span class="p">,</span>
    <span class="n">_memory_mapped_record_batch_reader_from_file</span><span class="p">,</span>
    <span class="n">cast_array_to_feature</span><span class="p">,</span>
    <span class="n">concat_tables</span><span class="p">,</span>
    <span class="n">embed_table_storage</span><span class="p">,</span>
    <span class="n">list_table_cache_files</span><span class="p">,</span>
    <span class="n">table_cast</span><span class="p">,</span>
    <span class="n">table_iter</span><span class="p">,</span>
    <span class="n">table_visitor</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span> <span class="k">as</span> <span class="n">hf_tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.file_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">estimate_dataset_size</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.info_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_small_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.metadata</span><span class="w"> </span><span class="kn">import</span> <span class="n">MetadataConfigs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.py_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Literal</span><span class="p">,</span>
    <span class="n">asdict</span><span class="p">,</span>
    <span class="n">convert_file_size_to_int</span><span class="p">,</span>
    <span class="n">glob_pattern_to_regex</span><span class="p">,</span>
    <span class="n">iflatmap_unordered</span><span class="p">,</span>
    <span class="n">string_to_dict</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.stratify</span><span class="w"> </span><span class="kn">import</span> <span class="n">stratified_shuffle_split_generate_indices</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.tf_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataset_to_tf</span><span class="p">,</span> <span class="n">minimal_tf_collate_fn</span><span class="p">,</span> <span class="n">multiprocess_dataset_to_tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">ListLike</span><span class="p">,</span> <span class="n">PathLike</span>


<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sqlite3</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pyspark</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sqlalchemy</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">.dataset_dict</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetDict</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">.iterable_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">IterableDataset</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">PUSH_TO_HUB_WITHOUT_METADATA_CONFIGS_SPLIT_PATTERN_SHARDED</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;data/</span><span class="si">{split}</span><span class="s2">-[0-9][0-9][0-9][0-9][0-9]-of-[0-9][0-9][0-9][0-9][0-9]*.parquet&quot;</span>
<span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DatasetInfoMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This base class exposes some attributes of DatasetInfo</span>
<span class="sd">    at the base level of the Dataset for easy access.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">info</span><span class="p">:</span> <span class="n">DatasetInfo</span><span class="p">,</span> <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="n">info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_split</span> <span class="o">=</span> <span class="n">split</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;[`~datasets.DatasetInfo`] object containing all the metadata in the dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;[`~datasets.NamedSplit`] object corresponding to a named dataset split.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">builder_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">builder_name</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">citation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">citation</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">config_name</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dataset_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">dataset_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">description</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">description</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">download_checksums</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">download_checksums</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">download_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">download_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">features</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">homepage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">homepage</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">license</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">license</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">size_in_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">size_in_bytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">supervised_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">supervised_keys</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">version</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TensorflowDatasetMixin</span><span class="p">:</span>
    <span class="n">_TF_DATASET_REFS</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_output_signature</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">collate_fn_args</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">cols_to_retain</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_test_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Private method used by `to_tf_dataset()` to find the shapes and dtypes of samples from this dataset</span>
<span class="sd">           after being passed through the collate_fn. Tensorflow needs an exact signature for tf.numpy_function, so</span>
<span class="sd">           the only way to do this is to run test batches - the collator may add or rename columns, so we can&#39;t figure</span>
<span class="sd">           it out just by inspecting the dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (`Dataset`): Dataset to load samples from.</span>
<span class="sd">            collate_fn(`bool`): Shuffle the dataset order when loading. Recommended True for training, False for</span>
<span class="sd">                validation/evaluation.</span>
<span class="sd">            collate_fn(`Callable`): A function or callable object (such as a `DataCollator`) that will collate</span>
<span class="sd">                lists of samples into a batch.</span>
<span class="sd">            collate_fn_args (`Dict`): A `dict` of keyword arguments to be passed to the</span>
<span class="sd">                `collate_fn`.</span>
<span class="sd">            batch_size (`int`, optional): The size of batches loaded from the dataset. Used for shape inference.</span>
<span class="sd">                Can be None, which indicates that batch sizes can be variable.</span>
<span class="sd">            num_test_batches (`int`): The number of batches to load from the dataset for shape inference.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `dict`: Dict mapping column names to tf.Tensorspec objects</span>
<span class="sd">            `dict`: Dict mapping column names to np.dtype objects</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">TF_AVAILABLE</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Called a Tensorflow-specific function but Tensorflow is not installed.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unable to get the output signature because the dataset is empty.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">cols_to_retain</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cols_to_retain</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">cols_to_retain</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;label_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">]))</span>

        <span class="n">test_batches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test_batches</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)),</span> <span class="n">test_batch_size</span><span class="p">)</span>
            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">cols_to_retain</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">test_batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">cols_to_retain</span><span class="p">}</span>
            <span class="n">test_batch</span> <span class="o">=</span> <span class="p">[{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">test_batch_size</span><span class="p">)]</span>
            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">collate_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">,</span> <span class="o">**</span><span class="n">collate_fn_args</span><span class="p">)</span>
            <span class="n">test_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

        <span class="n">tf_columns_to_signatures</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">np_columns_to_dtypes</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">test_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">raw_arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_batches</span><span class="p">]</span>
            <span class="c1"># In case the collate_fn returns something strange</span>
            <span class="n">np_arrays</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">raw_arrays</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">np_arrays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">np_arrays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">np_arrays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">array</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">np_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">bool</span><span class="p">:</span>
                <span class="n">tf_dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span>
                <span class="n">np_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">np_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
                <span class="n">tf_dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
                <span class="n">np_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span>
            <span class="k">elif</span> <span class="n">np_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;U&quot;</span><span class="p">:</span>  <span class="c1"># Unicode strings</span>
                <span class="n">np_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">str_</span>
                <span class="n">tf_dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unrecognized array dtype </span><span class="si">{</span><span class="n">np_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">. </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;Nested types and image/audio types are not supported yet.&quot;</span>
                <span class="p">)</span>
            <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">np_arrays</span><span class="p">]</span>
            <span class="n">static_shape</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">static_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># This dimension looks constant</span>
                    <span class="n">static_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sizes</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># Use None for variable dimensions</span>
                    <span class="n">static_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">tf_columns_to_signatures</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">static_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="p">)</span>
            <span class="n">np_columns_to_dtypes</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">np_dtype</span>

        <span class="k">return</span> <span class="n">tf_columns_to_signatures</span><span class="p">,</span> <span class="n">np_columns_to_dtypes</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_tf_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_remainder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">collate_fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">label_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefetch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">num_test_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a `tf.data.Dataset` from the underlying Dataset. This `tf.data.Dataset` will load and collate batches from</span>
<span class="sd">        the Dataset, and is suitable for passing to methods like `model.fit()` or `model.predict()`. The dataset will yield</span>
<span class="sd">        `dicts` for both inputs and labels unless the `dict` would contain only a single key, in which case a raw</span>
<span class="sd">        `tf.Tensor` is yielded instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of batches to load from the dataset. Defaults to `None`, which implies that the dataset won&#39;t be</span>
<span class="sd">                batched, but the returned dataset can be batched later with `tf_dataset.batch(batch_size)`.</span>
<span class="sd">            columns (`List[str]` or `str`, *optional*):</span>
<span class="sd">                Dataset column(s) to load in the `tf.data.Dataset`.</span>
<span class="sd">                Column names that are created by the `collate_fn` and that do not exist in the original dataset can be used.</span>
<span class="sd">            shuffle(`bool`, defaults to `False`):</span>
<span class="sd">                Shuffle the dataset order when loading. Recommended `True` for training, `False` for</span>
<span class="sd">                validation/evaluation.</span>
<span class="sd">            drop_remainder(`bool`, defaults to `False`):</span>
<span class="sd">                Drop the last incomplete batch when loading. Ensures</span>
<span class="sd">                that all batches yielded by the dataset will have the same length on the batch dimension.</span>
<span class="sd">            collate_fn(`Callable`, *optional*):</span>
<span class="sd">                A function or callable object (such as a `DataCollator`) that will collate</span>
<span class="sd">                lists of samples into a batch.</span>
<span class="sd">            collate_fn_args (`Dict`, *optional*):</span>
<span class="sd">                An optional `dict` of keyword arguments to be passed to the</span>
<span class="sd">                `collate_fn`.</span>
<span class="sd">            label_cols (`List[str]` or `str`, defaults to `None`):</span>
<span class="sd">                Dataset column(s) to load as labels.</span>
<span class="sd">                Note that many models compute loss internally rather than letting Keras do it, in which case</span>
<span class="sd">                passing the labels here is optional, as long as they&#39;re in the input `columns`.</span>
<span class="sd">            prefetch (`bool`, defaults to `True`):</span>
<span class="sd">                Whether to run the dataloader in a separate thread and maintain</span>
<span class="sd">                a small buffer of batches for training. Improves performance by allowing data to be loaded in the</span>
<span class="sd">                background while the model is training.</span>
<span class="sd">            num_workers (`int`, defaults to `0`):</span>
<span class="sd">                Number of workers to use for loading the dataset.</span>
<span class="sd">            num_test_batches (`int`, defaults to `20`):</span>
<span class="sd">                Number of batches to use to infer the output signature of the dataset.</span>
<span class="sd">                The higher this number, the more accurate the signature will be, but the longer it will take to</span>
<span class="sd">                create the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `tf.data.Dataset`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds_train = ds[&quot;train&quot;].to_tf_dataset(</span>
<span class="sd">        ...    columns=[&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;, &#39;label&#39;],</span>
<span class="sd">        ...    shuffle=True,</span>
<span class="sd">        ...    batch_size=16,</span>
<span class="sd">        ...    collate_fn=data_collator,</span>
<span class="sd">        ... )</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">TF_AVAILABLE</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Called a Tensorflow-specific function but Tensorflow is not installed.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_cols</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The output of `to_tf_dataset` will change when a passing single element list for `labels` or &quot;</span>
                <span class="s2">&quot;`columns` in the next datasets version. To return a tuple structure rather than dict, pass a &quot;</span>
                <span class="s2">&quot;single string.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Old behaviour: columns=[&#39;a&#39;], labels=[&#39;labels&#39;] -&gt; (tf.Tensor, tf.Tensor)  </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;             : columns=&#39;a&#39;, labels=&#39;labels&#39; -&gt; (tf.Tensor, tf.Tensor)  </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;New behaviour: columns=[&#39;a&#39;],labels=[&#39;labels&#39;] -&gt; ({&#39;a&#39;: tf.Tensor}, {&#39;labels&#39;: tf.Tensor})  </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;             : columns=&#39;a&#39;, labels=&#39;labels&#39; -&gt; (tf.Tensor, tf.Tensor) &quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Note that to_tf_dataset() loads the data with a generator rather than a full tf.data &quot;</span>
                <span class="s2">&quot;pipeline and is not compatible with remote TPU connections. If you encounter errors, please &quot;</span>
                <span class="s2">&quot;try using a TPU VM or, if your data can fit in memory, loading it into memory as a dict of &quot;</span>
                <span class="s2">&quot;Tensors instead of streaming with to_tf_dataset().&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">collate_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Set a very simple default collator that just stacks things together</span>
            <span class="n">collate_fn</span> <span class="o">=</span> <span class="n">minimal_tf_collate_fn</span>
        <span class="k">if</span> <span class="n">collate_fn_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">collate_fn_args</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">label_cols</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot specify label_cols without specifying columns!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">label_cols</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">label_cols</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_cols</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">label_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">label_cols</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">label_cols</span><span class="p">))</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_cols</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;List of label_cols contains duplicates.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">columns</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">columns</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">columns</span><span class="p">))</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;List of columns contains duplicates.&quot;</span><span class="p">)</span>
            <span class="n">cols_to_retain</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">columns</span> <span class="o">+</span> <span class="n">label_cols</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cols_to_retain</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Indicates keeping all valid columns</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">format</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;custom&quot;</span><span class="p">,</span> <span class="s2">&quot;numpy&quot;</span><span class="p">]:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;numpy&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="c1"># TODO(Matt, QL): deprecate the retention of label_ids and label</span>

        <span class="n">output_signature</span><span class="p">,</span> <span class="n">columns_to_np_types</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_get_output_signature</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">collate_fn_args</span><span class="o">=</span><span class="n">collate_fn_args</span><span class="p">,</span>
            <span class="n">cols_to_retain</span><span class="o">=</span><span class="n">cols_to_retain</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span> <span class="k">if</span> <span class="n">drop_remainder</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">num_test_batches</span><span class="o">=</span><span class="n">num_test_batches</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">in</span> <span class="n">output_signature</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;label_ids&quot;</span> <span class="ow">in</span> <span class="n">columns</span> <span class="ow">or</span> <span class="s2">&quot;label&quot;</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
                <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;label_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;label_ids&quot;</span> <span class="ow">in</span> <span class="n">label_cols</span> <span class="ow">or</span> <span class="s2">&quot;label&quot;</span> <span class="ow">in</span> <span class="n">label_cols</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">label_cols</span><span class="p">:</span>
                <span class="n">label_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">label_cols</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;label_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_signature</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> not found in dataset!&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">label_cols</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_signature</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label column </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> not found in dataset!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_workers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">dataset_to_tf</span><span class="p">(</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">cols_to_retain</span><span class="o">=</span><span class="n">cols_to_retain</span><span class="p">,</span>
                <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
                <span class="n">collate_fn_args</span><span class="o">=</span><span class="n">collate_fn_args</span><span class="p">,</span>
                <span class="n">columns_to_np_types</span><span class="o">=</span><span class="n">columns_to_np_types</span><span class="p">,</span>
                <span class="n">output_signature</span><span class="o">=</span><span class="n">output_signature</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">drop_remainder</span><span class="o">=</span><span class="n">drop_remainder</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">num_workers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;`batch_size` must be specified when using multiple workers, as unbatched multiprocessing &quot;</span>
                    <span class="s2">&quot;is not supported yet. Please provide a `batch_size` if `num_workers` is greater than 0.&quot;</span>
                <span class="p">)</span>
            <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">multiprocess_dataset_to_tf</span><span class="p">(</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">cols_to_retain</span><span class="o">=</span><span class="n">cols_to_retain</span><span class="p">,</span>
                <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
                <span class="n">collate_fn_args</span><span class="o">=</span><span class="n">collate_fn_args</span><span class="p">,</span>
                <span class="n">columns_to_np_types</span><span class="o">=</span><span class="n">columns_to_np_types</span><span class="p">,</span>
                <span class="n">output_signature</span><span class="o">=</span><span class="n">output_signature</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">drop_remainder</span><span class="o">=</span><span class="n">drop_remainder</span><span class="p">,</span>
                <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_workers must be &gt;= 0&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">split_features_and_labels</span><span class="p">(</span><span class="n">input_batch</span><span class="p">):</span>
            <span class="c1"># TODO(Matt, QL): deprecate returning the dict content when there&#39;s only one key</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">tensor</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">}</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">tensor</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">label_cols</span><span class="p">}</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">features</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>

        <span class="k">if</span> <span class="n">cols_to_retain</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">tf_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">split_features_and_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">prefetch</span><span class="p">:</span>
            <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">tf_dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

        <span class="c1"># Remove a reference to the open Arrow file on delete</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">cleanup_callback</span><span class="p">(</span><span class="n">ref</span><span class="p">):</span>
            <span class="n">dataset</span><span class="o">.</span><span class="fm">__del__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_TF_DATASET_REFS</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_TF_DATASET_REFS</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">tf_dataset</span><span class="p">,</span> <span class="n">cleanup_callback</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">tf_dataset</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DatasetTransformationNotAllowedError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="k">def</span><span class="w"> </span><span class="nf">transmit_format</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for dataset transforms that recreate a new Dataset to transmit the format of the original dataset to the new dataset&quot;&quot;&quot;</span>

    <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">args</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;self&quot;</span><span class="p">)</span>
        <span class="c1"># don&#39;t use self.format since it returns a list of columns for &#39;columns&#39; even if self_format_columns is None</span>
        <span class="n">unformatted_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">or</span> <span class="p">[])</span>
        <span class="n">self_format</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span>
            <span class="s2">&quot;format_kwargs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="p">,</span>
            <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">,</span>
            <span class="s2">&quot;output_all_columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c1"># apply actual function</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;DatasetDict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">datasets</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">out</span><span class="p">]</span>
        <span class="c1"># re-apply format to the output</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
            <span class="n">new_format</span> <span class="o">=</span> <span class="n">self_format</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">new_format</span><span class="p">[</span><span class="s2">&quot;columns&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># new formatted columns = (columns - previously unformatted columns)</span>
                <span class="c1"># sort the columns to have a deterministic list of columns that we can compare with `out_format`</span>
                <span class="n">new_format</span><span class="p">[</span><span class="s2">&quot;columns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="n">unformatted_columns</span><span class="p">)</span>
            <span class="n">out_format</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span>
                <span class="s2">&quot;format_kwargs&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="p">,</span>
                <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">)</span> <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;output_all_columns&quot;</span><span class="p">:</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">out_format</span> <span class="o">!=</span> <span class="n">new_format</span><span class="p">:</span>
                <span class="n">fingerprint</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span>
                <span class="n">dataset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="o">**</span><span class="n">new_format</span><span class="p">)</span>
                <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">fingerprint</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="n">wrapper</span><span class="o">.</span><span class="n">_decorator_name_</span> <span class="o">=</span> <span class="s2">&quot;transmit_format&quot;</span>
    <span class="k">return</span> <span class="n">wrapper</span>


<span class="k">def</span><span class="w"> </span><span class="nf">update_metadata_with_features</span><span class="p">(</span><span class="n">table</span><span class="p">:</span> <span class="n">Table</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">Features</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;To be used in dataset transforms that modify the features of the dataset, in order to update the features stored in the metadata of its schema.&quot;&quot;&quot;</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">({</span><span class="n">col_name</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">table</span><span class="o">.</span><span class="n">column_names</span><span class="p">})</span>
    <span class="k">if</span> <span class="n">table</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="sa">b</span><span class="s2">&quot;huggingface&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">table</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
        <span class="n">pa_metadata</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="o">.</span><span class="n">_build_metadata</span><span class="p">(</span><span class="n">DatasetInfo</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="sa">b</span><span class="s2">&quot;huggingface&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">())</span>
        <span class="k">if</span> <span class="s2">&quot;info&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">:</span>
            <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="n">DatasetInfo</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;info&quot;</span><span class="p">][</span><span class="s2">&quot;features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="n">DatasetInfo</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">))[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span>
        <span class="n">pa_metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;huggingface&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">metadata</span><span class="p">)}</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">replace_schema_metadata</span><span class="p">(</span><span class="n">pa_metadata</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">table</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_table</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Table</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;We check the table type to make sure it&#39;s an instance of :class:`datasets.table.Table`&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
        <span class="c1"># for a pyarrow table, we can just consider it as a in-memory table</span>
        <span class="c1"># this is here for backward compatibility</span>
        <span class="k">return</span> <span class="n">InMemoryTable</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">Table</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">table</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected a pyarrow.Table or a datasets.table.Table object, but got </span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check the column names to make sure they don&#39;t contain duplicates.&quot;&quot;&quot;</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counter</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
        <span class="n">duplicated_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">counter</span> <span class="k">if</span> <span class="n">counter</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The table can&#39;t have duplicated columns but columns </span><span class="si">{</span><span class="n">duplicated_columns</span><span class="si">}</span><span class="s2"> are duplicated.&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_valid_indices_value</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">index</span> <span class="o">+</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">index</span> <span class="o">&gt;=</span> <span class="n">size</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> out of range for dataset of size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">NonExistentDatasetError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used when we expect the existence of a dataset&quot;&quot;&quot;</span>

    <span class="k">pass</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Column</span><span class="p">(</span><span class="n">Sequence_</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An iterable for a specific column of a [`Dataset`].</span>

<span class="sd">    Example:</span>

<span class="sd">    Iterate on the texts of the &quot;text&quot; column of a dataset:</span>

<span class="sd">    ```python</span>
<span class="sd">    for text in dataset[&quot;text&quot;]:</span>
<span class="sd">        ...</span>
<span class="sd">    ```</span>

<span class="sd">    It also works with nested columns:</span>

<span class="sd">    ```python</span>
<span class="sd">    for source in dataset[&quot;metadata&quot;][&quot;source&quot;]:</span>
<span class="sd">        ...</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;Column&quot;</span><span class="p">],</span> <span class="n">column_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">column_name</span> <span class="o">=</span> <span class="n">column_name</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="n">column_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">source</span><span class="o">.</span><span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2">&#39; doesn&#39;t exist.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">_format_type</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
                <span class="c1"># the formatting transform may require all columns</span>
                <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">_fast_select_column</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span>
        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">source</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">example</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">_format_type</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
                <span class="c1"># the formatting transform may require all columns</span>
                <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">_fast_select_column</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">source</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;Column(&quot;</span> <span class="o">+</span> <span class="nb">repr</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;, ...])&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="k">else</span> <span class="s2">&quot;])&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;Column(&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;, ...])&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="k">else</span> <span class="s2">&quot;])&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Column</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<div class="viewcode-block" id="Dataset">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Dataset</span><span class="p">(</span><span class="n">DatasetInfoMixin</span><span class="p">,</span> <span class="n">IndexableMixin</span><span class="p">,</span> <span class="n">TensorflowDatasetMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Dataset backed by an Arrow table.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arrow_table</span><span class="p">:</span> <span class="n">Table</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_table</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Table</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">info</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DatasetInfo</span><span class="p">()</span>
        <span class="n">DatasetInfoMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
        <span class="n">IndexableMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">:</span> <span class="n">Table</span> <span class="o">=</span> <span class="n">_check_table</span><span class="p">(</span><span class="n">arrow_table</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Table</span><span class="p">]</span> <span class="o">=</span> <span class="n">_check_table</span><span class="p">(</span><span class="n">indices_table</span><span class="p">)</span> <span class="k">if</span> <span class="n">indices_table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">maybe_register_dataset_for_temp_dir_deletion</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">fingerprint</span>

        <span class="c1"># Read metadata</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="sa">b</span><span class="s2">&quot;huggingface&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="sa">b</span><span class="s2">&quot;huggingface&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">())</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;fingerprint&quot;</span> <span class="ow">in</span> <span class="n">metadata</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="p">):</span>  <span class="c1"># try to load fingerprint from the arrow file metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;fingerprint&quot;</span><span class="p">]</span>

        <span class="c1"># Infer features if None</span>
        <span class="n">inferred_features</span> <span class="o">=</span> <span class="n">Features</span><span class="o">.</span><span class="n">from_arrow_schema</span><span class="p">(</span><span class="n">arrow_table</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">inferred_features</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># make sure the nested columns are in the right order</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">reorder_fields_as</span><span class="p">(</span><span class="n">inferred_features</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s2">The &#39;source&#39; features come from dataset_info.json, and the &#39;target&#39; ones are those of the dataset arrow file.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># In case there are types like pa.dictionary that we need to convert to the underlying type</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">schema</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">)</span>

        <span class="c1"># Infer fingerprint if None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">generate_fingerprint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Sanity checks</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Features can&#39;t be None in a Dataset object&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fingerprint can&#39;t be None in a Dataset object&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="n">inferred_features</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;External features info don&#39;t match the dataset:</span><span class="se">\n</span><span class="s2">Got</span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="se">\n</span><span class="s2">with type</span><span class="se">\n</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">but expected something like</span><span class="se">\n</span><span class="si">{</span><span class="n">inferred_features</span><span class="si">}</span><span class="se">\n</span><span class="s2">with type</span><span class="se">\n</span><span class="si">{</span><span class="n">inferred_features</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">pa</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_unsigned_integer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;indices must be an Arrow table of unsigned integers, current type is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="n">_check_column_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">features</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Features</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">features</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># this is already checked in __init__</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Features can&#39;t be None in a Dataset object&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">features</span>

<div class="viewcode-block" id="Dataset.from_file">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.from_file.html#datasets.Dataset.from_file">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_file</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_filename</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a Dataset backed by an Arrow table at filename.</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (`str`):</span>
<span class="sd">                File name of the dataset.</span>
<span class="sd">            info (`DatasetInfo`, *optional*):</span>
<span class="sd">                Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Name of the dataset split.</span>
<span class="sd">            indices_filename (`str`, *optional*):</span>
<span class="sd">                File names of the indices.</span>
<span class="sd">            in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">ArrowReader</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="n">in_memory</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">indices_filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">indices_pa_table</span> <span class="o">=</span> <span class="n">ArrowReader</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">indices_filename</span><span class="p">,</span> <span class="n">in_memory</span><span class="o">=</span><span class="n">in_memory</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices_pa_table</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">arrow_table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span>
            <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">indices_table</span><span class="o">=</span><span class="n">indices_pa_table</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_buffer">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.from_buffer.html#datasets.Dataset.from_buffer">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_buffer</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">buffer</span><span class="p">:</span> <span class="n">pa</span><span class="o">.</span><span class="n">Buffer</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_buffer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pa</span><span class="o">.</span><span class="n">Buffer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a Dataset backed by an Arrow buffer.</span>

<span class="sd">        Args:</span>
<span class="sd">            buffer (`pyarrow.Buffer`):</span>
<span class="sd">                Arrow buffer.</span>
<span class="sd">            info (`DatasetInfo`, *optional*):</span>
<span class="sd">                Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Name of the dataset split.</span>
<span class="sd">            indices_buffer (`pyarrow.Buffer`, *optional*):</span>
<span class="sd">                Indices Arrow buffer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_buffer</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">indices_buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_buffer</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span> <span class="n">indices_table</span><span class="o">=</span><span class="n">indices_table</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_pandas">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.from_pandas.html#datasets.Dataset.from_pandas">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_pandas</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">preserve_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert `pandas.DataFrame` to a `pyarrow.Table` to create a [`Dataset`].</span>

<span class="sd">        The column types in the resulting Arrow Table are inferred from the dtypes of the `pandas.Series` in the</span>
<span class="sd">        DataFrame. In the case of non-object Series, the NumPy dtype is translated to its Arrow equivalent. In the</span>
<span class="sd">        case of `object`, we need to guess the datatype by looking at the Python objects in this Series.</span>

<span class="sd">        Be aware that Series of the `object` dtype don&#39;t carry enough information to always lead to a meaningful Arrow</span>
<span class="sd">        type. In the case that we cannot infer a type, e.g. because the DataFrame is of length 0 or the Series only</span>
<span class="sd">        contains `None/nan` objects, the type is set to `null`. This behavior can be avoided by constructing explicit</span>
<span class="sd">        features and passing it to this function.</span>

<span class="sd">        Important: a dataset created with from_pandas() lives in memory</span>
<span class="sd">        and therefore doesn&#39;t have an associated cache directory.</span>
<span class="sd">        This may change in the future, but in the meantime if you</span>
<span class="sd">        want to reduce memory usage you should write it back on disk</span>
<span class="sd">        and reload using e.g. save_to_disk / load_from_disk.</span>

<span class="sd">        Args:</span>
<span class="sd">            df (`pandas.DataFrame`):</span>
<span class="sd">                Dataframe that contains the dataset.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            info (`DatasetInfo`, *optional*):</span>
<span class="sd">                Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Name of the dataset split.</span>
<span class="sd">            preserve_index (`bool`, *optional*):</span>
<span class="sd">                Whether to store the index as an additional column in the resulting Dataset.</span>
<span class="sd">                The default of `None` will store the index as a column, except for `RangeIndex` which is stored as metadata only.</span>
<span class="sd">                Use `preserve_index=True` to force it to be stored as a column.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_pandas(df)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">!=</span> <span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Features specified in `features` and `info.features` can&#39;t be different:</span><span class="se">\n</span><span class="si">{</span><span class="n">features</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">features</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="p">()</span>
        <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span>
            <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">preserve_index</span><span class="o">=</span><span class="n">preserve_index</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)</span>
            <span class="c1"># needed to support the str to Audio conversion for instance</span>
            <span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_polars">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_polars">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_polars</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">df</span><span class="p">:</span> <span class="s2">&quot;pl.DataFrame&quot;</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Collect the underlying arrow arrays in an Arrow Table.</span>

<span class="sd">        This operation is mostly zero copy.</span>

<span class="sd">        Data types that do copy:</span>
<span class="sd">            * CategoricalType</span>

<span class="sd">        Args:</span>
<span class="sd">            df (`polars.DataFrame`): DataFrame to convert to Arrow Table</span>
<span class="sd">            features (`Features`, optional): Dataset features.</span>
<span class="sd">            info (`DatasetInfo`, optional): Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, optional): Name of the dataset split.</span>

<span class="sd">        Examples:</span>
<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_polars(df)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">!=</span> <span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Features specified in `features` and `info.features` can&#39;t be different:</span><span class="se">\n</span><span class="si">{</span><span class="n">features</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">features</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="p">()</span>
        <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># more expensive cast than InMemoryTable.from_polars(..., schema=features.arrow_schema)</span>
            <span class="c1"># needed to support the str to Audio conversion for instance</span>
            <span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_dict">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.from_dict.html#datasets.Dataset.from_dict">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_dict</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert `dict` to a `pyarrow.Table` to create a [`Dataset`].</span>

<span class="sd">        Important: a dataset created with from_dict() lives in memory</span>
<span class="sd">        and therefore doesn&#39;t have an associated cache directory.</span>
<span class="sd">        This may change in the future, but in the meantime if you</span>
<span class="sd">        want to reduce memory usage you should write it back on disk</span>
<span class="sd">        and reload using e.g. save_to_disk / load_from_disk.</span>

<span class="sd">        Args:</span>
<span class="sd">            mapping (`Mapping`):</span>
<span class="sd">                Mapping of strings to Arrays or Python lists.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            info (`DatasetInfo`, *optional*):</span>
<span class="sd">                Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Name of the dataset split.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">!=</span> <span class="n">features</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Features specified in `features` and `info.features` can&#39;t be different:</span><span class="se">\n</span><span class="si">{</span><span class="n">features</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">features</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">arrow_typed_mapping</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">ChunkedArray</span><span class="p">)):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">cast_array_to_feature</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">OptimizedTypedSequence</span><span class="p">(</span>
                    <span class="n">features</span><span class="o">.</span><span class="n">encode_column</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="p">,</span>
                    <span class="nb">type</span><span class="o">=</span><span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">col</span><span class="o">=</span><span class="n">col</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">arrow_typed_mapping</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="n">arrow_typed_mapping</span>
        <span class="n">pa_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">(</span><span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="p">()</span>
        <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="k">if</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">col</span><span class="p">:</span> <span class="n">generate_from_arrow_type</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">ChunkedArray</span><span class="p">))</span>
                    <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">get_inferred_type</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">pa_table</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_list">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_list">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_list</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">mapping</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.</span>

<span class="sd">        Note that the keys of the first entry will be used to determine the dataset columns,</span>
<span class="sd">        regardless of what is passed to features.</span>

<span class="sd">        Important: a dataset created with from_list() lives in memory</span>
<span class="sd">        and therefore doesn&#39;t have an associated cache directory.</span>
<span class="sd">        This may change in the future, but in the meantime if you</span>
<span class="sd">        want to reduce memory usage you should write it back on disk</span>
<span class="sd">        and reload using e.g. save_to_disk / load_from_disk.</span>

<span class="sd">        Args:</span>
<span class="sd">            mapping (`List[dict]`): A list of mappings of strings to row values.</span>
<span class="sd">            features (`Features`, optional): Dataset features.</span>
<span class="sd">            info (`DatasetInfo`, optional): Dataset information, like description, citation, etc.</span>
<span class="sd">            split (`NamedSplit`, optional): Name of the dataset split.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span> <span class="k">if</span> <span class="n">mapping</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">mapping</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.from_csv">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_csv">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_csv</span><span class="p">(</span>
        <span class="n">path_or_paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">PathLike</span><span class="p">]],</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create Dataset from CSV file(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_paths (`path-like` or list of `path-like`):</span>
<span class="sd">                Path(s) of the CSV file(s).</span>
<span class="sd">            split ([`NamedSplit`], *optional*):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                This is helpful if the dataset is made of multiple files. Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to [`pandas.read_csv`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_csv(&#39;path/to/dataset.csv&#39;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.csv</span><span class="w"> </span><span class="kn">import</span> <span class="n">CsvDatasetReader</span>

        <span class="k">return</span> <span class="n">CsvDatasetReader</span><span class="p">(</span>
            <span class="n">path_or_paths</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_generator">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.from_generator.html#datasets.Dataset.from_generator">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_generator</span><span class="p">(</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">gen_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">NamedSplit</span> <span class="o">=</span> <span class="n">Split</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span>
        <span class="n">fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a Dataset from a generator.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator (:`Callable`):</span>
<span class="sd">                A generator function that `yields` examples.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            gen_kwargs(`dict`, *optional*):</span>
<span class="sd">                Keyword arguments to be passed to the `generator` callable.</span>
<span class="sd">                You can define a sharded dataset by passing the list of shards in `gen_kwargs` and setting `num_proc` greater than 1.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                This is helpful if the dataset is made of multiple files. Multiprocessing is disabled by default.</span>
<span class="sd">                If `num_proc` is greater than one, then all list values in `gen_kwargs` must be the same length. These values will be split between calls to the generator. The number of shards will be the minimum of the shortest list in `gen_kwargs` and `num_proc`.</span>

<span class="sd">                &lt;Added version=&quot;2.7.0&quot;/&gt;</span>
<span class="sd">            split ([`NamedSplit`], defaults to `Split.TRAIN`):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>

<span class="sd">                &lt;Added version=&quot;2.21.0&quot;/&gt;</span>
<span class="sd">            fingerprint (`str`, *optional*):</span>
<span class="sd">                Fingerprint that will be used to generate dataset ID.</span>
<span class="sd">                By default `fingerprint` is generated by hashing the generator function and all the args which can be slow</span>
<span class="sd">                if it uses large objects like AI models.</span>

<span class="sd">                &lt;Added version=&quot;4.3.0&quot;/&gt;</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to :[`GeneratorConfig`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; def gen():</span>
<span class="sd">        ...     yield {&quot;text&quot;: &quot;Good&quot;, &quot;label&quot;: 0}</span>
<span class="sd">        ...     yield {&quot;text&quot;: &quot;Bad&quot;, &quot;label&quot;: 1}</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_generator(gen)</span>
<span class="sd">        ```</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; def gen(shards):</span>
<span class="sd">        ...     for shard in shards:</span>
<span class="sd">        ...         with open(shard) as f:</span>
<span class="sd">        ...             for line in f:</span>
<span class="sd">        ...                 yield {&quot;line&quot;: line}</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; shards = [f&quot;data{i}.txt&quot; for i in range(32)]</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_generator(gen, gen_kwargs={&quot;shards&quot;: shards})</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.generator</span><span class="w"> </span><span class="kn">import</span> <span class="n">GeneratorDatasetInputStream</span>

        <span class="k">return</span> <span class="n">GeneratorDatasetInputStream</span><span class="p">(</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">gen_kwargs</span><span class="o">=</span><span class="n">gen_kwargs</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">fingerprint</span><span class="o">=</span><span class="n">fingerprint</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_json">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_json">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_json</span><span class="p">(</span>
        <span class="n">path_or_paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">PathLike</span><span class="p">]],</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create Dataset from JSON or JSON Lines file(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_paths (`path-like` or list of `path-like`):</span>
<span class="sd">                Path(s) of the JSON or JSON Lines file(s).</span>
<span class="sd">            split ([`NamedSplit`], *optional*):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                 Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            field (`str`, *optional*):</span>
<span class="sd">                Field name of the JSON file where the dataset is contained in.</span>
<span class="sd">            num_proc (`int`, *optional* defaults to `None`):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                This is helpful if the dataset is made of multiple files. Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to [`JsonConfig`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_json(&#39;path/to/dataset.json&#39;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.json</span><span class="w"> </span><span class="kn">import</span> <span class="n">JsonDatasetReader</span>

        <span class="k">return</span> <span class="n">JsonDatasetReader</span><span class="p">(</span>
            <span class="n">path_or_paths</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">field</span><span class="o">=</span><span class="n">field</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_parquet">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_parquet">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_parquet</span><span class="p">(</span>
        <span class="n">path_or_paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">PathLike</span><span class="p">]],</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create Dataset from Parquet file(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_paths (`path-like` or list of `path-like`):</span>
<span class="sd">                Path(s) of the Parquet file(s).</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>
<span class="sd">            features (`Features`, *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            columns (`List[str]`, *optional*):</span>
<span class="sd">                If not `None`, only these columns will be read from the file.</span>
<span class="sd">                A column name may be a prefix of a nested field, e.g. &#39;a&#39; will select</span>
<span class="sd">                &#39;a.b&#39;, &#39;a.c&#39;, and &#39;a.d.e&#39;.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                This is helpful if the dataset is made of multiple files. Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to [`ParquetConfig`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_parquet(&#39;path/to/dataset.parquet&#39;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.parquet</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParquetDatasetReader</span>

        <span class="k">return</span> <span class="n">ParquetDatasetReader</span><span class="p">(</span>
            <span class="n">path_or_paths</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_text">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_text">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_text</span><span class="p">(</span>
        <span class="n">path_or_paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">PathLike</span><span class="p">]],</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create Dataset from text file(s).</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_paths (`path-like` or list of `path-like`):</span>
<span class="sd">                Path(s) of the text file(s).</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>
<span class="sd">            features (`Features`, *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                This is helpful if the dataset is made of multiple files. Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to [`TextConfig`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_text(&#39;path/to/dataset.txt&#39;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextDatasetReader</span>

        <span class="k">return</span> <span class="n">TextDatasetReader</span><span class="p">(</span>
            <span class="n">path_or_paths</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_spark">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_spark">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_spark</span><span class="p">(</span>
        <span class="n">df</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">working_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a Dataset from Spark DataFrame. Dataset downloading is distributed over Spark workers.</span>

<span class="sd">        Args:</span>
<span class="sd">            df (`pyspark.sql.DataFrame`):</span>
<span class="sd">                The DataFrame containing the desired data.</span>
<span class="sd">            split (`NamedSplit`, *optional*):</span>
<span class="sd">                Split name to be assigned to the dataset.</span>
<span class="sd">            features (`Features`, *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data. When using a multi-node Spark cluster, the cache_dir must be accessible to both</span>
<span class="sd">                workers and the driver.</span>
<span class="sd">            keep_in_memory (`bool`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            working_dir (`str`, *optional*)</span>
<span class="sd">                Intermediate directory for each Spark worker to write data to before moving it to `cache_dir`. Setting</span>
<span class="sd">                a non-NFS intermediate directory may improve performance.</span>
<span class="sd">            load_from_cache_file (`bool`):</span>
<span class="sd">                Whether to load the dataset from the cache if possible.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; df = spark.createDataFrame(</span>
<span class="sd">        &gt;&gt;&gt;     data=[[1, &quot;Elia&quot;], [2, &quot;Teo&quot;], [3, &quot;Fang&quot;]],</span>
<span class="sd">        &gt;&gt;&gt;     columns=[&quot;id&quot;, &quot;name&quot;],</span>
<span class="sd">        &gt;&gt;&gt; )</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_spark(df)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.spark</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkDatasetReader</span>

        <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;win32&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">OSError</span><span class="p">(</span><span class="s2">&quot;Dataset.from_spark is not currently supported on Windows&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">SparkDatasetReader</span><span class="p">(</span>
            <span class="n">df</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">streaming</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">working_dir</span><span class="o">=</span><span class="n">working_dir</span><span class="p">,</span>
            <span class="n">load_from_cache_file</span><span class="o">=</span><span class="n">load_from_cache_file</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.from_sql">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.from_sql">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_sql</span><span class="p">(</span>
        <span class="n">sql</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;sqlalchemy.sql.Selectable&quot;</span><span class="p">],</span>
        <span class="n">con</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;sqlalchemy.engine.Connection&quot;</span><span class="p">,</span> <span class="s2">&quot;sqlalchemy.engine.Engine&quot;</span><span class="p">,</span> <span class="s2">&quot;sqlite3.Connection&quot;</span><span class="p">],</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create Dataset from SQL query or database table.</span>

<span class="sd">        Args:</span>
<span class="sd">            sql (`str` or `sqlalchemy.sql.Selectable`):</span>
<span class="sd">                SQL query to be executed or a table name.</span>
<span class="sd">            con (`str` or `sqlite3.Connection` or `sqlalchemy.engine.Connection` or `sqlalchemy.engine.Connection`):</span>
<span class="sd">                A [URI string](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls) used to instantiate a database connection or a SQLite3/SQLAlchemy connection object.</span>
<span class="sd">            features ([`Features`], *optional*):</span>
<span class="sd">                Dataset features.</span>
<span class="sd">            cache_dir (`str`, *optional*, defaults to `&quot;~/.cache/huggingface/datasets&quot;`):</span>
<span class="sd">                Directory to cache data.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            **kwargs (additional keyword arguments):</span>
<span class="sd">                Keyword arguments to be passed to [`SqlConfig`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; # Fetch a database table</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_sql(&quot;test_data&quot;, &quot;postgres:///db_name&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # Execute a SQL query on the table</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_sql(&quot;SELECT sentence FROM test_data&quot;, &quot;postgres:///db_name&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # Use a Selectable object to specify the query</span>
<span class="sd">        &gt;&gt;&gt; from sqlalchemy import select, text</span>
<span class="sd">        &gt;&gt;&gt; stmt = select([text(&quot;sentence&quot;)]).select_from(text(&quot;test_data&quot;))</span>
<span class="sd">        &gt;&gt;&gt; ds = Dataset.from_sql(stmt, &quot;postgres:///db_name&quot;)</span>
<span class="sd">        ```</span>

<span class="sd">        &gt; [!TIP]</span>
<span class="sd">        &gt; The returned dataset can only be cached if `con` is specified as URI string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SqlDatasetReader</span>

        <span class="k">return</span> <span class="n">SqlDatasetReader</span><span class="p">(</span>
            <span class="n">sql</span><span class="p">,</span>
            <span class="n">con</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">maybe_register_dataset_for_temp_dir_deletion</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_data&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_indices&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
        <span class="c1"># Here `del` is used to del the pyarrow tables. This properly closes the files used for memory mapped tables</span>
        <span class="bp">self</span><span class="o">.</span><span class="fm">__del__</span><span class="p">()</span>

<div class="viewcode-block" id="Dataset.save_to_disk">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.save_to_disk.html#datasets.Dataset.save_to_disk">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_to_disk</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="n">PathLike</span><span class="p">,</span>
        <span class="n">max_shard_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_shards</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves a dataset to a dataset directory, or in a filesystem using any implementation of `fsspec.spec.AbstractFileSystem`.</span>

<span class="sd">        For [`Image`], [`Audio`] and [`Video`] data:</span>

<span class="sd">        All the Image(), Audio() and Video() data are stored in the arrow files.</span>
<span class="sd">        If you want to store paths or urls, please use the Value(&quot;string&quot;) type.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (`path-like`):</span>
<span class="sd">                Path (e.g. `dataset/train`) or remote URI (e.g. `s3://my-bucket/dataset/train`)</span>
<span class="sd">                of the dataset directory where the dataset will be saved to.</span>
<span class="sd">            max_shard_size (`int` or `str`, *optional*, defaults to `&quot;500MB&quot;`):</span>
<span class="sd">                The maximum size of the dataset shards to be saved to the filesystem. If expressed as a string, needs to be digits followed by a unit</span>
<span class="sd">                (like `&quot;50MB&quot;`).</span>
<span class="sd">            num_shards (`int`, *optional*):</span>
<span class="sd">                Number of shards to write. By default the number of shards depends on `max_shard_size` and `num_proc`.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            num_proc (`int`, *optional*):</span>
<span class="sd">                Number of processes when downloading and generating the dataset locally.</span>
<span class="sd">                Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            storage_options (`dict`, *optional*):</span>
<span class="sd">                Key/value pairs to be passed on to the file-system backend, if any.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.save_to_disk(&quot;path/to/dataset/directory&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.save_to_disk(&quot;path/to/dataset/directory&quot;, max_shard_size=&quot;1GB&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.save_to_disk(&quot;path/to/dataset/directory&quot;, num_shards=1024)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">max_shard_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_shards</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Failed to push_to_hub: please specify either max_shard_size or num_shards, but not both.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;please remove all the indexes using `dataset.drop_index` before saving a dataset&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_shards</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_nbytes</span><span class="p">()</span>
            <span class="n">max_shard_size</span> <span class="o">=</span> <span class="n">convert_file_size_to_int</span><span class="p">(</span><span class="n">max_shard_size</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">MAX_SHARD_SIZE</span><span class="p">)</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_nbytes</span> <span class="o">/</span> <span class="n">max_shard_size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">num_proc</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">fs</span><span class="p">:</span> <span class="n">fsspec</span><span class="o">.</span><span class="n">AbstractFileSystem</span>
        <span class="n">fs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">url_to_fs</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="n">storage_options</span> <span class="ow">or</span> <span class="p">{}))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_remote_filesystem</span><span class="p">(</span><span class="n">fs</span><span class="p">):</span>
            <span class="n">parent_cache_files_paths</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">Path</span><span class="p">(</span><span class="n">cache_filename</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span> <span class="k">for</span> <span class="n">cache_filename</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span>
            <span class="p">}</span>
            <span class="c1"># Check that the dataset doesn&#39;t overwrite itself. It can cause a permission error on Windows and a segfault on linux.</span>
            <span class="k">if</span> <span class="n">Path</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span> <span class="ow">in</span> <span class="n">parent_cache_files_paths</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">PermissionError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Tried to overwrite </span><span class="si">{</span><span class="n">Path</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="si">}</span><span class="s2"> but a dataset can&#39;t overwrite itself.&quot;</span>
                <span class="p">)</span>

        <span class="n">fs</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Get json serializable state</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">&quot;_fingerprint&quot;</span><span class="p">,</span>
                <span class="s2">&quot;_format_columns&quot;</span><span class="p">,</span>
                <span class="s2">&quot;_format_kwargs&quot;</span><span class="p">,</span>
                <span class="s2">&quot;_format_type&quot;</span><span class="p">,</span>
                <span class="s2">&quot;_output_all_columns&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">}</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_split&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_data_files&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;data-</span><span class="si">{</span><span class="n">shard_idx</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">-of-</span><span class="si">{</span><span class="n">num_shards</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">.arrow&quot;</span><span class="p">}</span> <span class="k">for</span> <span class="n">shard_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_format_kwargs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_format_kwargs&quot;</span><span class="p">][</span><span class="n">k</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The format kwargs must be JSON serializable, but key &#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&#39; isn&#39;t.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="kc">None</span>
        <span class="c1"># Get json serializable dataset info</span>
        <span class="n">dataset_info</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="p">)</span>

        <span class="n">shards_done</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">hf_tqdm</span><span class="p">(</span>
            <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; examples&quot;</span><span class="p">,</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Saving the dataset (</span><span class="si">{</span><span class="n">shards_done</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards)&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">kwargs_per_job</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;job_id&quot;</span><span class="p">:</span> <span class="n">shard_idx</span><span class="p">,</span>
                <span class="s2">&quot;shard&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">shard_idx</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="s2">&quot;fpath&quot;</span><span class="p">:</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;data-</span><span class="si">{</span><span class="n">shard_idx</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">-of-</span><span class="si">{</span><span class="n">num_shards</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">.arrow&quot;</span><span class="p">),</span>
                <span class="s2">&quot;storage_options&quot;</span><span class="p">:</span> <span class="n">storage_options</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">shard_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">shard_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_shards</span>
        <span class="n">shard_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_shards</span>
        <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">num_proc</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">pbar</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">iflatmap_unordered</span><span class="p">(</span>
                        <span class="n">pool</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_save_to_disk_single</span><span class="p">,</span> <span class="n">kwargs_iterable</span><span class="o">=</span><span class="n">kwargs_per_job</span>
                    <span class="p">):</span>
                        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                            <span class="n">shards_done</span> <span class="o">+=</span> <span class="mi">1</span>
                            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving the dataset (</span><span class="si">{</span><span class="n">shards_done</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards)&quot;</span><span class="p">)</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished writing shard number </span><span class="si">{</span><span class="n">job_id</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                            <span class="n">shard_lengths</span><span class="p">[</span><span class="n">job_id</span><span class="p">],</span> <span class="n">shard_sizes</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">content</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">pbar</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="n">kwargs_per_job</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_save_to_disk_single</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                            <span class="n">shards_done</span> <span class="o">+=</span> <span class="mi">1</span>
                            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving the dataset (</span><span class="si">{</span><span class="n">shards_done</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards)&quot;</span><span class="p">)</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished writing shard number </span><span class="si">{</span><span class="n">job_id</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                            <span class="n">shard_lengths</span><span class="p">[</span><span class="n">job_id</span><span class="p">],</span> <span class="n">shard_sizes</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">content</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">fs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
            <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_STATE_JSON_FILENAME</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">state_file</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">state_file</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">fs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
            <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_INFO_FILENAME</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">dataset_info_file</span><span class="p">:</span>
            <span class="c1"># Sort only the first level of keys, or we might shuffle fields of nested features if we use sort_keys=True</span>
            <span class="n">sorted_keys_dataset_info</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">dataset_info</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataset_info</span><span class="p">)}</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">sorted_keys_dataset_info</span><span class="p">,</span> <span class="n">dataset_info_file</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></div>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_save_to_disk_single</span><span class="p">(</span><span class="n">job_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shard</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="n">fpath</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">DEFAULT_MAX_BATCH_SIZE</span>

        <span class="n">num_examples_progress_update</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">writer</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">shard</span><span class="o">.</span><span class="n">features</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">fpath</span><span class="p">,</span>
            <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span>
            <span class="n">embed_local_files</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">pa_table</span> <span class="ow">in</span> <span class="n">shard</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">pa_table</span><span class="p">)</span>
                <span class="n">num_examples_progress_update</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pa_table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">_time</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">PBAR_REFRESH_TIME_INTERVAL</span><span class="p">:</span>
                    <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="k">yield</span> <span class="n">job_id</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
                    <span class="n">num_examples_progress_update</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">job_id</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
            <span class="n">num_examples</span><span class="p">,</span> <span class="n">num_bytes</span> <span class="o">=</span> <span class="n">writer</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">yield</span> <span class="n">job_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">num_bytes</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_local_temp_path</span><span class="p">(</span><span class="n">uri_or_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds and returns a Path concatenating a local temporary dir with the dir path (or absolute/relative</span>
<span class="sd">        path extracted from the uri) passed.</span>

<span class="sd">        Args:</span>
<span class="sd">            uri_or_path (`str`): Path (e.g. `&quot;dataset/train&quot;`) or remote URI (e.g.</span>
<span class="sd">                `&quot;s3://my-bucket/dataset/train&quot;`) to concatenate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :class:`Path`: the concatenated path (temp dir + path)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">src_dataset_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">uri_or_path</span><span class="p">)</span>
        <span class="n">tmp_dir</span> <span class="o">=</span> <span class="n">get_temporary_cache_files_directory</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Path</span><span class="p">(</span><span class="n">tmp_dir</span><span class="p">,</span> <span class="n">src_dataset_path</span><span class="o">.</span><span class="n">relative_to</span><span class="p">(</span><span class="n">src_dataset_path</span><span class="o">.</span><span class="n">anchor</span><span class="p">))</span>

<div class="viewcode-block" id="Dataset.load_from_disk">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.load_from_disk.html#datasets.Dataset.load_from_disk">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_from_disk</span><span class="p">(</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="n">PathLike</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads a dataset that was previously saved using [`save_to_disk`] from a dataset directory, or from a</span>
<span class="sd">        filesystem using any implementation of `fsspec.spec.AbstractFileSystem`.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (`path-like`):</span>
<span class="sd">                Path (e.g. `&quot;dataset/train&quot;`) or remote URI (e.g. `&quot;s3//my-bucket/dataset/train&quot;`)</span>
<span class="sd">                of the dataset directory where the dataset will be loaded from.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `None`):</span>
<span class="sd">                Whether to copy the dataset in-memory. If `None`, the</span>
<span class="sd">                dataset will not be copied in-memory unless explicitly enabled by setting</span>
<span class="sd">                `datasets.config.IN_MEMORY_MAX_SIZE` to nonzero. See more details in the</span>
<span class="sd">                [improve performance](../cache#improve-performance) section.</span>
<span class="sd">            storage_options (`dict`, *optional*):</span>
<span class="sd">                Key/value pairs to be passed on to the file-system backend, if any.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`] or [`DatasetDict`]:</span>
<span class="sd">            - If `dataset_path` is a path of a dataset directory, the dataset requested.</span>
<span class="sd">            - If `dataset_path` is a path of a dataset dict directory, a `datasets.DatasetDict` with each split.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds = load_from_disk(&quot;path/to/dataset/directory&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fs</span><span class="p">:</span> <span class="n">fsspec</span><span class="o">.</span><span class="n">AbstractFileSystem</span>
        <span class="n">fs</span><span class="p">,</span> <span class="n">dataset_path</span> <span class="o">=</span> <span class="n">url_to_fs</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="n">storage_options</span> <span class="ow">or</span> <span class="p">{}))</span>

        <span class="n">dest_dataset_path</span> <span class="o">=</span> <span class="n">dataset_path</span>
        <span class="n">dataset_dict_json_path</span> <span class="o">=</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASETDICT_JSON_FILENAME</span><span class="p">)</span>
        <span class="n">dataset_state_json_path</span> <span class="o">=</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_STATE_JSON_FILENAME</span><span class="p">)</span>
        <span class="n">dataset_info_path</span> <span class="o">=</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_INFO_FILENAME</span><span class="p">)</span>

        <span class="n">dataset_dict_is_file</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">dataset_dict_json_path</span><span class="p">)</span>
        <span class="n">dataset_info_is_file</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">dataset_info_path</span><span class="p">)</span>
        <span class="n">dataset_state_is_file</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">dataset_state_json_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset_info_is_file</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">dataset_state_is_file</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dataset_dict_is_file</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;No such files: &#39;</span><span class="si">{</span><span class="n">dataset_info_path</span><span class="si">}</span><span class="s2">&#39;, nor &#39;</span><span class="si">{</span><span class="n">dataset_state_json_path</span><span class="si">}</span><span class="s2">&#39; found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.&quot;</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;No such files: &#39;</span><span class="si">{</span><span class="n">dataset_info_path</span><span class="si">}</span><span class="s2">&#39;, nor &#39;</span><span class="si">{</span><span class="n">dataset_state_json_path</span><span class="si">}</span><span class="s2">&#39; found. Expected to load a `Dataset` object but provided path is not a `Dataset`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset_info_is_file</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dataset_dict_is_file</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;No such file: &#39;</span><span class="si">{</span><span class="n">dataset_info_path</span><span class="si">}</span><span class="s2">&#39; found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.&quot;</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;No such file: &#39;</span><span class="si">{</span><span class="n">dataset_info_path</span><span class="si">}</span><span class="s2">&#39;. Expected to load a `Dataset` object but provided path is not a `Dataset`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset_state_is_file</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dataset_dict_is_file</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;No such file: &#39;</span><span class="si">{</span><span class="n">dataset_state_json_path</span><span class="si">}</span><span class="s2">&#39; found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.&quot;</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;No such file: &#39;</span><span class="si">{</span><span class="n">dataset_state_json_path</span><span class="si">}</span><span class="s2">&#39;. Expected to load a `Dataset` object but provided path is not a `Dataset`.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># copies file from filesystem if it is remote filesystem to local filesystem and modifies dataset_path to temp directory containing local copies</span>
        <span class="k">if</span> <span class="n">is_remote_filesystem</span><span class="p">(</span><span class="n">fs</span><span class="p">):</span>
            <span class="n">src_dataset_path</span> <span class="o">=</span> <span class="n">dest_dataset_path</span>
            <span class="n">dest_dataset_path</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_build_local_temp_path</span><span class="p">(</span><span class="n">src_dataset_path</span><span class="p">)</span>
            <span class="n">fs</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">src_dataset_path</span><span class="p">,</span> <span class="n">dest_dataset_path</span><span class="o">.</span><span class="n">as_posix</span><span class="p">(),</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">dataset_state_json_path</span> <span class="o">=</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_STATE_JSON_FILENAME</span><span class="p">)</span>
            <span class="n">dataset_info_path</span> <span class="o">=</span> <span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASET_INFO_FILENAME</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset_state_json_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">state_file</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">state_file</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset_info_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">dataset_info_file</span><span class="p">:</span>
            <span class="n">dataset_info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">dataset_info_file</span><span class="p">))</span>

        <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">estimate_dataset_size</span><span class="p">(</span>
            <span class="n">Path</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">data_file</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">data_file</span> <span class="ow">in</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_data_files&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">keep_in_memory</span> <span class="o">=</span> <span class="n">keep_in_memory</span> <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">is_small_dataset</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">)</span>
        <span class="n">table_cls</span> <span class="o">=</span> <span class="n">InMemoryTable</span> <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="k">else</span> <span class="n">MemoryMappedTable</span>

        <span class="n">arrow_table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">(</span>
            <span class="n">thread_map</span><span class="p">(</span>
                <span class="n">table_cls</span><span class="o">.</span><span class="n">from_file</span><span class="p">,</span>
                <span class="p">[</span><span class="n">posixpath</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest_dataset_path</span><span class="p">,</span> <span class="n">data_file</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">data_file</span> <span class="ow">in</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_data_files&quot;</span><span class="p">]],</span>
                <span class="n">tqdm_class</span><span class="o">=</span><span class="n">hf_tqdm</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Loading dataset from disk&quot;</span><span class="p">,</span>
                <span class="c1"># set `disable=None` rather than `disable=False` by default to disable progress bar when no TTY attached</span>
                <span class="n">disable</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_data_files&quot;</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="mi">16</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">split</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_split&quot;</span><span class="p">]</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">Split</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="k">if</span> <span class="n">split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">split</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">arrow_table</span><span class="o">=</span><span class="n">arrow_table</span><span class="p">,</span>
            <span class="n">info</span><span class="o">=</span><span class="n">dataset_info</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">fingerprint</span><span class="o">=</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_fingerprint&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="nb">format</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_format_type&quot;</span><span class="p">],</span>
            <span class="s2">&quot;format_kwargs&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_format_kwargs&quot;</span><span class="p">],</span>
            <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_format_columns&quot;</span><span class="p">],</span>
            <span class="s2">&quot;output_all_columns&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_output_all_columns&quot;</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="o">**</span><span class="nb">format</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dataset</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Table</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The Apache Arrow table backing the dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.data</span>
<span class="sd">        MemoryMappedTable</span>
<span class="sd">        text: string</span>
<span class="sd">        label: int64</span>
<span class="sd">        ----</span>
<span class="sd">        text: [[&quot;compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .&quot;,&quot;the soundtrack alone is worth the price of admission .&quot;,&quot;rodriguez does a splendid job of racial profiling hollywood style--casting excellent latin actors of all ages--a trend long overdue .&quot;,&quot;beneath the film&#39;s obvious determination to shock at any cost lies considerable skill and determination , backed by sheer nerve .&quot;,&quot;bielinsky is a filmmaker of impressive talent .&quot;,&quot;so beautifully acted and directed , it&#39;s clear that washington most certainly has a new career ahead of him if he so chooses .&quot;,&quot;a visual spectacle full of stunning images and effects .&quot;,&quot;a gentle and engrossing character study .&quot;,&quot;it&#39;s enough to watch huppert scheming , with her small , intelligent eyes as steady as any noir villain , and to enjoy the perfectly pitched web of tension that chabrol spins .&quot;,&quot;an engrossing portrait of uncompromising artists trying to create something original against the backdrop of a corporate music industry that only seems to care about the bottom line .&quot;,...,&quot;ultimately , jane learns her place as a girl , softens up and loses some of the intensity that made her an interesting character to begin with .&quot;,&quot;ah-nuld&#39;s action hero days might be over .&quot;,&quot;it&#39;s clear why deuces wild , which was shot two years ago , has been gathering dust on mgm&#39;s shelf .&quot;,&quot;feels like nothing quite so much as a middle-aged moviemaker&#39;s attempt to surround himself with beautiful , half-naked women .&quot;,&quot;when the precise nature of matthew&#39;s predicament finally comes into sharp focus , the revelation fails to justify the build-up .&quot;,&quot;this picture is murder by numbers , and as easy to be bored by as your abc&#39;s , despite a few whopping shootouts .&quot;,&quot;hilarious musical comedy though stymied by accents thick as mud .&quot;,&quot;if you are into splatter movies , then you will probably have a reasonably good time with the salton sea .&quot;,&quot;a dull , simple-minded and stereotypical tale of drugs , death and mind-numbing indifference on the inner-city streets .&quot;,&quot;the feature-length stretch . . . strains the show&#39;s concept .&quot;]]</span>
<span class="sd">        label: [[1,1,1,1,1,1,1,1,1,1,...,0,0,0,0,0,0,0,0,0,0]]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cache_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The cache files containing the Apache Arrow table backing the dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.cache_files</span>
<span class="sd">        [{&#39;filename&#39;: &#39;/root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/rotten_tomatoes_movie_review-validation.arrow&#39;}]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cache_files</span> <span class="o">=</span> <span class="n">list_table_cache_files</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cache_files</span> <span class="o">+=</span> <span class="n">list_table_cache_files</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">cache_filename</span><span class="p">}</span> <span class="k">for</span> <span class="n">cache_filename</span> <span class="ow">in</span> <span class="n">cache_files</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of columns in the dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.num_columns</span>
<span class="sd">        2</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">num_columns</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of rows in the dataset (same as [`Dataset.__len__`]).</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.num_rows</span>
<span class="sd">        1066</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">num_rows</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">num_rows</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">column_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Names of the columns in the dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.column_names</span>
<span class="sd">        [&#39;text&#39;, &#39;label&#39;]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shape of the dataset (number of columns, number of rows).</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.shape</span>
<span class="sd">        (1066, 2)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">num_rows</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">num_columns</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">shape</span>

<div class="viewcode-block" id="Dataset.unique">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.unique.html#datasets.Dataset.unique">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unique</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a list of the unique elements in a column.</span>

<span class="sd">        This is implemented in the low-level backend and as such, very fast.</span>

<span class="sd">        Args:</span>
<span class="sd">            column (`str`):</span>
<span class="sd">                Column name (list all the column names with [`~datasets.Dataset.column_names`]).</span>

<span class="sd">        Returns:</span>
<span class="sd">            `list`: List of unique elements in the given column.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.unique(&#39;label&#39;)</span>
<span class="sd">        [1, 0]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column (</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">) not in table columns (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">num_rows</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_indices</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="n">column</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.class_encode_column">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.class_encode_column.html#datasets.Dataset.class_encode_column">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">class_encode_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">include_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Casts the given column as [`~datasets.features.ClassLabel`] and updates the table.</span>

<span class="sd">        Args:</span>
<span class="sd">            column (`str`):</span>
<span class="sd">                The name of the column to cast (list all the column names with [`~datasets.Dataset.column_names`])</span>
<span class="sd">            include_nulls (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to include null values in the class labels. If `True`, the null values will be encoded as the `&quot;None&quot;` class label.</span>

<span class="sd">                &lt;Added version=&quot;1.14.2&quot;/&gt;</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;google/boolq&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;answer&#39;: Value(&#39;bool&#39;),</span>
<span class="sd">         &#39;passage&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;question&#39;: Value(&#39;string&#39;)}</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.class_encode_column(&#39;answer&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;answer&#39;: ClassLabel(num_classes=2, names=[&#39;False&#39;, &#39;True&#39;]),</span>
<span class="sd">         &#39;passage&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;question&#39;: Value(&#39;string&#39;)}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sanity checks</span>
        <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column (</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">) not in table columns (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>
        <span class="n">src_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">src_feat</span><span class="p">,</span> <span class="n">Value</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Class encoding is only supported for </span><span class="si">{</span><span class="n">Value</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> column, and column </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">src_feat</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">src_feat</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="s2">&quot;string&quot;</span> <span class="ow">or</span> <span class="p">(</span><span class="n">include_nulls</span> <span class="ow">and</span> <span class="kc">None</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">column</span><span class="p">)):</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">stringify_column</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="nb">str</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">if</span> <span class="n">include_nulls</span> <span class="ow">or</span> <span class="n">sample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="k">return</span> <span class="n">batch</span>

            <span class="n">dset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">stringify_column</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Stringifying the column&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dset</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="c1"># Create the new feature</span>
        <span class="n">class_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dset</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">column</span><span class="p">)</span> <span class="k">if</span> <span class="n">include_nulls</span> <span class="ow">or</span> <span class="n">sample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">dst_feat</span> <span class="o">=</span> <span class="n">ClassLabel</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">class_names</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">cast_to_class_labels</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">dst_feat</span><span class="o">.</span><span class="n">str2int</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span> <span class="k">if</span> <span class="n">include_nulls</span> <span class="ow">or</span> <span class="n">sample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="k">return</span> <span class="n">batch</span>

        <span class="n">new_features</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_features</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">dst_feat</span>

        <span class="n">dset</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">cast_to_class_labels</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">new_features</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Casting to class labels&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">dset</span></div>


<div class="viewcode-block" id="Dataset.flatten">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.flatten.html#datasets.Dataset.flatten">[docs]</a>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Flatten the table.</span>
<span class="sd">        Each column with a struct type is flattened into one column per struct field.</span>
<span class="sd">        Other columns are left unchanged.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset with flattened columns.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;rajpurkar/squad&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;id&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;title&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;context&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;question&#39;: Value(&#39;string&#39;),</span>
<span class="sd">         &#39;answers&#39;: {&#39;text&#39;: List(Value(&#39;string&#39;)),</span>
<span class="sd">         &#39;answer_start&#39;: List(Value(&#39;int32&#39;))}}</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.flatten()</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;id&#39;, &#39;title&#39;, &#39;context&#39;, &#39;question&#39;, &#39;answers.text&#39;, &#39;answers.answer_start&#39;],</span>
<span class="sd">            num_rows: 87599</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">StructType</span><span class="p">)</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">schema</span><span class="p">):</span>
                <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">({</span><span class="n">col</span><span class="p">:</span> <span class="n">dataset</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">column_names</span><span class="p">})</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Flattened dataset from depth </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s2"> to depth </span><span class="si">{</span><span class="mi">1</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">depth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">max_depth</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;unknown&#39;</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.cast">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.cast.html#datasets.Dataset.cast">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cast</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Features</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cast the dataset to a new set of features.</span>

<span class="sd">        Args:</span>
<span class="sd">            features ([`Features`]):</span>
<span class="sd">                New features to cast the dataset to.</span>
<span class="sd">                The name of the fields in the features must match the current column names.</span>
<span class="sd">                The type of the data must also be convertible from one type to the other.</span>
<span class="sd">                For non-trivial conversion, e.g. `str` &lt;-&gt; `ClassLabel` you should use [`~datasets.Dataset.map`] to update the Dataset.</span>
<span class="sd">            batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of examples per batch provided to cast.</span>
<span class="sd">                If `batch_size &lt;= 0` or `batch_size == None` then provide the full dataset as a single batch to cast.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to copy the data in-memory.</span>
<span class="sd">            load_from_cache_file (`bool`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the current computation from `function`</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            cache_file_name (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                results of the computation instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running [`~datasets.Dataset.map`].</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes for multiprocessing. By default it doesn&#39;t</span>
<span class="sd">                use multiprocessing.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset with casted features.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset, ClassLabel, Value</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;label&#39;: ClassLabel(names=[&#39;neg&#39;, &#39;pos&#39;]),</span>
<span class="sd">         &#39;text&#39;: Value(&#39;string&#39;)}</span>
<span class="sd">        &gt;&gt;&gt; new_features = ds.features.copy()</span>
<span class="sd">        &gt;&gt;&gt; new_features[&#39;label&#39;] = ClassLabel(names=[&#39;bad&#39;, &#39;good&#39;])</span>
<span class="sd">        &gt;&gt;&gt; new_features[&#39;text&#39;] = Value(&#39;large_string&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.cast(new_features)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;label&#39;: ClassLabel(names=[&#39;bad&#39;, &#39;good&#39;]),</span>
<span class="sd">         &#39;text&#39;: Value(&#39;large_string&#39;)}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The columns in features (</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="si">}</span><span class="s2">) must be identical &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;as the columns in the dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">features</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span>
        <span class="nb">format</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span>
        <span class="c1"># capture the PyArrow version here to make the lambda serializable on Windows</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">table_cast</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">),</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">load_from_cache_file</span><span class="o">=</span><span class="n">load_from_cache_file</span><span class="p">,</span>
            <span class="n">cache_file_name</span><span class="o">=</span><span class="n">cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Casting the dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="o">**</span><span class="nb">format</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.cast_column">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.cast_column.html#datasets.Dataset.cast_column">[docs]</a>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cast_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">feature</span><span class="p">:</span> <span class="n">FeatureType</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cast column to feature for decoding.</span>

<span class="sd">        Args:</span>
<span class="sd">            column (`str`):</span>
<span class="sd">                Column name.</span>
<span class="sd">            feature (`FeatureType`):</span>
<span class="sd">                Target feature.</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset, ClassLabel</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;label&#39;: ClassLabel(names=[&#39;neg&#39;, &#39;pos&#39;]),</span>
<span class="sd">         &#39;text&#39;: Value(&#39;string&#39;)}</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.cast_column(&#39;label&#39;, ClassLabel(names=[&#39;bad&#39;, &#39;good&#39;]))</span>
<span class="sd">        &gt;&gt;&gt; ds.features</span>
<span class="sd">        {&#39;label&#39;: ClassLabel(names=[&#39;bad&#39;, &#39;good&#39;]),</span>
<span class="sd">         &#39;text&#39;: Value(&#39;string&#39;)}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feature</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="s2">&quot;decode_example&quot;</span><span class="p">):</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">)</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">dataset</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>
            <span class="n">features</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">features</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.remove_columns">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.remove_columns.html#datasets.Dataset.remove_columns">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove one or several column(s) in the dataset and the features associated to them.</span>

<span class="sd">        You can also remove a column using [`~datasets.Dataset.map`] with `remove_columns` but the present method</span>
<span class="sd">        doesn&#39;t copy the data of the remaining columns and is thus faster.</span>

<span class="sd">        Args:</span>
<span class="sd">            column_names (`Union[str, List[str]]`):</span>
<span class="sd">                Name of the column(s) to remove.</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset object without the columns to remove.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.remove_columns(&#39;label&#39;)</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.remove_columns(column_names=ds.column_names) # Removing all the columns returns an empty dataset with the `num_rows` property set to 0</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [],</span>
<span class="sd">            num_rows: 0</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">column_names</span><span class="p">]</span>

        <span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Column name </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> not in the dataset. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current columns in the dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span>

        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.rename_column">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.rename_column.html#datasets.Dataset.rename_column">[docs]</a>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rename_column</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">original_column_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_column_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Rename a column in the dataset, and move the features associated to the original column under the new column</span>
<span class="sd">        name.</span>

<span class="sd">        Args:</span>
<span class="sd">            original_column_name (`str`):</span>
<span class="sd">                Name of the column to rename.</span>
<span class="sd">            new_column_name (`str`):</span>
<span class="sd">                New name for the column.</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset with a renamed column.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.rename_column(&#39;label&#39;, &#39;label_new&#39;)</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label_new&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">original_column_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Original column name </span><span class="si">{</span><span class="n">original_column_name</span><span class="si">}</span><span class="s2"> not in the dataset. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current columns in the dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">new_column_name</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;New column name </span><span class="si">{</span><span class="n">new_column_name</span><span class="si">}</span><span class="s2"> already in the dataset. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Please choose a column name which is not already in the dataset. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current columns in the dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">new_column_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;New column name is empty.&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">new_column_name</span> <span class="k">if</span> <span class="n">col</span> <span class="o">==</span> <span class="n">original_column_name</span> <span class="k">else</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">]</span>

        <span class="n">new_column_names</span> <span class="o">=</span> <span class="n">rename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_format_columns</span> <span class="o">=</span> <span class="n">rename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">)</span>

        <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="n">new_column_name</span> <span class="k">if</span> <span class="n">col</span> <span class="o">==</span> <span class="n">original_column_name</span> <span class="k">else</span> <span class="n">col</span><span class="p">:</span> <span class="n">feature</span>
                <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">new_column_names</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.rename_columns">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.rename_columns.html#datasets.Dataset.rename_columns">[docs]</a>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">rename_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Rename several columns in the dataset, and move the features associated to the original columns under</span>
<span class="sd">        the new column names.</span>

<span class="sd">        Args:</span>
<span class="sd">            column_mapping (`Dict[str, str]`):</span>
<span class="sd">                A mapping of columns to rename to their new names</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset with renamed columns</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.rename_columns({&#39;text&#39;: &#39;text_new&#39;, &#39;label&#39;: &#39;label_new&#39;})</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text_new&#39;, &#39;label_new&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">extra_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">column_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extra_columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Original column names </span><span class="si">{</span><span class="n">extra_columns</span><span class="si">}</span><span class="s2"> not in the dataset. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current columns in the dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">number_of_duplicates_in_new_columns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_mapping</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">column_mapping</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">number_of_duplicates_in_new_columns</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;New column names must all be different, but this column mapping &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;has </span><span class="si">{</span><span class="n">number_of_duplicates_in_new_columns</span><span class="si">}</span><span class="s2"> duplicates&quot;</span>
            <span class="p">)</span>

        <span class="n">empty_new_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_col</span> <span class="k">for</span> <span class="n">new_col</span> <span class="ow">in</span> <span class="n">column_mapping</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">new_col</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">empty_new_columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New column names </span><span class="si">{</span><span class="n">empty_new_columns</span><span class="si">}</span><span class="s2"> are empty.&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">column_mapping</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_mapping</span> <span class="k">else</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">]</span>

        <span class="n">new_column_names</span> <span class="o">=</span> <span class="n">rename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">_format_columns</span> <span class="o">=</span> <span class="n">rename</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">)</span>

        <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="n">column_mapping</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_mapping</span> <span class="k">else</span> <span class="n">col</span><span class="p">:</span> <span class="n">feature</span>
                <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">new_column_names</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.select_columns">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.select_columns.html#datasets.Dataset.select_columns">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">select_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select one or several column(s) in the dataset and the features</span>
<span class="sd">        associated to them.</span>

<span class="sd">        Args:</span>
<span class="sd">            column_names (`Union[str, List[str]]`):</span>
<span class="sd">                Name of the column(s) to keep.</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform. If `None`,</span>
<span class="sd">                the new fingerprint is computed using a hash of the previous</span>
<span class="sd">                fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A copy of the dataset object which only consists of</span>
<span class="sd">            selected columns.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.select_columns([&#39;text&#39;])</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">column_names</span><span class="p">]</span>

        <span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Column name </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> not in the &quot;</span>
                <span class="s2">&quot;dataset. Current columns in the dataset: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Features</span><span class="p">({</span><span class="n">col</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">})</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


    <span class="nd">@transmit_format</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_fast_select_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">select</span><span class="p">([</span><span class="n">column_name</span><span class="p">])</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">Features</span><span class="p">({</span><span class="n">column_name</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">column_name</span><span class="p">]}))</span>
        <span class="k">return</span> <span class="n">dataset</span>

<div class="viewcode-block" id="Dataset.__len__">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.__len__.html#datasets.Dataset.__len__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of rows in the dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.__len__</span>
<span class="sd">        &lt;bound method Dataset.__len__ of Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })&gt;</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rows</span></div>


<div class="viewcode-block" id="Dataset.__iter__">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.__iter__.html#datasets.Dataset.__iter__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterate through the examples.</span>

<span class="sd">        If a formatting is set with [`Dataset.set_format`] rows will be returned with the</span>
<span class="sd">        selected format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fast iteration</span>
            <span class="c1"># Benchmark: https://gist.github.com/mariosasko/0248288a2e3a7556873969717c1fe52b (fast_iter_batch)</span>
            <span class="n">format_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">get_formatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">ARROW_READER_BATCH_SIZE_IN_DATASET_ITER</span>
            <span class="k">for</span> <span class="n">pa_subtable</span> <span class="ow">in</span> <span class="n">table_iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pa_subtable</span><span class="o">.</span><span class="n">num_rows</span><span class="p">):</span>
                    <span class="n">pa_subtable_ex</span> <span class="o">=</span> <span class="n">pa_subtable</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">formatted_output</span> <span class="o">=</span> <span class="n">format_table</span><span class="p">(</span>
                        <span class="n">pa_subtable_ex</span><span class="p">,</span>
                        <span class="mi">0</span><span class="p">,</span>
                        <span class="n">formatter</span><span class="o">=</span><span class="n">formatter</span><span class="p">,</span>
                        <span class="n">format_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">,</span>
                        <span class="n">output_all_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">yield</span> <span class="n">formatted_output</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_rows</span><span class="p">):</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem</span><span class="p">(</span>
                    <span class="n">i</span><span class="p">,</span>
                <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.iter">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.iter.html#datasets.Dataset.iter">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">iter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">drop_last_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterate through the batches of size `batch_size`.</span>

<span class="sd">        If a formatting is set with [`~datasets.Dataset.set_format`] rows will be returned with the</span>
<span class="sd">        selected format.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (:obj:`int`): size of each batch to yield.</span>
<span class="sd">            drop_last_batch (:obj:`bool`, default `False`): Whether a last batch smaller than the batch_size should be</span>
<span class="sd">                dropped</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fast iteration</span>
            <span class="c1"># Benchmark: https://gist.github.com/mariosasko/0248288a2e3a7556873969717c1fe52b (fast_iter_batch)</span>
            <span class="n">format_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">get_formatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">pa_subtable</span> <span class="ow">in</span> <span class="n">table_iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_last_batch</span><span class="o">=</span><span class="n">drop_last_batch</span><span class="p">):</span>
                <span class="n">formatted_batch</span> <span class="o">=</span> <span class="n">format_table</span><span class="p">(</span>
                    <span class="n">pa_subtable</span><span class="p">,</span>
                    <span class="nb">range</span><span class="p">(</span><span class="n">pa_subtable</span><span class="o">.</span><span class="n">num_rows</span><span class="p">),</span>
                    <span class="n">formatter</span><span class="o">=</span><span class="n">formatter</span><span class="p">,</span>
                    <span class="n">format_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">,</span>
                    <span class="n">output_all_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">yield</span> <span class="n">formatted_batch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rows</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">drop_last_batch</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem</span><span class="p">(</span>
                    <span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">),</span>
                <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Dataset(</span><span class="se">{{\n</span><span class="s2">    features: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">    num_rows: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="se">\n}}</span><span class="s2">)&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">format</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span>
            <span class="s2">&quot;format_kwargs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="p">,</span>
            <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">,</span>
            <span class="s2">&quot;output_all_columns&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span><span class="p">,</span>
        <span class="p">}</span>

<div class="viewcode-block" id="Dataset.formatted_as">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.formatted_as.html#datasets.Dataset.formatted_as">[docs]</a>
    <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">formatted_as</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">format_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;To be used in a `with` statement. Set `__getitem__` return format (type and columns).</span>

<span class="sd">        Args:</span>
<span class="sd">            type (`str`, *optional*):</span>
<span class="sd">                Either output type selected in `[None, &#39;numpy&#39;, &#39;torch&#39;, &#39;tensorflow&#39;, &#39;jax&#39;, &#39;arrow&#39;, &#39;pandas&#39;, &#39;polars&#39;]`.</span>
<span class="sd">                `None` means `__getitem__`` returns python objects (default).</span>
<span class="sd">            columns (`List[str]`, *optional*):</span>
<span class="sd">                Columns to format in the output.</span>
<span class="sd">                `None` means `__getitem__` returns all columns (default).</span>
<span class="sd">            output_all_columns (`bool`, defaults to `False`):</span>
<span class="sd">                Keep un-formatted columns as well in the output (as python objects).</span>
<span class="sd">            **format_kwargs (additional keyword arguments):</span>
<span class="sd">                Keywords arguments passed to the convert function like `np.array`, `torch.tensor` or `tensorflow.ragged.constant`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">old_format_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span>
        <span class="n">old_format_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span>
        <span class="n">old_format_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span>
        <span class="n">old_output_all_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">output_all_columns</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="n">old_format_type</span><span class="p">,</span> <span class="n">old_format_columns</span><span class="p">,</span> <span class="n">old_output_all_columns</span><span class="p">,</span> <span class="o">**</span><span class="n">old_format_kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.set_format">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.set_format.html#datasets.Dataset.set_format">[docs]</a>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_format</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">format_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set `__getitem__` return format (type and columns). The data formatting is applied on-the-fly.</span>
<span class="sd">        The format `type` (for example &quot;numpy&quot;) is used to format batches when using `__getitem__`.</span>
<span class="sd">        It&#39;s also possible to use custom transforms for formatting using [`~datasets.Dataset.set_transform`].</span>

<span class="sd">        Args:</span>
<span class="sd">            type (`str`, *optional*):</span>
<span class="sd">                Either output type selected in `[None, &#39;numpy&#39;, &#39;torch&#39;, &#39;tensorflow&#39;, &#39;jax&#39;, &#39;arrow&#39;, &#39;pandas&#39;, &#39;polars&#39;]`.</span>
<span class="sd">                `None` means `__getitem__` returns python objects (default).</span>
<span class="sd">            columns (`List[str]`, *optional*):</span>
<span class="sd">                Columns to format in the output.</span>
<span class="sd">                `None` means `__getitem__` returns all columns (default).</span>
<span class="sd">            output_all_columns (`bool`, defaults to `False`):</span>
<span class="sd">                Keep un-formatted columns as well in the output (as python objects).</span>
<span class="sd">            **format_kwargs (additional keyword arguments):</span>
<span class="sd">                Keywords arguments passed to the convert function like `np.array`, `torch.tensor` or `tensorflow.ragged.constant`.</span>

<span class="sd">        It is possible to call [`~datasets.Dataset.map`] after calling `set_format`. Since `map` may add new columns, then the list of formatted columns</span>
<span class="sd">        gets updated. In this case, if you apply `map` on a dataset to add a new column, then this column will be formatted as:</span>

<span class="sd">            ```</span>
<span class="sd">            new formatted columns = (all columns - previously unformatted columns)</span>
<span class="sd">            ```</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(lambda x: tokenizer(x[&#39;text&#39;], truncation=True, padding=True), batched=True)</span>
<span class="sd">        &gt;&gt;&gt; ds.set_format(type=&#39;numpy&#39;, columns=[&#39;text&#39;, &#39;label&#39;])</span>
<span class="sd">        &gt;&gt;&gt; ds.format</span>
<span class="sd">        {&#39;type&#39;: &#39;numpy&#39;,</span>
<span class="sd">        &#39;format_kwargs&#39;: {},</span>
<span class="sd">        &#39;columns&#39;: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">        &#39;output_all_columns&#39;: False}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">format_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">format_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;format_kwargs&quot;</span><span class="p">,</span> <span class="p">{}))</span>  <span class="c1"># allow to use self.set_format(**self.format)</span>

        <span class="c1"># Check that the format_type and format_kwargs are valid and make it possible to have a Formatter</span>
        <span class="nb">type</span> <span class="o">=</span> <span class="n">get_format_type_from_alias</span><span class="p">(</span><span class="nb">type</span><span class="p">)</span>
        <span class="n">get_formatter</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>

        <span class="c1"># Check filter column</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">columns</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Columns </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> not in the dataset. Current columns in the dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Ensures modifications made to the list after this call don&#39;t cause bugs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span> <span class="o">=</span> <span class="nb">type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="o">=</span> <span class="n">format_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="o">=</span> <span class="n">columns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span> <span class="o">=</span> <span class="n">output_all_columns</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Set __getitem__(key) output type to </span><span class="si">%s</span><span class="s2"> for </span><span class="si">%s</span><span class="s2"> columns &quot;</span>
            <span class="s2">&quot; (when key is int or slice) and </span><span class="si">%s</span><span class="s2"> output other (un-formatted) columns.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;python objects&quot;</span> <span class="k">if</span> <span class="nb">type</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">type</span><span class="p">,</span>
            <span class="s2">&quot;no&quot;</span> <span class="k">if</span> <span class="n">columns</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">columns</span><span class="p">),</span>
            <span class="s2">&quot;do&quot;</span> <span class="k">if</span> <span class="n">output_all_columns</span> <span class="k">else</span> <span class="s2">&quot;don&#39;t&quot;</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.reset_format">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.reset_format.html#datasets.Dataset.reset_format">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_format</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset `__getitem__` return format to python objects and all columns.</span>

<span class="sd">        Same as `self.set_format()`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(lambda x: tokenizer(x[&#39;text&#39;], truncation=True, padding=True), batched=True)</span>
<span class="sd">        &gt;&gt;&gt; ds.set_format(type=&#39;numpy&#39;, columns=[&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;, &#39;label&#39;])</span>
<span class="sd">        &gt;&gt;&gt; ds.format</span>
<span class="sd">        {&#39;columns&#39;: [&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;, &#39;label&#39;],</span>
<span class="sd">         &#39;format_kwargs&#39;: {},</span>
<span class="sd">         &#39;output_all_columns&#39;: False,</span>
<span class="sd">         &#39;type&#39;: &#39;numpy&#39;}</span>
<span class="sd">        &gt;&gt;&gt; ds.reset_format()</span>
<span class="sd">        &gt;&gt;&gt; ds.format</span>
<span class="sd">        {&#39;columns&#39;: [&#39;text&#39;, &#39;label&#39;, &#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;],</span>
<span class="sd">         &#39;format_kwargs&#39;: {},</span>
<span class="sd">         &#39;output_all_columns&#39;: False,</span>
<span class="sd">         &#39;type&#39;: None}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_format</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.set_transform">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.set_transform.html#datasets.Dataset.set_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">],</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set `__getitem__` return format using this transform. The transform is applied on-the-fly on batches when `__getitem__` is called.</span>
<span class="sd">        As [`~datasets.Dataset.set_format`], this can be reset using [`~datasets.Dataset.reset_format`].</span>

<span class="sd">        Args:</span>
<span class="sd">            transform (`Callable`, *optional*):</span>
<span class="sd">                User-defined formatting transform, replaces the format defined by [`~datasets.Dataset.set_format`].</span>
<span class="sd">                A formatting function is a callable that takes a batch (as a `dict`) as input and returns a batch.</span>
<span class="sd">                This function is applied right before returning the objects in `__getitem__`.</span>
<span class="sd">            columns (`List[str]`, *optional*):</span>
<span class="sd">                Columns to format in the output.</span>
<span class="sd">                If specified, then the input batch of the transform only contains those columns.</span>
<span class="sd">            output_all_columns (`bool`, defaults to `False`):</span>
<span class="sd">                Keep un-formatted columns as well in the output (as python objects).</span>
<span class="sd">                If set to True, then the other un-formatted columns are kept with the output of the transform.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)</span>
<span class="sd">        &gt;&gt;&gt; def encode(batch):</span>
<span class="sd">        ...     return tokenizer(batch[&#39;text&#39;], padding=True, truncation=True, return_tensors=&#39;pt&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds.set_transform(encode)</span>
<span class="sd">        &gt;&gt;&gt; ds[0]</span>
<span class="sd">        {&#39;attention_mask&#39;: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="sd">         1, 1]),</span>
<span class="sd">         &#39;input_ids&#39;: tensor([  101, 29353,  2135, 15102,  1996,  9428, 20868,  2890,  8663,  6895,</span>
<span class="sd">                 20470,  2571,  3663,  2090,  4603,  3017,  3008,  1998,  2037, 24211,</span>
<span class="sd">                 5637,  1998, 11690,  2336,  1012,   102]),</span>
<span class="sd">         &#39;token_type_ids&#39;: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                 0, 0])}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="s2">&quot;custom&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">output_all_columns</span><span class="o">=</span><span class="n">output_all_columns</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.with_format">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.with_format.html#datasets.Dataset.with_format">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">with_format</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">format_kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set `__getitem__` return format (type and columns). The data formatting is applied on-the-fly.</span>
<span class="sd">        The format `type` (for example &quot;numpy&quot;) is used to format batches when using `__getitem__`.</span>

<span class="sd">        It&#39;s also possible to use custom transforms for formatting using [`~datasets.Dataset.with_transform`].</span>

<span class="sd">        Contrary to [`~datasets.Dataset.set_format`], `with_format` returns a new [`Dataset`] object.</span>

<span class="sd">        Args:</span>
<span class="sd">            type (`str`, *optional*):</span>
<span class="sd">                Either output type selected in `[None, &#39;numpy&#39;, &#39;torch&#39;, &#39;tensorflow&#39;, &#39;jax&#39;, &#39;arrow&#39;, &#39;pandas&#39;, &#39;polars&#39;]`.</span>
<span class="sd">                `None` means `__getitem__` returns python objects (default).</span>
<span class="sd">            columns (`List[str]`, *optional*):</span>
<span class="sd">                Columns to format in the output.</span>
<span class="sd">                `None` means `__getitem__` returns all columns (default).</span>
<span class="sd">            output_all_columns (`bool`, defaults to `False`):</span>
<span class="sd">                Keep un-formatted columns as well in the output (as python objects).</span>
<span class="sd">            **format_kwargs (additional keyword arguments):</span>
<span class="sd">                Keywords arguments passed to the convert function like `np.array`, `torch.tensor` or `tensorflow.ragged.constant`.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(lambda x: tokenizer(x[&#39;text&#39;], truncation=True, padding=True), batched=True)</span>
<span class="sd">        &gt;&gt;&gt; ds.format</span>
<span class="sd">        {&#39;columns&#39;: [&#39;text&#39;, &#39;label&#39;, &#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;],</span>
<span class="sd">         &#39;format_kwargs&#39;: {},</span>
<span class="sd">         &#39;output_all_columns&#39;: False,</span>
<span class="sd">         &#39;type&#39;: None}</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.with_format(&quot;torch&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.format</span>
<span class="sd">        {&#39;columns&#39;: [&#39;text&#39;, &#39;label&#39;, &#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;],</span>
<span class="sd">         &#39;format_kwargs&#39;: {},</span>
<span class="sd">         &#39;output_all_columns&#39;: False,</span>
<span class="sd">         &#39;type&#39;: &#39;torch&#39;}</span>
<span class="sd">        &gt;&gt;&gt; ds[0]</span>
<span class="sd">        {&#39;text&#39;: &#39;compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .&#39;,</span>
<span class="sd">         &#39;label&#39;: tensor(1),</span>
<span class="sd">         &#39;input_ids&#39;: tensor([  101, 18027, 16310, 16001,  1103,  9321,   178, 11604,  7235,  6617,</span>
<span class="sd">                1742,  2165,  2820,  1206,  6588, 22572, 12937,  1811,  2153,  1105,</span>
<span class="sd">                1147, 12890, 19587,  6463,  1105, 15026,  1482,   119,   102,     0,</span>
<span class="sd">                    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>
<span class="sd">                    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>
<span class="sd">                    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>
<span class="sd">                    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>
<span class="sd">                    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>
<span class="sd">                    0,     0,     0,     0]),</span>
<span class="sd">         &#39;token_type_ids&#39;: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),</span>
<span class="sd">         &#39;attention_mask&#39;: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="sd">                1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">output_all_columns</span><span class="o">=</span><span class="n">output_all_columns</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="Dataset.with_transform">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.with_transform.html#datasets.Dataset.with_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">with_transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">],</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_all_columns</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set `__getitem__` return format using this transform. The transform is applied on-the-fly on batches when `__getitem__` is called.</span>

<span class="sd">        As [`~datasets.Dataset.set_format`], this can be reset using [`~datasets.Dataset.reset_format`].</span>

<span class="sd">        Contrary to [`~datasets.Dataset.set_transform`], `with_transform` returns a new [`Dataset`] object.</span>

<span class="sd">        Args:</span>
<span class="sd">            transform (`Callable`, `optional`):</span>
<span class="sd">                User-defined formatting transform, replaces the format defined by [`~datasets.Dataset.set_format`].</span>
<span class="sd">                A formatting function is a callable that takes a batch (as a `dict`) as input and returns a batch.</span>
<span class="sd">                This function is applied right before returning the objects in `__getitem__`.</span>
<span class="sd">            columns (`List[str]`, `optional`):</span>
<span class="sd">                Columns to format in the output.</span>
<span class="sd">                If specified, then the input batch of the transform only contains those columns.</span>
<span class="sd">            output_all_columns (`bool`, defaults to `False`):</span>
<span class="sd">                Keep un-formatted columns as well in the output (as python objects).</span>
<span class="sd">                If set to `True`, then the other un-formatted columns are kept with the output of the transform.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-cased&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def encode(example):</span>
<span class="sd">        ...     return tokenizer(example[&quot;text&quot;], padding=True, truncation=True, return_tensors=&#39;pt&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.with_transform(encode)</span>
<span class="sd">        &gt;&gt;&gt; ds[0]</span>
<span class="sd">        {&#39;attention_mask&#39;: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="sd">         1, 1, 1, 1, 1]),</span>
<span class="sd">         &#39;input_ids&#39;: tensor([  101, 18027, 16310, 16001,  1103,  9321,   178, 11604,  7235,  6617,</span>
<span class="sd">                 1742,  2165,  2820,  1206,  6588, 22572, 12937,  1811,  2153,  1105,</span>
<span class="sd">                 1147, 12890, 19587,  6463,  1105, 15026,  1482,   119,   102]),</span>
<span class="sd">         &#39;token_type_ids&#39;: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="sd">                 0, 0, 0, 0, 0])}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">output_all_columns</span><span class="o">=</span><span class="n">output_all_columns</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_getitem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ListLike</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Can be used to index columns (by string names) or rows (by integer, slice, or list-like of integer indices)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;dataset index must be int, str, slice or collection of int, not bool&quot;</span><span class="p">)</span>
        <span class="n">format_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;format_type&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;format_type&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span>
        <span class="n">format_columns</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;format_columns&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;format_columns&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span>
        <span class="n">output_all_columns</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;output_all_columns&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;output_all_columns&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_all_columns</span>
        <span class="p">)</span>
        <span class="n">format_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;format_kwargs&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;format_kwargs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span>
        <span class="n">format_kwargs</span> <span class="o">=</span> <span class="n">format_kwargs</span> <span class="k">if</span> <span class="n">format_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">formatter</span> <span class="o">=</span> <span class="n">get_formatter</span><span class="p">(</span><span class="n">format_type</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="o">**</span><span class="n">format_kwargs</span><span class="p">)</span>
        <span class="n">pa_subtable</span> <span class="o">=</span> <span class="n">query_table</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">)</span>
        <span class="n">formatted_output</span> <span class="o">=</span> <span class="n">format_table</span><span class="p">(</span>
            <span class="n">pa_subtable</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">formatter</span><span class="o">=</span><span class="n">formatter</span><span class="p">,</span> <span class="n">format_columns</span><span class="o">=</span><span class="n">format_columns</span><span class="p">,</span> <span class="n">output_all_columns</span><span class="o">=</span><span class="n">output_all_columns</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">formatted_output</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>  <span class="c1"># noqa: F811</span>
        <span class="o">...</span>

    <span class="nd">@overload</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>  <span class="c1"># noqa: F811</span>
        <span class="o">...</span>

<div class="viewcode-block" id="Dataset.__getitem__">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.__getitem__.html#datasets.Dataset.__getitem__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>  <span class="c1"># noqa: F811</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">,</span> <span class="s2">&quot;pandas&quot;</span><span class="p">,</span> <span class="s2">&quot;polars&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getitem</span><span class="p">(</span><span class="n">key</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">__getitems__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Can be used to get a batch using a list of integers indices.&quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
        <span class="n">n_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batch</span><span class="p">))])</span>
        <span class="k">return</span> <span class="p">[{</span><span class="n">col</span><span class="p">:</span> <span class="n">array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">array</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_examples</span><span class="p">)]</span>

<div class="viewcode-block" id="Dataset.cleanup_cache_files">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.cleanup_cache_files.html#datasets.Dataset.cleanup_cache_files">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup_cache_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up all cache files in the dataset cache directory, excepted the currently used cache file if there is</span>
<span class="sd">        one.</span>

<span class="sd">        Be careful when running this command that no other process is currently using other cache files.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `int`: Number of removed files.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds.cleanup_cache_files()</span>
<span class="sd">        10</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_cache_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">cache_file</span><span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">cache_file</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">current_cache_files</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="n">cache_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">current_cache_files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Listing files in </span><span class="si">{</span><span class="n">cache_directory</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">files</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">cache_directory</span><span class="p">)</span>
        <span class="n">files_to_remove</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">f_name</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
            <span class="n">full_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_directory</span><span class="p">,</span> <span class="n">f_name</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">f_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;cache-&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">f_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.arrow&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">full_name</span> <span class="ow">in</span> <span class="n">current_cache_files</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Keeping currently used cache file at </span><span class="si">{</span><span class="n">full_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">files_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">files_to_remove</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removing </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">files_to_remove</span><span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_get_cache_file_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fingerprint</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">is_caching_enabled</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">:</span>
            <span class="n">cache_file_name</span> <span class="o">=</span> <span class="s2">&quot;cache-&quot;</span> <span class="o">+</span> <span class="n">fingerprint</span> <span class="o">+</span> <span class="s2">&quot;.arrow&quot;</span>
            <span class="n">cache_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;filename&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cache_file_name</span> <span class="o">=</span> <span class="s2">&quot;cache-&quot;</span> <span class="o">+</span> <span class="n">generate_random_fingerprint</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;.arrow&quot;</span>
            <span class="n">cache_directory</span> <span class="o">=</span> <span class="n">get_temporary_cache_files_directory</span><span class="p">()</span>
        <span class="n">cache_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_directory</span><span class="p">,</span> <span class="n">cache_file_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cache_file_path</span>

<div class="viewcode-block" id="Dataset.map">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.map.html#datasets.Dataset.map">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">with_indices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">with_rank</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">input_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">drop_last_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">disable_nullable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_</span><span class="si">{rank:05d}</span><span class="s2">_of_</span><span class="si">{num_proc:05d}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_original_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply a function to all the examples in the table (individually or in batches) and update the table.</span>
<span class="sd">        If your function returns a column that already exists, then it overwrites it.</span>

<span class="sd">        You can specify whether the function should be batched or not with the `batched` parameter:</span>

<span class="sd">        - If batched is `False`, then the function takes 1 example in and should return 1 example.</span>
<span class="sd">          An example is a dictionary, e.g. `{&quot;text&quot;: &quot;Hello there !&quot;}`.</span>
<span class="sd">        - If batched is `True` and `batch_size` is 1, then the function takes a batch of 1 example as input and can return a batch with 1 or more examples.</span>
<span class="sd">          A batch is a dictionary, e.g. a batch of 1 example is `{&quot;text&quot;: [&quot;Hello there !&quot;]}`.</span>
<span class="sd">        - If batched is `True` and `batch_size` is `n &gt; 1`, then the function takes a batch of `n` examples as input and can return a batch with `n` examples, or with an arbitrary number of examples.</span>
<span class="sd">          Note that the last batch may have less than `n` examples.</span>
<span class="sd">          A batch is a dictionary, e.g. a batch of `n` examples is `{&quot;text&quot;: [&quot;Hello there !&quot;] * n}`.</span>

<span class="sd">        If the function is asynchronous, then `map` will run your function in parallel, with up to one thousand simultaneous calls.</span>
<span class="sd">        It is recommended to use a `asyncio.Semaphore` in your function if you want to set a maximum number of operations that can run at the same time.</span>

<span class="sd">        Args:</span>
<span class="sd">            function (`Callable`): Function with one of the following signatures:</span>

<span class="sd">                - `function(example: Dict[str, Any]) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(example: Dict[str, Any], *extra_args) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>
<span class="sd">                - `function(batch: Dict[str, List]) -&gt; Dict[str, List]` if `batched=True` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(batch: Dict[str, List], *extra_args) -&gt; Dict[str, List]` if `batched=True` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>

<span class="sd">                For advanced usage, the function can also return a `pyarrow.Table`.</span>
<span class="sd">                If the function is asynchronous, then `map` will run your function in parallel.</span>
<span class="sd">                Moreover if your function returns nothing (`None`), then `map` will run your function and return the dataset unchanged.</span>
<span class="sd">                If no function is provided, default to identity function: `lambda x: x`.</span>
<span class="sd">            with_indices (`bool`, defaults to `False`):</span>
<span class="sd">                Provide example indices to `function`. Note that in this case the</span>
<span class="sd">                signature of `function` should be `def function(example, idx[, rank]): ...`.</span>
<span class="sd">            with_rank (`bool`, defaults to `False`):</span>
<span class="sd">                Provide process rank to `function`. Note that in this case the</span>
<span class="sd">                signature of `function` should be `def function(example[, idx], rank): ...`.</span>
<span class="sd">            input_columns (`Optional[Union[str, List[str]]]`, defaults to `None`):</span>
<span class="sd">                The columns to be passed into `function`</span>
<span class="sd">                as positional arguments. If `None`, a `dict` mapping to all formatted columns is passed as one argument.</span>
<span class="sd">            batched (`bool`, defaults to `False`):</span>
<span class="sd">                Provide batch of examples to `function`.</span>
<span class="sd">            batch_size (`int`, *optional*, defaults to `1000`):</span>
<span class="sd">                Number of examples per batch provided to `function` if `batched=True`.</span>
<span class="sd">                If `batch_size &lt;= 0` or `batch_size == None`, provide the full dataset as a single batch to `function`.</span>
<span class="sd">            drop_last_batch (`bool`, defaults to `False`):</span>
<span class="sd">                Whether a last batch smaller than the batch_size should be</span>
<span class="sd">                dropped instead of being processed by the function.</span>
<span class="sd">            remove_columns (`Optional[Union[str, List[str]]]`, defaults to `None`):</span>
<span class="sd">                Remove a selection of columns while doing the mapping.</span>
<span class="sd">                Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding</span>
<span class="sd">                columns with names in `remove_columns`, these columns will be kept.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the dataset in memory instead of writing it to a cache file.</span>
<span class="sd">            load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the current computation from `function`</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            cache_file_name (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                results of the computation instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            features (`Optional[datasets.Features]`, defaults to `None`):</span>
<span class="sd">                Use a specific Features to store the cache file</span>
<span class="sd">                instead of the automatically generated one.</span>
<span class="sd">            disable_nullable (`bool`, defaults to `False`):</span>
<span class="sd">                Disallow null values in the table.</span>
<span class="sd">            fn_kwargs (`Dict`, *optional*, defaults to `None`):</span>
<span class="sd">                Keyword arguments to be passed to `function`.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                 The number of processes to use for multiprocessing.</span>
<span class="sd">                - If `None` or `0`, no multiprocessing is used and the operation runs in the main process.</span>
<span class="sd">                - If greater than `1`, one or multiple worker processes are used to process data in parallel.</span>
<span class="sd">                 Note: The function passed to `map()` must be picklable for multiprocessing to work correctly</span>
<span class="sd">                 (i.e., prefer functions defined at the top level of a module, not inside another function or class).</span>
<span class="sd">             suffix_template (`str`):</span>
<span class="sd">                If `cache_file_name` is specified, then this suffix</span>
<span class="sd">                will be added at the end of the base name of each. Defaults to `&quot;_{rank:05d}_of_{num_proc:05d}&quot;`. For example, if `cache_file_name` is &quot;processed.arrow&quot;, then for</span>
<span class="sd">                `rank=1` and `num_proc=4`, the resulting file would be `&quot;processed_00001_of_00004.arrow&quot;` for the default suffix.</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>
<span class="sd">            desc (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Meaningful description to be displayed alongside with the progress bar while mapping examples.</span>
<span class="sd">            try_original_type (`Optional[bool]`, defaults to `True`):</span>
<span class="sd">                Try to keep the types of the original columns (e.g. int32 -&gt; int32).</span>
<span class="sd">                Set to False if you want to always infer new types.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def add_prefix(example):</span>
<span class="sd">        ...     example[&quot;text&quot;] = &quot;Review: &quot; + example[&quot;text&quot;]</span>
<span class="sd">        ...     return example</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(add_prefix)</span>
<span class="sd">        &gt;&gt;&gt; ds[0:3][&quot;text&quot;]</span>
<span class="sd">        [&#39;Review: compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .&#39;,</span>
<span class="sd">         &#39;Review: the soundtrack alone is worth the price of admission .&#39;,</span>
<span class="sd">         &#39;Review: rodriguez does a splendid job of racial profiling hollywood style--casting excellent latin actors of all ages--a trend long overdue .&#39;]</span>

<span class="sd">        # process a batch of examples</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(lambda example: tokenizer(example[&quot;text&quot;]), batched=True)</span>
<span class="sd">        # set number of processors</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.map(add_prefix, num_proc=4)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">and</span> <span class="n">cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use either `keep_in_memory` or `cache_file_name` but not both.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_proc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_proc must be &gt;= 0 or None.&quot;</span><span class="p">)</span>

        <span class="n">string_formatter</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">Formatter</span><span class="p">()</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="p">{</span><span class="n">field_name</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">field_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">string_formatter</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">suffix_template</span><span class="p">)</span> <span class="k">if</span> <span class="n">field_name</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">fields</span> <span class="o">!=</span> <span class="p">{</span><span class="s2">&quot;rank&quot;</span><span class="p">,</span> <span class="s2">&quot;num_proc&quot;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;suffix_template must contain exactly the fields &#39;rank&#39; and &#39;num_proc&#39;, got: </span><span class="si">{</span><span class="n">fields</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># If the array is empty we do nothing (but we make sure to handle an empty indices mapping and remove the requested columns anyway)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># empty indices mapping</span>
                <span class="bp">self</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">info</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                    <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                    <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">remove_columns</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span><span class="n">remove_columns</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>  <span class="c1"># noqa: E731</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_columns</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">input_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_columns</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">input_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">input_columns</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input column </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> not in the dataset. Current columns in the dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">remove_columns</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">remove_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">remove_columns</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">remove_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">remove_columns</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Column to remove </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span><span class="si">}</span><span class="s2"> not in the dataset. Current columns in the dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">load_from_cache_file</span> <span class="o">=</span> <span class="n">load_from_cache_file</span> <span class="k">if</span> <span class="n">load_from_cache_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">is_caching_enabled</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">fn_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fn_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">_fix_for_backward_compatible_features</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;num_proc must be &lt;= </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">. Reducing num_proc to </span><span class="si">{</span><span class="n">num_proc</span><span class="si">}</span><span class="s2"> for dataset of size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">dataset_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;shard&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="p">,</span>
            <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">function</span><span class="p">,</span>
            <span class="s2">&quot;with_indices&quot;</span><span class="p">:</span> <span class="n">with_indices</span><span class="p">,</span>
            <span class="s2">&quot;with_rank&quot;</span><span class="p">:</span> <span class="n">with_rank</span><span class="p">,</span>
            <span class="s2">&quot;input_columns&quot;</span><span class="p">:</span> <span class="n">input_columns</span><span class="p">,</span>
            <span class="s2">&quot;batched&quot;</span><span class="p">:</span> <span class="n">batched</span><span class="p">,</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
            <span class="s2">&quot;drop_last_batch&quot;</span><span class="p">:</span> <span class="n">drop_last_batch</span><span class="p">,</span>
            <span class="s2">&quot;remove_columns&quot;</span><span class="p">:</span> <span class="n">remove_columns</span><span class="p">,</span>
            <span class="s2">&quot;keep_in_memory&quot;</span><span class="p">:</span> <span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="s2">&quot;writer_batch_size&quot;</span><span class="p">:</span> <span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
            <span class="s2">&quot;disable_nullable&quot;</span><span class="p">:</span> <span class="n">disable_nullable</span><span class="p">,</span>
            <span class="s2">&quot;fn_kwargs&quot;</span><span class="p">:</span> <span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="s2">&quot;try_original_type&quot;</span><span class="p">:</span> <span class="n">try_original_type</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">new_fingerprint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we create a unique hash from the function,</span>
            <span class="c1"># current dataset file and the mapping args</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">format_transform_for_fingerprint</span><span class="p">(</span><span class="n">Dataset</span><span class="o">.</span><span class="n">_map_single</span><span class="p">)</span>
            <span class="n">kwargs_for_fingerprint</span> <span class="o">=</span> <span class="n">format_kwargs_for_fingerprint</span><span class="p">(</span><span class="n">Dataset</span><span class="o">.</span><span class="n">_map_single</span><span class="p">,</span> <span class="p">(),</span> <span class="n">dataset_kwargs</span><span class="p">)</span>
            <span class="n">kwargs_for_fingerprint</span><span class="p">[</span><span class="s2">&quot;fingerprint_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;new_fingerprint&quot;</span>
            <span class="n">new_fingerprint</span> <span class="o">=</span> <span class="n">update_fingerprint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span><span class="p">,</span> <span class="n">transform</span><span class="p">,</span> <span class="n">kwargs_for_fingerprint</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">validate_fingerprint</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">)</span>
        <span class="n">dataset_kwargs</span><span class="p">[</span><span class="s2">&quot;new_fingerprint&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_fingerprint</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cache_file_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_file_path</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">)</span>
        <span class="n">dataset_kwargs</span><span class="p">[</span><span class="s2">&quot;cache_file_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cache_file_name</span>

        <span class="k">if</span> <span class="n">cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cache_file_prefix</span><span class="p">,</span> <span class="n">cache_file_ext</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cache_file_ext</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected cache_file_name to have an extension, but got: </span><span class="si">{</span><span class="n">cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cache_file_prefix</span> <span class="o">=</span> <span class="n">cache_file_ext</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">load_processed_shard_from_cache</span><span class="p">(</span><span class="n">shard_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Load a processed shard from cache if it exists, otherwise throw an error.&quot;&quot;&quot;</span>
            <span class="n">shard</span> <span class="o">=</span> <span class="n">shard_kwargs</span><span class="p">[</span><span class="s2">&quot;shard&quot;</span><span class="p">]</span>
            <span class="c1"># Check if we&#39;ve already cached this computation (indexed by a hash)</span>
            <span class="k">if</span> <span class="n">shard_kwargs</span><span class="p">[</span><span class="s2">&quot;cache_file_name&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">shard_kwargs</span><span class="p">[</span><span class="s2">&quot;cache_file_name&quot;</span><span class="p">])</span> <span class="ow">and</span> <span class="n">load_from_cache_file</span><span class="p">:</span>
                    <span class="n">info</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
                    <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">shard_kwargs</span><span class="p">[</span><span class="s2">&quot;cache_file_name&quot;</span><span class="p">],</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">shard</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">NonExistentDatasetError</span>

        <span class="n">existing_cache_file_map</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">):</span>
                <span class="n">existing_cache_file_map</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">cache_file_name</span><span class="p">]</span>

            <span class="k">assert</span> <span class="n">cache_file_prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cache_file_ext</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">cache_file_with_suffix_pattern</span> <span class="o">=</span> <span class="n">cache_file_prefix</span> <span class="o">+</span> <span class="n">suffix_template</span> <span class="o">+</span> <span class="n">cache_file_ext</span>

            <span class="k">for</span> <span class="n">cache_file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">iglob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cache_file_prefix</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">cache_file_ext</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">suffix_variable_map</span> <span class="o">=</span> <span class="n">string_to_dict</span><span class="p">(</span>
                    <span class="n">Path</span><span class="p">(</span><span class="n">cache_file</span><span class="p">)</span><span class="o">.</span><span class="n">as_posix</span><span class="p">(),</span> <span class="n">Path</span><span class="p">(</span><span class="n">cache_file_with_suffix_pattern</span><span class="p">)</span><span class="o">.</span><span class="n">as_posix</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">suffix_variable_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">file_num_proc</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">suffix_variable_map</span><span class="p">[</span><span class="s2">&quot;num_proc&quot;</span><span class="p">])</span>
                    <span class="n">existing_cache_file_map</span><span class="p">[</span><span class="n">file_num_proc</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cache_file</span><span class="p">)</span>

        <span class="n">num_shards</span> <span class="o">=</span> <span class="n">num_proc</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">existing_cache_file_map</span><span class="p">:</span>
            <span class="c1"># to avoid remapping when a different num_proc is given than when originally cached, update num_shards to</span>
            <span class="c1"># what was used originally</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">select_existing_cache_files</span><span class="p">(</span><span class="n">mapped_num_proc</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
                <span class="n">percent_missing</span> <span class="o">=</span> <span class="p">(</span><span class="n">mapped_num_proc</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">existing_cache_file_map</span><span class="p">[</span><span class="n">mapped_num_proc</span><span class="p">]))</span> <span class="o">/</span> <span class="n">mapped_num_proc</span>
                <span class="n">num_shards_diff</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">mapped_num_proc</span> <span class="o">-</span> <span class="n">num_shards</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">percent_missing</span><span class="p">,</span>  <span class="c1"># choose the most complete set of existing cache files</span>
                    <span class="n">num_shards_diff</span><span class="p">,</span>  <span class="c1"># then choose the mapped_num_proc closest to the current num_proc</span>
                    <span class="n">mapped_num_proc</span><span class="p">,</span>  <span class="c1"># finally, choose whichever mapped_num_proc is lower</span>
                <span class="p">)</span>

            <span class="n">num_shards</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">existing_cache_file_map</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">select_existing_cache_files</span><span class="p">)</span>

        <span class="n">existing_cache_files</span> <span class="o">=</span> <span class="n">existing_cache_file_map</span><span class="p">[</span><span class="n">num_shards</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">format_cache_file_name</span><span class="p">(</span>
            <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="n">rank</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;*&quot;</span><span class="p">]],</span>  <span class="c1"># noqa: F722</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cache_file_name</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">cache_file_name</span>

            <span class="k">assert</span> <span class="n">cache_file_prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cache_file_ext</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">cache_file_name</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">cache_file_prefix</span> <span class="o">+</span> <span class="n">suffix_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="n">num_shards</span><span class="p">)</span> <span class="o">+</span> <span class="n">cache_file_ext</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">):</span>
                    <span class="n">process_name</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="s2">&quot;Main process&quot;</span> <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">num_proc</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;Process #</span><span class="si">{</span><span class="n">rank</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">num_shards</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">process_name</span><span class="si">}</span><span class="s2"> will write at </span><span class="si">{</span><span class="n">cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># TODO: this assumes the format_spec of rank in suffix_template</span>
                <span class="n">cache_file_name</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">cache_file_prefix</span>
                    <span class="o">+</span> <span class="n">suffix_template</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{rank:05d}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{rank}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="n">num_shards</span><span class="p">)</span>
                    <span class="o">+</span> <span class="n">cache_file_ext</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">cache_file_name</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">format_new_fingerprint</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
            <span class="n">new_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span> <span class="o">+</span> <span class="n">suffix_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="n">num_shards</span><span class="p">)</span>
            <span class="n">validate_fingerprint</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">new_fingerprint</span>

        <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">prev_env</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>
            <span class="c1"># check if parallelism if off</span>
            <span class="c1"># from https://github.com/huggingface/tokenizers/blob/bb668bc439dc34389b71dbb8ce0c597f15707b53/tokenizers/src/utils/parallelism.rs#L22</span>
            <span class="k">if</span> <span class="n">prev_env</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">,</span> <span class="s2">&quot;false&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;off&quot;</span><span class="p">,</span>
                <span class="s2">&quot;false&quot;</span><span class="p">,</span>
                <span class="s2">&quot;f&quot;</span><span class="p">,</span>
                <span class="s2">&quot;no&quot;</span><span class="p">,</span>
                <span class="s2">&quot;n&quot;</span><span class="p">,</span>
                <span class="s2">&quot;0&quot;</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Setting TOKENIZERS_PARALLELISM=false for forked processes.&quot;</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prev_env</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>

        <span class="n">kwargs_per_job</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span>
        <span class="k">if</span> <span class="n">num_shards</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">shards</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span>
            <span class="n">kwargs_per_job</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset_kwargs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shards</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">kwargs_per_job</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">,</span>
                    <span class="s2">&quot;shard&quot;</span><span class="p">:</span> <span class="n">shards</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span>
                    <span class="s2">&quot;cache_file_name&quot;</span><span class="p">:</span> <span class="n">format_cache_file_name</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">,</span> <span class="n">rank</span><span class="p">),</span>
                    <span class="s2">&quot;rank&quot;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
                    <span class="s2">&quot;offset&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shards</span><span class="p">[:</span><span class="n">rank</span><span class="p">]),</span>
                    <span class="s2">&quot;new_fingerprint&quot;</span><span class="p">:</span> <span class="n">format_new_fingerprint</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">,</span> <span class="n">rank</span><span class="p">),</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">)</span>
            <span class="p">]</span>

        <span class="n">transformed_shards</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Dataset</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_shards</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">job_kwargs</span> <span class="o">=</span> <span class="n">kwargs_per_job</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">job_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">transformed_shards</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_processed_shard_from_cache</span><span class="p">(</span><span class="n">job_kwargs</span><span class="p">)</span>
                <span class="n">kwargs_per_job</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">except</span> <span class="n">NonExistentDatasetError</span><span class="p">:</span>
                <span class="k">pass</span>

        <span class="k">if</span> <span class="n">unprocessed_kwargs_per_job</span> <span class="o">:=</span> <span class="p">[</span><span class="n">kwargs</span> <span class="k">for</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="n">kwargs_per_job</span> <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unprocessed_kwargs_per_job</span><span class="p">)</span> <span class="o">!=</span> <span class="n">num_shards</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Reprocessing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">unprocessed_kwargs_per_job</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards because some of them were &quot;</span>
                    <span class="s2">&quot;missing from the cache.&quot;</span>
                <span class="p">)</span>

            <span class="n">pbar_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">pbar_initial</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">existing_cache_files</span><span class="p">)</span> <span class="o">*</span> <span class="n">pbar_total</span> <span class="o">//</span> <span class="n">num_shards</span>
            <span class="k">if</span> <span class="n">batched</span> <span class="ow">and</span> <span class="n">drop_last_batch</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="ow">or</span> <span class="mi">1</span>
                <span class="n">pbar_initial</span> <span class="o">=</span> <span class="n">pbar_initial</span> <span class="o">//</span> <span class="n">num_shards</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_shards</span> <span class="o">*</span> <span class="n">batch_size</span>
                <span class="n">pbar_total</span> <span class="o">=</span> <span class="n">pbar_total</span> <span class="o">//</span> <span class="n">num_shards</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_shards</span> <span class="o">*</span> <span class="n">batch_size</span>

            <span class="k">with</span> <span class="n">hf_tqdm</span><span class="p">(</span>
                <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; examples&quot;</span><span class="p">,</span>
                <span class="n">initial</span><span class="o">=</span><span class="n">pbar_initial</span><span class="p">,</span>
                <span class="n">total</span><span class="o">=</span><span class="n">pbar_total</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="p">(</span><span class="n">desc</span> <span class="ow">or</span> <span class="s2">&quot;Map&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot; (num_proc=</span><span class="si">{</span><span class="n">num_proc</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
                <span class="n">shards_done</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">check_if_shard_done</span><span class="p">(</span><span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">done</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">content</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dataset</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">nonlocal</span> <span class="n">shards_done</span>
                    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                        <span class="n">shards_done</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished processing shard number </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">)</span>
                        <span class="n">transformed_shards</span><span class="p">[</span><span class="n">rank</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">content</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
                        <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">num_proc</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
                        <span class="n">os</span><span class="o">.</span><span class="n">environ</span> <span class="o">=</span> <span class="n">prev_env</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Spawning </span><span class="si">{</span><span class="n">num_proc</span><span class="si">}</span><span class="s2"> processes&quot;</span><span class="p">)</span>

                        <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">iflatmap_unordered</span><span class="p">(</span>
                            <span class="n">pool</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_map_single</span><span class="p">,</span> <span class="n">kwargs_iterable</span><span class="o">=</span><span class="n">unprocessed_kwargs_per_job</span>
                        <span class="p">):</span>
                            <span class="n">check_if_shard_done</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>

                        <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                        <span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">unprocessed_kwargs</span> <span class="ow">in</span> <span class="n">unprocessed_kwargs_per_job</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_map_single</span><span class="p">(</span><span class="o">**</span><span class="n">unprocessed_kwargs</span><span class="p">):</span>
                            <span class="n">check_if_shard_done</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>

            <span class="c1"># Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)</span>
            <span class="k">for</span> <span class="n">job_kwargs</span> <span class="ow">in</span> <span class="n">unprocessed_kwargs_per_job</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;shard&quot;</span> <span class="ow">in</span> <span class="n">job_kwargs</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">job_kwargs</span><span class="p">[</span><span class="s2">&quot;shard&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading cached processed dataset at </span><span class="si">{</span><span class="n">format_cache_file_name</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;*&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">all_transformed_shards</span> <span class="o">=</span> <span class="p">[</span><span class="n">shard</span> <span class="k">for</span> <span class="n">shard</span> <span class="ow">in</span> <span class="n">transformed_shards</span> <span class="k">if</span> <span class="n">shard</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">transformed_shards</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_transformed_shards</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to retrieve results from map: result list </span><span class="si">{</span><span class="n">transformed_shards</span><span class="si">}</span><span class="s2"> still contains None - &quot;</span>
                <span class="s2">&quot;at least one worker failed to return its results&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">num_shards</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">all_transformed_shards</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Concatenating </span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards&quot;</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">_concatenate_map_style_datasets</span><span class="p">(</span><span class="n">all_transformed_shards</span><span class="p">)</span>

        <span class="c1"># update fingerprint if the dataset changed</span>
        <span class="n">result</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">new_fingerprint</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
                <span class="n">transformed_shard</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">!=</span> <span class="n">shard</span><span class="o">.</span><span class="n">_fingerprint</span>
                <span class="k">for</span> <span class="n">transformed_shard</span><span class="p">,</span> <span class="n">shard</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">all_transformed_shards</span><span class="p">,</span> <span class="n">shards</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fingerprint</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span></div>


    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_map_single</span><span class="p">(</span>
        <span class="n">shard</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span>
        <span class="n">function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">with_indices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">with_rank</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">input_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">drop_last_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">disable_nullable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">try_original_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply a function to all the elements in the table (individually or in batches)</span>
<span class="sd">        and update the table (if function does update examples).</span>

<span class="sd">        Args:</span>
<span class="sd">            shard (`datasets.Dataset`): Dataset to map the transform on.</span>
<span class="sd">            function (`Callable`): with one of the following signature:</span>
<span class="sd">                - `function(example: Dict[str, Any]) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(example: Dict[str, Any], *extra_args) -&gt; Dict[str, Any]` if `batched=False` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>
<span class="sd">                - `function(batch: Dict[str, List]) -&gt; Dict[str, List]` if `batched=True` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(batch: Dict[str, List], *extra_args) -&gt; Dict[str, List]` if `batched=True` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>

<span class="sd">                For advanced usage, the function can also return a `pyarrow.Table`.</span>
<span class="sd">                Moreover if your function returns nothing (`None`), then `map` will run your function and return the dataset unchanged.</span>
<span class="sd">                If no function is provided, default to identity function: lambda x: x</span>
<span class="sd">            with_indices (`bool`, defaults to `False`): Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx[, rank]): ...`.</span>
<span class="sd">            with_rank (`bool`, default `False`): Provide process rank to `function`. Note that in this case the signature of `function` should be `def function(example[, idx], rank): ...`.</span>
<span class="sd">            input_columns (`Optional[List[str]]`, defaults to `None`): The columns to be passed into `function` as</span>
<span class="sd">                positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.</span>
<span class="sd">            batched (`bool`, defaults to `False`): Provide batch of examples to `function`</span>
<span class="sd">            batch_size (`int`, optional, defaults to `1000`): Number of examples per batch provided to `function` if `batched=True`</span>
<span class="sd">                `batch_size &lt;= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`</span>
<span class="sd">            drop_last_batch (`bool`, default: `False`): Whether a last batch smaller than the batch_size should be</span>
<span class="sd">                dropped instead of being processed by the function.</span>
<span class="sd">            remove_columns (`Optional[List[str]]`, defaults to `None`): Remove a selection of columns while doing the mapping.</span>
<span class="sd">                Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding</span>
<span class="sd">                columns with names in `remove_columns`, these columns will be kept.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`): Keep the dataset in memory instead of writing it to a cache file.</span>
<span class="sd">            cache_file_name (`str`, optional, defaults to `None`): Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                results of the computation instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, default `1000`): Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `.map()`.</span>
<span class="sd">            features (`Optional[datasets.Features]`, defaults to `None`): Use a specific Features to store the cache file</span>
<span class="sd">                instead of the automatically generated one.</span>
<span class="sd">            disable_nullable (`bool`, defaults to `False`): Disallow null values in the table.</span>
<span class="sd">            fn_kwargs (`Dict`, optional, defaults to `None`): Keyword arguments to be passed to `function`</span>
<span class="sd">            new_fingerprint (`str`, optional, defaults to `None`): the new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>
<span class="sd">            rank: (`int`, optional, defaults to `None`): If specified, this is the process rank when doing multiprocessing</span>
<span class="sd">            offset: (`int`, defaults to 0): If specified, this is an offset applied to the indices passed to `function` if `with_indices=True`.</span>
<span class="sd">            try_original_type: (`Optional[bool]`, defaults to `True`):</span>
<span class="sd">                Try to keep the types of the original columns (e.g. int32 -&gt; int32).</span>
<span class="sd">                Set to False if you want to always infer new types.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">fn_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fn_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># If we do batch computation but no batch size is provided, default to the full dataset</span>
        <span class="k">if</span> <span class="n">batched</span> <span class="ow">and</span> <span class="p">(</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">num_rows</span>

        <span class="c1"># We set this variable to True after processing the first example/batch in</span>
        <span class="c1"># `apply_function_on_filtered_inputs` if the map function returns a dict.</span>
        <span class="c1"># If set to False, no new arrow table will be created</span>

        <span class="n">update_data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">format_kwargs</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">_format_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Lazy formatting is only available for the default format (None/python)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">input_columns</span> <span class="ow">and</span> <span class="n">shard</span><span class="o">.</span><span class="n">_format_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">format_kwargs</span><span class="p">[</span><span class="s2">&quot;lazy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">input_formatter</span> <span class="o">=</span> <span class="n">get_formatter</span><span class="p">(</span>
            <span class="n">shard</span><span class="o">.</span><span class="n">_format_type</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">shard</span><span class="o">.</span><span class="n">features</span><span class="p">,</span>
            <span class="o">**</span><span class="n">format_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">check_same_num_examples</span> <span class="o">=</span> <span class="n">batched</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">validate_function_output</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Validate output of the map function.&quot;&quot;&quot;</span>
            <span class="n">allowed_processed_inputs_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;polars&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>

                <span class="n">allowed_processed_inputs_types</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,)</span>
            <span class="k">if</span> <span class="n">processed_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">,</span> <span class="n">allowed_processed_inputs_types</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Provided `function` which is applied to all elements of table returns a variable of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">batched</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
                <span class="n">allowed_batch_return_types</span> <span class="o">=</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;polars&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>

                    <span class="n">allowed_batch_return_types</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">TF_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;tensorflow&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>

                    <span class="n">allowed_batch_return_types</span> <span class="o">+=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">TORCH_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

                    <span class="n">allowed_batch_return_types</span> <span class="o">+=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">JAX_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;jax&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

                    <span class="n">allowed_batch_return_types</span> <span class="o">+=</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,)</span>
                <span class="n">all_dict_values_are_lists</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">allowed_batch_return_types</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">all_dict_values_are_lists</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Provided `function` which is applied to all elements of table returns a `dict` of types </span><span class="si">{</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">processed_inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span><span class="si">}</span><span class="s2">. When using `batched=True`, make sure provided `function` returns a `dict` of types like `</span><span class="si">{</span><span class="n">allowed_batch_return_types</span><span class="si">}</span><span class="s2">`.&quot;</span>
                    <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">prepare_inputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Utility to apply the function on a selection of columns.&quot;&quot;&quot;</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">format_table</span><span class="p">(</span>
                <span class="n">pa_inputs</span><span class="p">,</span>
                <span class="mi">0</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">batched</span> <span class="k">else</span> <span class="nb">range</span><span class="p">(</span><span class="n">pa_inputs</span><span class="o">.</span><span class="n">num_rows</span><span class="p">),</span>
                <span class="n">format_columns</span><span class="o">=</span><span class="n">input_columns</span><span class="p">,</span>
                <span class="n">formatter</span><span class="o">=</span><span class="n">input_formatter</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">fn_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span> <span class="k">if</span> <span class="n">input_columns</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">inputs</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">input_columns</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">effective_indices</span> <span class="o">=</span> <span class="n">indices</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">effective_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">indices</span> <span class="o">+</span> <span class="n">offset</span>
            <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
            <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
                <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">effective_indices</span><span class="p">,)</span>
            <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
                <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
            <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">fn_args</span><span class="p">,</span> <span class="n">additional_args</span><span class="p">,</span> <span class="n">fn_kwargs</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">prepare_outputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">processed_inputs</span><span class="p">):</span>
            <span class="k">nonlocal</span> <span class="n">update_data</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">update_data</span> <span class="o">:=</span> <span class="p">(</span><span class="n">processed_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">,</span> <span class="n">LazyDict</span><span class="p">):</span>
                <span class="n">processed_inputs</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="o">.</span><span class="n">keys_to_format</span>
                <span class="p">}</span>
                <span class="n">returned_lazy_dict</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">returned_lazy_dict</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">validate_function_output</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">shard</span><span class="o">.</span><span class="n">_format_type</span> <span class="ow">or</span> <span class="n">input_columns</span><span class="p">:</span>
                <span class="c1"># TODO(QL, MS): ideally the behavior should be the same even if the dataset is formatted (may require major release)</span>
                <span class="n">inputs_to_merge</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">pa_inputs</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="n">pa_inputs</span><span class="o">.</span><span class="n">itercolumns</span><span class="p">()))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">LazyDict</span><span class="p">):</span>
                <span class="n">inputs_to_merge</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">k</span><span class="p">:</span> <span class="p">(</span><span class="n">v</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">keys_to_format</span> <span class="k">else</span> <span class="n">pa_inputs</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inputs_to_merge</span> <span class="o">=</span> <span class="n">inputs</span>
            <span class="k">if</span> <span class="n">remove_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">remove_columns</span><span class="p">:</span>
                    <span class="c1"># `function` can modify input in-place causing column to be already removed.</span>
                    <span class="k">if</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">inputs_to_merge</span><span class="p">:</span>
                        <span class="n">inputs_to_merge</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">returned_lazy_dict</span> <span class="ow">and</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="p">:</span>
                        <span class="n">processed_inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">check_same_num_examples</span><span class="p">:</span>
                <span class="n">input_num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">)</span>
                <span class="n">processed_inputs_num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">processed_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">()))])</span>
                <span class="k">if</span> <span class="n">input_num_examples</span> <span class="o">!=</span> <span class="n">processed_inputs_num_examples</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                        <span class="s2">&quot;Using `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn&#39;t create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
                    <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processed_inputs</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
                <span class="c1"># The .map() transform *updates* the dataset:</span>
                <span class="c1"># the output dictionary contains both the the input data and the output data.</span>
                <span class="c1"># The output dictionary may contain Arrow values from `inputs_to_merge` so that we can re-write them efficiently.</span>
                <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">inputs_to_merge</span><span class="p">,</span> <span class="o">**</span><span class="n">processed_inputs</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">processed_inputs</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">apply_function</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Utility to apply the function on a selection of columns.&quot;&quot;&quot;</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">fn_args</span><span class="p">,</span> <span class="n">additional_args</span><span class="p">,</span> <span class="n">fn_kwargs</span> <span class="o">=</span> <span class="n">prepare_inputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>
            <span class="n">processed_inputs</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">fn_args</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">prepare_outputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">processed_inputs</span><span class="p">)</span>

        <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">async_apply_function</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Utility to apply the function on a selection of columns. Same code but async&quot;&quot;&quot;</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">fn_args</span><span class="p">,</span> <span class="n">additional_args</span><span class="p">,</span> <span class="n">fn_kwargs</span> <span class="o">=</span> <span class="n">prepare_inputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>
            <span class="n">processed_inputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">fn_args</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">prepare_outputs</span><span class="p">(</span><span class="n">pa_inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">processed_inputs</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">init_buffer_and_writer</span><span class="p">():</span>
            <span class="c1"># Prepare output buffer and batched writer in memory or on file if we update the table</span>
            <span class="n">writer_features</span> <span class="o">=</span> <span class="n">features</span>
            <span class="k">if</span> <span class="n">writer_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">writer_features</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">features</span>
                <span class="n">update_features</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">update_features</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">or</span> <span class="n">cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">buf_writer</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">BufferOutputStream</span><span class="p">()</span>
                <span class="n">tmp_file</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">writer</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="p">(</span>
                    <span class="n">features</span><span class="o">=</span><span class="n">writer_features</span><span class="p">,</span>
                    <span class="n">stream</span><span class="o">=</span><span class="n">buf_writer</span><span class="p">,</span>
                    <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
                    <span class="n">update_features</span><span class="o">=</span><span class="n">update_features</span><span class="p">,</span>
                    <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
                    <span class="n">disable_nullable</span><span class="o">=</span><span class="n">disable_nullable</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">buf_writer</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Caching processed dataset at </span><span class="si">{</span><span class="n">cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">tmp_file</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="s2">&quot;wb&quot;</span><span class="p">,</span> <span class="nb">dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">writer</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="p">(</span>
                    <span class="n">features</span><span class="o">=</span><span class="n">writer_features</span><span class="p">,</span>
                    <span class="n">path</span><span class="o">=</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
                    <span class="n">update_features</span><span class="o">=</span><span class="n">update_features</span><span class="p">,</span>
                    <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
                    <span class="n">disable_nullable</span><span class="o">=</span><span class="n">disable_nullable</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">buf_writer</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">tmp_file</span>

        <span class="n">tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">asyncio</span><span class="o">.</span><span class="n">Task</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">iscoroutinefunction</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_running_loop</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">new_event_loop</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loop</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">iter_outputs</span><span class="p">(</span><span class="n">shard_iterable</span><span class="p">):</span>
            <span class="k">nonlocal</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">loop</span>
            <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">iscoroutinefunction</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
                <span class="n">indices</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">shard_iterable</span><span class="p">:</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loop</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">async_apply_function</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">)))</span>
                    <span class="c1"># keep the total active tasks under a certain number</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">MAX_NUM_RUNNING_ASYNC_MAP_FUNCTIONS_IN_PARALLEL</span><span class="p">:</span>
                        <span class="n">done</span><span class="p">,</span> <span class="n">pending</span> <span class="o">=</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
                            <span class="n">asyncio</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">return_when</span><span class="o">=</span><span class="n">asyncio</span><span class="o">.</span><span class="n">FIRST_COMPLETED</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">while</span> <span class="n">tasks</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pending</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">MAX_NUM_RUNNING_ASYNC_MAP_FUNCTIONS_IN_PARALLEL</span><span class="p">:</span>
                            <span class="n">done</span><span class="p">,</span> <span class="n">pending</span> <span class="o">=</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
                                <span class="n">asyncio</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">return_when</span><span class="o">=</span><span class="n">asyncio</span><span class="o">.</span><span class="n">FIRST_COMPLETED</span><span class="p">)</span>
                            <span class="p">)</span>
                    <span class="c1"># yield finished tasks</span>
                    <span class="k">while</span> <span class="n">tasks</span> <span class="ow">and</span> <span class="n">tasks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">done</span><span class="p">():</span>
                        <span class="k">yield</span> <span class="n">indices</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="k">while</span> <span class="n">tasks</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span><span class="n">tasks</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">indices</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">shard_iterable</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">i</span><span class="p">,</span> <span class="n">apply_function</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>

        <span class="n">num_examples_progress_update</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># If `update_data` is True after processing the first example/batch, initialize these resources with `init_buffer_and_writer`</span>
        <span class="n">buf_writer</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">tmp_file</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="c1"># Check if Polars is available and import it if so</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;polars&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>

        <span class="c1"># Optionally initialize the writer as a context manager</span>
        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">ExitStack</span><span class="p">()</span> <span class="k">as</span> <span class="n">stack</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">arrow_formatted_shard</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span>

                <span class="c1"># Loop over single examples or batches and write to buffer/file if examples are to be updated</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">batched</span><span class="p">:</span>
                    <span class="n">shard_iterable</span> <span class="o">=</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">arrow_formatted_shard</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">drop_last_batch</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">shard</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">batch_size</span>
                    <span class="n">shard_iterable</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
                        <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">)))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)),</span>
                        <span class="n">arrow_formatted_shard</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_last_batch</span><span class="o">=</span><span class="n">drop_last_batch</span><span class="p">),</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">batched</span><span class="p">:</span>
                    <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">iter_outputs</span><span class="p">(</span><span class="n">shard_iterable</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">update_data</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">buf_writer</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">tmp_file</span> <span class="o">=</span> <span class="n">init_buffer_and_writer</span><span class="p">()</span>
                                <span class="n">stack</span><span class="o">.</span><span class="n">enter_context</span><span class="p">(</span><span class="n">writer</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_row</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
                            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_row</span><span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">example</span><span class="p">))</span>
                            <span class="k">elif</span> <span class="p">(</span>
                                <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span>
                                <span class="ow">and</span> <span class="s2">&quot;polars&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>
                                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
                            <span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_row</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">())</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
                        <span class="n">num_examples_progress_update</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">_time</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">PBAR_REFRESH_TIME_INTERVAL</span><span class="p">:</span>
                            <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                            <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
                            <span class="n">num_examples_progress_update</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">iter_outputs</span><span class="p">(</span><span class="n">shard_iterable</span><span class="p">):</span>
                        <span class="n">num_examples_in_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">update_data</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">i</span> <span class="ow">and</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">buf_writer</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">tmp_file</span> <span class="o">=</span> <span class="n">init_buffer_and_writer</span><span class="p">()</span>
                                <span class="n">stack</span><span class="o">.</span><span class="n">enter_context</span><span class="p">(</span><span class="n">writer</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
                            <span class="k">elif</span> <span class="p">(</span>
                                <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span> <span class="ow">and</span> <span class="s2">&quot;polars&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
                            <span class="p">):</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">())</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">writer</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">try_original_type</span><span class="o">=</span><span class="n">try_original_type</span><span class="p">)</span>
                        <span class="n">num_examples_progress_update</span> <span class="o">+=</span> <span class="n">num_examples_in_batch</span>
                        <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">_time</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">PBAR_REFRESH_TIME_INTERVAL</span><span class="p">:</span>
                            <span class="n">_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                            <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
                            <span class="n">num_examples_progress_update</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="n">update_data</span> <span class="ow">and</span> <span class="n">writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">writer</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>  <span class="c1"># close_stream=bool(buf_writer is None))  # We only close if we are writing in a file</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">Exception</span><span class="p">,</span> <span class="ne">KeyboardInterrupt</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
                <span class="k">if</span> <span class="n">update_data</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">writer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">writer</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">tmp_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">tmp_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">loop</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Canceling </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">)</span><span class="si">}</span><span class="s2"> async tasks.&quot;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
                        <span class="n">task</span><span class="o">.</span><span class="n">cancel</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;KeyboardInterrupt&quot;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span><span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">))</span>
                    <span class="k">except</span> <span class="p">(</span><span class="n">asyncio</span><span class="o">.</span><span class="n">CancelledError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Tasks canceled.&quot;</span><span class="p">)</span>
                <span class="k">raise</span>

        <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">num_examples_progress_update</span>
        <span class="k">if</span> <span class="n">update_data</span> <span class="ow">and</span> <span class="n">tmp_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tmp_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">cache_file_name</span><span class="p">)</span>
            <span class="n">umask</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">umask</span><span class="p">(</span><span class="mo">0o666</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">umask</span><span class="p">(</span><span class="n">umask</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">,</span> <span class="mo">0o666</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">umask</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">update_data</span><span class="p">:</span>
            <span class="c1"># Create new Dataset from buffer or file</span>
            <span class="n">info</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">info</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">writer</span><span class="o">.</span><span class="n">_features</span>
            <span class="k">if</span> <span class="n">buf_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">cache_file_name</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">shard</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_buffer</span><span class="p">(</span><span class="n">buf_writer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">(),</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">shard</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">rank</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">shard</span>

<div class="viewcode-block" id="Dataset.batch">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.batch.html#datasets.Dataset.batch">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">drop_last_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Group samples from the dataset into batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int`):</span>
<span class="sd">                The number of samples in each batch.</span>
<span class="sd">            drop_last_batch (`bool`, defaults to `False`):</span>
<span class="sd">                Whether to drop the last incomplete batch.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Max number of processes when generating cache. Already cached shards are loaded sequentially.</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]: A new Dataset where each item is a batch of multiple samples from the original dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; batched_ds = ds.batch(batch_size=4)</span>
<span class="sd">        &gt;&gt;&gt; batched_ds[0]</span>
<span class="sd">        {&#39;text&#39;: [&#39;compassionately explores the seemingly irreconcilable situation...&#39;, ...],  # 4 items</span>
<span class="sd">        &#39;label&#39;: [1, 1, 1, 1]}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">batch_fn</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">example</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">batch_fn</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">drop_last_batch</span><span class="o">=</span><span class="n">drop_last_batch</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Batching examples&quot;</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.filter">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.filter.html#datasets.Dataset.filter">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span>
        <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;load_from_cache_file&quot;</span><span class="p">,</span> <span class="s2">&quot;cache_file_name&quot;</span><span class="p">,</span> <span class="s2">&quot;desc&quot;</span><span class="p">],</span> <span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.0.1&quot;</span>
    <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">with_indices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">with_rank</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">input_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">suffix_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;_</span><span class="si">{rank:05d}</span><span class="s2">_of_</span><span class="si">{num_proc:05d}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply a filter function to all the elements in the table in batches</span>
<span class="sd">        and update the table so that the dataset only includes examples according to the filter function.</span>

<span class="sd">        If the function is asynchronous, then `filter` will run your function in parallel, with up to one thousand simultaneous calls (configurable).</span>
<span class="sd">        It is recommended to use a `asyncio.Semaphore` in your function if you want to set a maximum number of operations that can run at the same time.</span>

<span class="sd">        Args:</span>
<span class="sd">            function (`Callable`): Callable with one of the following signatures:</span>

<span class="sd">                - `function(example: Dict[str, Any]) -&gt; bool` if `batched=False` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(example: Dict[str, Any], *extra_args) -&gt; bool` if `batched=False` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>
<span class="sd">                - `function(batch: Dict[str, List]) -&gt; List[bool]` if `batched=True` and `with_indices=False` and `with_rank=False`</span>
<span class="sd">                - `function(batch: Dict[str, List], *extra_args) -&gt; List[bool]` if `batched=True` and `with_indices=True` and/or `with_rank=True` (one extra arg for each)</span>

<span class="sd">                If the function is asynchronous, then `filter` will run your function in parallel.</span>
<span class="sd">                If no function is provided, defaults to an always `True` function: `lambda x: True`.</span>
<span class="sd">            with_indices (`bool`, defaults to `False`):</span>
<span class="sd">                Provide example indices to `function`. Note that in this case the</span>
<span class="sd">                signature of `function` should be `def function(example, idx[, rank]): ...`.</span>
<span class="sd">            with_rank (`bool`, defaults to `False`):</span>
<span class="sd">                Provide process rank to `function`. Note that in this case the</span>
<span class="sd">                signature of `function` should be `def function(example[, idx], rank): ...`.</span>
<span class="sd">            input_columns (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The columns to be passed into `function` as</span>
<span class="sd">                positional arguments. If `None`, a `dict` mapping to all formatted columns is passed as one argument.</span>
<span class="sd">            batched (`bool`, defaults to `False`):</span>
<span class="sd">                Provide batch of examples to `function`.</span>
<span class="sd">            batch_size (`int`, *optional*, defaults to `1000`):</span>
<span class="sd">                Number of examples per batch provided to `function` if</span>
<span class="sd">                `batched = True`. If `batched = False`, one example per batch is passed to `function`.</span>
<span class="sd">                If `batch_size &lt;= 0` or `batch_size == None`, provide the full dataset as a single batch to `function`.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the dataset in memory instead of writing it to a cache file.</span>
<span class="sd">            load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the current computation from `function`</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            cache_file_name (`str`, *optional*):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                results of the computation instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            fn_kwargs (`dict`, *optional*):</span>
<span class="sd">                Keyword arguments to be passed to `function`.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                 The number of processes to use for multiprocessing.</span>
<span class="sd">                - If `None` or `0`, no multiprocessing is used and the operation runs in the main process.</span>
<span class="sd">                - If greater than `1`, one or multiple worker processes are used to process data in parallel.</span>
<span class="sd">                 Note: The function passed to `map()` must be picklable for multiprocessing to work correctly</span>
<span class="sd">                 (i.e., prefer functions defined at the top level of a module, not inside another function or class).</span>
<span class="sd">            suffix_template (`str`):</span>
<span class="sd">                If `cache_file_name` is specified, then this suffix will be added at the end of the base name of each.</span>
<span class="sd">                For example, if `cache_file_name` is `&quot;processed.arrow&quot;`, then for `rank = 1` and `num_proc = 4`,</span>
<span class="sd">                the resulting file would be `&quot;processed_00001_of_00004.arrow&quot;` for the default suffix (default</span>
<span class="sd">                `_{rank:05d}_of_{num_proc:05d}`).</span>
<span class="sd">            new_fingerprint (`str`, *optional*):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>
<span class="sd">            desc (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Meaningful description to be displayed alongside with the progress bar while filtering examples.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.filter(lambda x: x[&quot;label&quot;] == 1)</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 533</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.filter` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.`&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="kc">True</span>  <span class="c1"># noqa: E731</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># We generally batch the underlying map() to get faster throughput,</span>
        <span class="c1"># but in case of async we force batch_size=1 to enable parallelism</span>
        <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">iscoroutinefunction</span><span class="p">(</span><span class="n">function</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">batched</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">function</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                <span class="n">async_get_indices_from_mask_function</span>
                <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">iscoroutinefunction</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">get_indices_from_mask_function</span><span class="p">,</span>
                <span class="n">function</span><span class="p">,</span>
                <span class="n">batched</span><span class="p">,</span>
                <span class="n">with_indices</span><span class="p">,</span>
                <span class="n">with_rank</span><span class="p">,</span>
                <span class="n">input_columns</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">with_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">with_rank</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">Features</span><span class="p">({</span><span class="s2">&quot;indices&quot;</span><span class="p">:</span> <span class="n">Value</span><span class="p">(</span><span class="s2">&quot;uint64&quot;</span><span class="p">)}),</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">load_from_cache_file</span><span class="o">=</span><span class="n">load_from_cache_file</span><span class="p">,</span>
            <span class="n">cache_file_name</span><span class="o">=</span><span class="n">cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">suffix_template</span><span class="o">=</span><span class="n">suffix_template</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
            <span class="n">input_columns</span><span class="o">=</span><span class="n">input_columns</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="n">desc</span> <span class="ow">or</span> <span class="s2">&quot;Filter&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">new_dataset</span><span class="o">.</span><span class="n">_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">data</span>
        <span class="n">new_dataset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="o">=</span> <span class="n">new_fingerprint</span>
        <span class="k">return</span> <span class="n">new_dataset</span></div>


<div class="viewcode-block" id="Dataset.flatten_indices">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.flatten_indices">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;cache_file_name&quot;</span><span class="p">])</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">flatten_indices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Features</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">disable_nullable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create and cache a new Dataset by flattening the indices mapping.</span>

<span class="sd">        Args:</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the dataset in memory instead of writing it to a cache file.</span>
<span class="sd">            cache_file_name (`str`, *optional*, default `None`):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                results of the computation instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            features (`Optional[datasets.Features]`, defaults to `None`):</span>
<span class="sd">                Use a specific [`Features`] to store the cache file</span>
<span class="sd">                instead of the automatically generated one.</span>
<span class="sd">            disable_nullable (`bool`, defaults to `False`):</span>
<span class="sd">                Allow null values in the table.</span>
<span class="sd">            num_proc (`int`, optional, default `None`):</span>
<span class="sd">                Max number of processes when generating cache. Already cached shards are loaded sequentially</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># for speed</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">cache_file_name</span><span class="o">=</span><span class="n">cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">disable_nullable</span><span class="o">=</span><span class="n">disable_nullable</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Flattening the indices&quot;</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_new_dataset_with_indices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_buffer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pa</span><span class="o">.</span><span class="n">Buffer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a new Dataset obtained by adding indices (provided in indices_cache_file_name or in a buffer) to the</span>
<span class="sd">        current Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">indices_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one of indices_cache_file_name or indices_buffer must be provided.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fingerprint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;please specify a fingerprint for the dataset with indices&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="n">MemoryMappedTable</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">indices_cache_file_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_buffer</span><span class="p">(</span><span class="n">indices_buffer</span><span class="p">)</span>

        <span class="c1"># Return new Dataset object</span>
        <span class="c1"># don&#39;t forget to copy the objects</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
            <span class="n">info</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
            <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
            <span class="n">indices_table</span><span class="o">=</span><span class="n">indices_table</span><span class="p">,</span>
            <span class="n">fingerprint</span><span class="o">=</span><span class="n">fingerprint</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Dataset.select">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.select.html#datasets.Dataset.select">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;indices_cache_file_name&quot;</span><span class="p">])</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">select</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new dataset with rows selected following the list/array of indices.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices (`range`, `list`, `iterable`, `ndarray` or `Series`):</span>
<span class="sd">                Range, list or 1D-array of integer indices for indexing.</span>
<span class="sd">                If the indices correspond to a contiguous range, the Arrow table is simply sliced.</span>
<span class="sd">                However passing a list of indices that are not contiguous creates indices mapping, which is much less efficient,</span>
<span class="sd">                but still faster than recreating an Arrow table made of the requested rows.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the indices mapping in memory instead of writing it to a cache file.</span>
<span class="sd">            indices_cache_file_name (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                indices mapping instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.select(range(4))</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 4</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">and</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use either `keep_in_memory` or `indices_cache_file_name` but not both.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.select` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># If indices is a PyArrow array, we convert to NumPy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">ChunkedArray</span><span class="p">)):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="c1"># Convert generator objects to lists</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="c1"># If the indices are contiguous, simply slice the arrow table</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">range</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">_is_range_contiguous</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="ow">and</span> <span class="n">indices</span><span class="o">.</span><span class="n">start</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">start</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">stop</span> <span class="o">-</span> <span class="n">indices</span><span class="o">.</span><span class="n">start</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_contiguous</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">start</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="c1"># if `indices` is an empty iterable, we return an empty dataset</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_contiguous</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">counter_from_start</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">counter_from_start</span><span class="p">)):</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">counter_from_start</span><span class="p">)</span> <span class="o">-</span> <span class="n">start</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_contiguous</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span>

        <span class="c1"># If not contiguous, we need to create a new indices mapping</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_with_indices_mapping</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_select_contiguous</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new dataset with rows from a contiguous slice of data.</span>
<span class="sd">        The slice is defined by that start index and its length.</span>

<span class="sd">        Args:</span>
<span class="sd">            start (`int`): start index.</span>
<span class="sd">            length (`int`): length of the slice to select.</span>
<span class="sd">            new_fingerprint (`str`, optional, default `None`): the new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds._select_contiguous(0, 4)</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 4</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.select` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="n">_check_valid_indices_value</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">_check_valid_indices_value</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">),</span>
                <span class="n">info</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                <span class="n">info</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                <span class="n">indices_table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">),</span>
                <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;indices_cache_file_name&quot;</span><span class="p">])</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_select_with_indices_mapping</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new dataset with rows selected following the list/array of indices.</span>
<span class="sd">        The new dataset is made by creating a new indices mapping on top of the main arrow table.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices (sequence, iterable, range, ndarray or Series): List or 1D-array of integer indices for indexing.</span>
<span class="sd">            keep_in_memory (`bool`, default `False`): Keep the indices mapping in memory instead of writing it to a cache file.</span>
<span class="sd">            indices_cache_file_name (`str`, optional, default `None`): Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                indices mapping instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, default `1000`): Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `.map()`.</span>
<span class="sd">            new_fingerprint (`str`, optional, default `None`): the new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds._select_with_indices_mapping(range(4))</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 4</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">and</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use either `keep_in_memory` or `indices_cache_file_name` but not both.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.select` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># Prepare the writer for our indices arrow table</span>
        <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">or</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">buf_writer</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">BufferOutputStream</span><span class="p">()</span>
            <span class="n">tmp_file</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="p">(</span>
                <span class="n">stream</span><span class="o">=</span><span class="n">buf_writer</span><span class="p">,</span> <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span> <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;indices&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">buf_writer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Caching indices mapping at </span><span class="si">{</span><span class="n">indices_cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">indices_cache_file_name</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">tmp_file</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="s2">&quot;wb&quot;</span><span class="p">,</span> <span class="nb">dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">ArrowWriter</span><span class="p">(</span>
                <span class="n">path</span><span class="o">=</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span> <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;indices&quot;</span>
            <span class="p">)</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">:</span>
            <span class="n">_check_valid_indices_value</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">indices</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">_check_valid_indices_value</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">indices</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_contiguous</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span>

        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">uint64</span><span class="p">())</span>
        <span class="c1"># Check if we need to convert indices</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">indices_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices_array</span><span class="p">)</span>

        <span class="n">indices_table</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">([</span><span class="n">indices_array</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">])</span>

        <span class="k">with</span> <span class="n">writer</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">indices_table</span><span class="p">)</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>  <span class="c1"># close_stream=bool(buf_writer is None))  We only close if we are writing in a file</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">Exception</span><span class="p">,</span> <span class="ne">KeyboardInterrupt</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">tmp_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tmp_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="k">raise</span>

        <span class="k">if</span> <span class="n">tmp_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tmp_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">tmp_file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">indices_cache_file_name</span><span class="p">)</span>
            <span class="n">umask</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">umask</span><span class="p">(</span><span class="mo">0o666</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">umask</span><span class="p">(</span><span class="n">umask</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="n">indices_cache_file_name</span><span class="p">,</span> <span class="mo">0o666</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">umask</span><span class="p">)</span>

        <span class="c1"># Return new Dataset object</span>
        <span class="k">if</span> <span class="n">buf_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span>
                <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span><span class="p">,</span> <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span><span class="n">indices_buffer</span><span class="o">=</span><span class="n">buf_writer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">(),</span> <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.skip">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.skip">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">skip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new [`Dataset`] that skips the first `n` elements.</span>

<span class="sd">        Args:</span>
<span class="sd">            n (`int`):</span>
<span class="sd">                Number of elements to skip.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; list(ds.take(3))</span>
<span class="sd">        [{&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the rock is destined to be the 21st century\&#39;s new &quot; conan &quot; and that he\&#39;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\&#39;s expanded vision of j . r . r . tolkien\&#39;s middle-earth .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1, &#39;text&#39;: &#39;effective but too-tepid biopic&#39;}]</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.skip(1)</span>
<span class="sd">        &gt;&gt;&gt; list(ds.take(3))</span>
<span class="sd">        [{&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\&#39;s expanded vision of j . r . r . tolkien\&#39;s middle-earth .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1, &#39;text&#39;: &#39;effective but too-tepid biopic&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;if you sometimes like to go to the movies to have fun , wasabi is a good place to start .&#39;}]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)))</span></div>


<div class="viewcode-block" id="Dataset.repeat">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.repeat">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_times</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new [`Dataset`] that repeats the underlying dataset `num_times` times.</span>

<span class="sd">        Like itertools.repeat, repeating once just returns the full dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_times (`int`):</span>
<span class="sd">                Number of times to repeat the dataset.</span>

<span class="sd">        Example:</span>
<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.take(2).repeat(2)</span>
<span class="sd">        &gt;&gt;&gt; list(ds)</span>
<span class="sd">        [{&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the rock is destined to be the 21st century\&#39;s new &quot; conan &quot; and that he\&#39;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\&#39;s expanded vision of j . r . r . tolkien\&#39;s middle-earth .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1, &#39;text&#39;: &#39;effective but too-tepid biopic&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the rock is destined to be the 21st century\&#39;s new &quot; conan &quot; and that he\&#39;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\&#39;s expanded vision of j . r . r . tolkien\&#39;s middle-earth .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1, &#39;text&#39;: &#39;effective but too-tepid biopic&#39;}]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_times</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Map style datasets do not support indefinite repetition.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_concatenate_map_style_datasets</span><span class="p">([</span><span class="bp">self</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_times</span><span class="p">)</span> <span class="k">if</span> <span class="n">num_times</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">([])</span></div>


<div class="viewcode-block" id="Dataset.take">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.take">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new [`Dataset`] with only the first `n` elements.</span>

<span class="sd">        Args:</span>
<span class="sd">            n (`int`):</span>
<span class="sd">                Number of elements to take.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; small_ds = ds.take(2)</span>
<span class="sd">        &gt;&gt;&gt; list(small_ds)</span>
<span class="sd">        [{&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the rock is destined to be the 21st century\&#39;s new &quot; conan &quot; and that he\&#39;s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .&#39;},</span>
<span class="sd">         {&#39;label&#39;: 1,</span>
<span class="sd">         &#39;text&#39;: &#39;the gorgeously elaborate continuation of &quot; the lord of the rings &quot; trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\&#39;s expanded vision of j . r . r . tolkien\&#39;s middle-earth .&#39;}]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span></div>


<div class="viewcode-block" id="Dataset.sort">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.sort.html#datasets.Dataset.sort">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;load_from_cache_file&quot;</span><span class="p">,</span> <span class="s2">&quot;indices_cache_file_name&quot;</span><span class="p">])</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sort</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">column_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence_</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">reverse</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Sequence_</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">null_placement</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;at_end&quot;</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new dataset sorted according to a single or multiple columns.</span>

<span class="sd">        Args:</span>
<span class="sd">            column_names (`Union[str, Sequence[str]]`):</span>
<span class="sd">                Column name(s) to sort by.</span>
<span class="sd">            reverse (`Union[bool, Sequence[bool]]`, defaults to `False`):</span>
<span class="sd">                If `True`, sort by descending order rather than ascending. If a single bool is provided,</span>
<span class="sd">                the value is applied to the sorting of all column names. Otherwise a list of bools with the</span>
<span class="sd">                same length and order as column_names must be provided.</span>
<span class="sd">            null_placement (`str`, defaults to `at_end`):</span>
<span class="sd">                Put `None` values at the beginning if `at_start` or `first` or at the end if `at_end` or `last`</span>

<span class="sd">                &lt;Added version=&quot;1.14.2&quot;/&gt;</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the sorted indices in memory instead of writing it to a cache file.</span>
<span class="sd">            load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the sorted indices</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            indices_cache_file_name (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                sorted indices instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                Higher value gives smaller cache files, lower value consume less temporary memory.</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&#39;cornell-movie-review-data/rotten_tomatoes&#39;, split=&#39;validation&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds[&#39;label&#39;][:10]</span>
<span class="sd">        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>
<span class="sd">        &gt;&gt;&gt; sorted_ds = ds.sort(&#39;label&#39;)</span>
<span class="sd">        &gt;&gt;&gt; sorted_ds[&#39;label&#39;][:10]</span>
<span class="sd">        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span>
<span class="sd">        &gt;&gt;&gt; another_sorted_ds = ds.sort([&#39;label&#39;, &#39;text&#39;], reverse=[True, False])</span>
<span class="sd">        &gt;&gt;&gt; another_sorted_ds[&#39;label&#39;][:10]</span>
<span class="sd">        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.sort` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># Check proper format of and for duplicates in column_names</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">column_names</span><span class="p">]</span>

        <span class="c1"># Check proper format and length of reverse</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reverse</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_names</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Parameter &#39;reverse&#39; should be either a boolean or a list of booleans with the same length as &#39;column_names&#39;.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reverse</span> <span class="o">=</span> <span class="p">[</span><span class="n">reverse</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>

        <span class="c1"># Check whether column name(s) exist in dataset</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">&#39; not found in the dataset. Please provide a column selected in: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Change null_placement to conform to pyarrow&#39;s sort_indices() while ensuring backwards compatibility</span>
        <span class="k">if</span> <span class="n">null_placement</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;at_start&quot;</span><span class="p">,</span> <span class="s2">&quot;at_end&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">null_placement</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
                <span class="n">null_placement</span> <span class="o">=</span> <span class="s2">&quot;at_start&quot;</span>
            <span class="k">elif</span> <span class="n">null_placement</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
                <span class="n">null_placement</span> <span class="o">=</span> <span class="s2">&quot;at_end&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;null_placement &#39;</span><span class="si">{</span><span class="n">null_placement</span><span class="si">}</span><span class="s2">&#39; is an invalid parameter value. Must be either &#39;last&#39;, &#39;at_end&#39;, &#39;first&#39; or &#39;at_start&#39;.&quot;</span>
                <span class="p">)</span>

        <span class="n">load_from_cache_file</span> <span class="o">=</span> <span class="n">load_from_cache_file</span> <span class="k">if</span> <span class="n">load_from_cache_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">is_caching_enabled</span><span class="p">()</span>

        <span class="c1"># Check if we&#39;ve already cached this computation (indexed by a hash)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># we create a unique hash from the function, current dataset file and the mapping args</span>
                <span class="n">indices_cache_file_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_file_path</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">indices_cache_file_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">load_from_cache_file</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading cached sorted indices for dataset at </span><span class="si">{</span><span class="n">indices_cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span>
                    <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span> <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span>
                <span class="p">)</span>

        <span class="n">sort_table</span> <span class="o">=</span> <span class="n">query_table</span><span class="p">(</span>
            <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
            <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">sort_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="s2">&quot;ascending&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">col_reverse</span> <span class="k">else</span> <span class="s2">&quot;descending&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">col_reverse</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">pc</span><span class="o">.</span><span class="n">sort_indices</span><span class="p">(</span><span class="n">sort_table</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="n">sort_keys</span><span class="p">,</span> <span class="n">null_placement</span><span class="o">=</span><span class="n">null_placement</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.shuffle">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.shuffle.html#datasets.Dataset.shuffle">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span>
        <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">randomized_function</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;load_from_cache_file&quot;</span><span class="p">,</span> <span class="s2">&quot;indices_cache_file_name&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shuffle</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new Dataset where the rows are shuffled.</span>

<span class="sd">        Currently shuffling uses numpy random generators.</span>
<span class="sd">        You can either supply a NumPy BitGenerator to use, or a seed to initiate NumPy&#39;s default random generator (PCG64).</span>

<span class="sd">        Shuffling takes the list of indices `[0:len(my_dataset)]` and shuffles it to create an indices mapping.</span>
<span class="sd">        However as soon as your [`Dataset`] has an indices mapping, the speed can become 10x slower.</span>
<span class="sd">        This is because there is an extra step to get the row index to read using the indices mapping, and most importantly, you aren&#39;t reading contiguous chunks of data anymore.</span>
<span class="sd">        To restore the speed, you&#39;d need to rewrite the entire dataset on your disk again using [`Dataset.flatten_indices`], which removes the indices mapping.</span>
<span class="sd">        This may take a lot of time depending of the size of your dataset though:</span>

<span class="sd">        ```python</span>
<span class="sd">        my_dataset[0]  # fast</span>
<span class="sd">        my_dataset = my_dataset.shuffle(seed=42)</span>
<span class="sd">        my_dataset[0]  # up to 10x slower</span>
<span class="sd">        my_dataset = my_dataset.flatten_indices()  # rewrite the shuffled dataset on disk as contiguous chunks of data</span>
<span class="sd">        my_dataset[0]  # fast again</span>
<span class="sd">        ```</span>

<span class="sd">        In this case, we recommend switching to an [`IterableDataset`] and leveraging its fast approximate shuffling method [`IterableDataset.shuffle`].</span>
<span class="sd">        It only shuffles the shards order and adds a shuffle buffer to your dataset, which keeps the speed of your dataset optimal:</span>

<span class="sd">        ```python</span>
<span class="sd">        my_iterable_dataset = my_dataset.to_iterable_dataset(num_shards=128)</span>
<span class="sd">        for example in enumerate(my_iterable_dataset):  # fast</span>
<span class="sd">            pass</span>

<span class="sd">        shuffled_iterable_dataset = my_iterable_dataset.shuffle(seed=42, buffer_size=100)</span>

<span class="sd">        for example in enumerate(shuffled_iterable_dataset):  # as fast as before</span>
<span class="sd">            pass</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            seed (`int`, *optional*):</span>
<span class="sd">                A seed to initialize the default BitGenerator if `generator=None`.</span>
<span class="sd">                If `None`, then fresh, unpredictable entropy will be pulled from the OS.</span>
<span class="sd">                If an `int` or `array_like[ints]` is passed, then it will be passed to SeedSequence to derive the initial BitGenerator state.</span>
<span class="sd">            generator (`numpy.random.Generator`, *optional*):</span>
<span class="sd">                Numpy random Generator to use to compute the permutation of the dataset rows.</span>
<span class="sd">                If `generator=None` (default), uses `np.random.default_rng` (the default BitGenerator (PCG64) of NumPy).</span>
<span class="sd">            keep_in_memory (`bool`, default `False`):</span>
<span class="sd">                Keep the shuffled indices in memory instead of writing it to a cache file.</span>
<span class="sd">            load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the shuffled indices</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            indices_cache_file_name (`str`, *optional*):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                shuffled indices instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the dataset after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds[&#39;label&#39;][:10]</span>
<span class="sd">        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>

<span class="sd">        # set a seed</span>
<span class="sd">        &gt;&gt;&gt; shuffled_ds = ds.shuffle(seed=42)</span>
<span class="sd">        &gt;&gt;&gt; shuffled_ds[&#39;label&#39;][:10]</span>
<span class="sd">        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0]</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.shuffle` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">keep_in_memory</span> <span class="ow">and</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please use either `keep_in_memory` or `indices_cache_file_name` but not both.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Both `seed` and `generator` were provided. Please specify just one of them.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The provided generator must be an instance of numpy.random.Generator&quot;</span><span class="p">)</span>

        <span class="n">load_from_cache_file</span> <span class="o">=</span> <span class="n">load_from_cache_file</span> <span class="k">if</span> <span class="n">load_from_cache_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">is_caching_enabled</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
                <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="k">if</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="mi">624</span> <span class="k">else</span> <span class="n">seed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>  <span class="c1"># do 1 step of rng</span>
            <span class="n">generator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Check if we&#39;ve already cached this computation (indexed by a hash)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># we create a unique hash from the function, current dataset file and the mapping args</span>
                <span class="n">indices_cache_file_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_file_path</span><span class="p">(</span><span class="n">new_fingerprint</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">indices_cache_file_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">load_from_cache_file</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading cached shuffled indices for dataset at </span><span class="si">{</span><span class="n">indices_cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span>
                    <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span> <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span>
                <span class="p">)</span>

        <span class="n">permutation</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">permutation</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_in_memory</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.train_test_split">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.train_test_split.html#datasets.Dataset.train_test_split">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span>
        <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">randomized_function</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">fingerprint_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train_new_fingerprint&quot;</span><span class="p">,</span> <span class="s2">&quot;test_new_fingerprint&quot;</span><span class="p">],</span>
        <span class="n">ignore_kwargs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;load_from_cache_file&quot;</span><span class="p">,</span> <span class="s2">&quot;train_indices_cache_file_name&quot;</span><span class="p">,</span> <span class="s2">&quot;test_indices_cache_file_name&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_test_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">stratify_by_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">load_from_cache_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">test_indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">train_new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">test_new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DatasetDict&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a dictionary ([`datasets.DatasetDict`]) with two random train and test subsets (`train` and `test` `Dataset` splits).</span>
<span class="sd">        Splits are created from the dataset according to `test_size`, `train_size` and `shuffle`.</span>

<span class="sd">        This method is similar to scikit-learn `train_test_split`.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_size (`Union[float, int, None]`, *optional*):</span>
<span class="sd">                Size of the test split</span>
<span class="sd">                If `float`, should be between `0.0` and `1.0` and represent the proportion of the dataset to include in the test split.</span>
<span class="sd">                If `int`, represents the absolute number of test samples.</span>
<span class="sd">                If `None`, the value is set to the complement of the train size.</span>
<span class="sd">                If `train_size` is also `None`, it will be set to `0.25`.</span>
<span class="sd">            train_size (`Union[float, int, None]`, *optional*):</span>
<span class="sd">                Size of the train split</span>
<span class="sd">                If `float`, should be between `0.0` and `1.0` and represent the proportion of the dataset to include in the train split.</span>
<span class="sd">                If `int`, represents the absolute number of train samples.</span>
<span class="sd">                If `None`, the value is automatically set to the complement of the test size.</span>
<span class="sd">            shuffle (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether or not to shuffle the data before splitting.</span>
<span class="sd">            stratify_by_column (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The column name of labels to be used to perform stratified split of data.</span>
<span class="sd">            seed (`int`, *optional*):</span>
<span class="sd">                A seed to initialize the default BitGenerator if `generator=None`.</span>
<span class="sd">                If `None`, then fresh, unpredictable entropy will be pulled from the OS.</span>
<span class="sd">                If an `int` or `array_like[ints]` is passed, then it will be passed to SeedSequence to derive the initial BitGenerator state.</span>
<span class="sd">            generator (`numpy.random.Generator`, *optional*):</span>
<span class="sd">                Numpy random Generator to use to compute the permutation of the dataset rows.</span>
<span class="sd">                If `generator=None` (default), uses `np.random.default_rng` (the default BitGenerator (PCG64) of NumPy).</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the splits indices in memory instead of writing it to a cache file.</span>
<span class="sd">            load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):</span>
<span class="sd">                If a cache file storing the splits indices</span>
<span class="sd">                can be identified, use it instead of recomputing.</span>
<span class="sd">            train_cache_file_name (`str`, *optional*):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                train split indices instead of the automatically generated cache file name.</span>
<span class="sd">            test_cache_file_name (`str`, *optional*):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                test split indices instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                Number of rows per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>
<span class="sd">            train_new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the train set after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>
<span class="sd">            test_new_fingerprint (`str`, *optional*, defaults to `None`):</span>
<span class="sd">                The new fingerprint of the test set after transform.</span>
<span class="sd">                If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.train_test_split(test_size=0.2, shuffle=True)</span>
<span class="sd">        DatasetDict({</span>
<span class="sd">            train: Dataset({</span>
<span class="sd">                features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">                num_rows: 852</span>
<span class="sd">            })</span>
<span class="sd">            test: Dataset({</span>
<span class="sd">                features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">                num_rows: 214</span>
<span class="sd">            })</span>
<span class="sd">        })</span>

<span class="sd">        # set a seed</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.train_test_split(test_size=0.2, seed=42)</span>

<span class="sd">        # stratified split</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;stanfordnlp/imdb&quot;,split=&quot;train&quot;)</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 25000</span>
<span class="sd">        })</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.train_test_split(test_size=0.2, stratify_by_column=&quot;label&quot;)</span>
<span class="sd">        DatasetDict({</span>
<span class="sd">            train: Dataset({</span>
<span class="sd">                features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">                num_rows: 20000</span>
<span class="sd">            })</span>
<span class="sd">            test: Dataset({</span>
<span class="sd">                features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">                num_rows: 5000</span>
<span class="sd">            })</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.dataset_dict</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetDict</span>  <span class="c1"># import here because of circular dependency</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_indexes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DatasetTransformationNotAllowedError</span><span class="p">(</span>
                <span class="s2">&quot;Using `.train_test_split` on a dataset with attached indexes is not allowed. You can first run `.drop_index() to remove your index and then re-add it.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># If the array is empty we do nothing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">DatasetDict</span><span class="p">({</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="p">})</span>

        <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span>

        <span class="c1"># Safety checks similar to scikit-learn&#39;s ones.</span>
        <span class="c1"># (adapted from https://github.com/scikit-learn/scikit-learn/blob/fd237278e895b42abe8d8d09105cbb82dc2cbba7/sklearn/model_selection/_split.py#L1750)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;test_size=</span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2"> should be either positive and smaller &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;than the number of samples </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> or a float in the (0, 1) range&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;train_size=</span><span class="si">{</span><span class="n">train_size</span><span class="si">}</span><span class="s2"> should be either positive and smaller &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;than the number of samples </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> or a float in the (0, 1) range&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid value for train_size: </span><span class="si">{</span><span class="n">train_size</span><span class="si">}</span><span class="s2"> of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid value for test_size: </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2"> of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The sum of test_size and train_size = </span><span class="si">{</span><span class="n">train_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">test_size</span><span class="si">}</span><span class="s2">, should be in the (0, 1)&quot;</span>
                <span class="s2">&quot; range. Reduce test_size and/or train_size.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">n_test</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">n_test</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_test</span>
        <span class="k">elif</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_test</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_train</span>

        <span class="k">if</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The sum of train_size and test_size = </span><span class="si">{</span><span class="n">n_train</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">n_test</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="s2">&quot;should be smaller than the number of &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;samples </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">. Reduce test_size and/or &quot;</span>
                <span class="s2">&quot;train_size.&quot;</span>
            <span class="p">)</span>

        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;With n_samples=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">, test_size=</span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2"> and train_size=</span><span class="si">{</span><span class="n">train_size</span><span class="si">}</span><span class="s2">, the &quot;</span>
                <span class="s2">&quot;resulting train set will be empty. Adjust any of the &quot;</span>
                <span class="s2">&quot;aforementioned parameters.&quot;</span>
            <span class="p">)</span>

        <span class="n">load_from_cache_file</span> <span class="o">=</span> <span class="n">load_from_cache_file</span> <span class="k">if</span> <span class="n">load_from_cache_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">is_caching_enabled</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
                <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="k">if</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="mi">624</span> <span class="k">else</span> <span class="n">seed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>  <span class="c1"># do 1 step of rng</span>
            <span class="n">generator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Check if we&#39;ve already cached this computation (indexed by a hash)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_files</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">test_indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># we create a unique hash from the function, current dataset file and the mapping args</span>

                <span class="k">if</span> <span class="n">train_indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">train_indices_cache_file_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_file_path</span><span class="p">(</span><span class="n">train_new_fingerprint</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">test_indices_cache_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">test_indices_cache_file_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_file_path</span><span class="p">(</span><span class="n">test_new_fingerprint</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">train_indices_cache_file_name</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">test_indices_cache_file_name</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">load_from_cache_file</span>
            <span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Loading cached split indices for dataset at </span><span class="si">{</span><span class="n">train_indices_cache_file_name</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">test_indices_cache_file_name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">DatasetDict</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span>
                            <span class="n">fingerprint</span><span class="o">=</span><span class="n">train_new_fingerprint</span><span class="p">,</span> <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">train_indices_cache_file_name</span>
                        <span class="p">),</span>
                        <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_dataset_with_indices</span><span class="p">(</span>
                            <span class="n">fingerprint</span><span class="o">=</span><span class="n">test_new_fingerprint</span><span class="p">,</span> <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">test_indices_cache_file_name</span>
                        <span class="p">),</span>
                    <span class="p">}</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stratify_by_column</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Stratified train/test split is not implemented for `shuffle=False`&quot;</span><span class="p">)</span>
            <span class="n">train_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">)</span>
            <span class="n">test_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># stratified partition</span>
            <span class="k">if</span> <span class="n">stratify_by_column</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stratify_by_column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Key </span><span class="si">{</span><span class="n">stratify_by_column</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">stratify_by_column</span><span class="p">],</span> <span class="n">ClassLabel</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Stratifying by column is only supported for </span><span class="si">{</span><span class="n">ClassLabel</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> column, and column </span><span class="si">{</span><span class="n">stratify_by_column</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">stratify_by_column</span><span class="p">])</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">train_indices</span><span class="p">,</span> <span class="n">test_indices</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
                        <span class="n">stratified_shuffle_split_generate_indices</span><span class="p">(</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;numpy&quot;</span><span class="p">)[</span><span class="n">stratify_by_column</span><span class="p">]),</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">generator</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Minimum class count error&quot;</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;The least populated class in </span><span class="si">{</span><span class="n">stratify_by_column</span><span class="si">}</span><span class="s2"> column has only 1&quot;</span>
                            <span class="s2">&quot; member, which is too few. The minimum&quot;</span>
                            <span class="s2">&quot; number of groups for any class cannot&quot;</span>
                            <span class="s2">&quot; be less than 2.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">error</span>

            <span class="c1"># random partition</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">permutation</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
                <span class="n">test_indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
                <span class="n">train_indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">n_test</span> <span class="p">:</span> <span class="p">(</span><span class="n">n_test</span> <span class="o">+</span> <span class="n">n_train</span><span class="p">)]</span>

        <span class="n">train_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">train_indices_cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">train_new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">test_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">test_indices</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">test_indices_cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="n">new_fingerprint</span><span class="o">=</span><span class="n">test_new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">DatasetDict</span><span class="p">({</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_split</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">test_split</span><span class="p">})</span></div>


<div class="viewcode-block" id="Dataset.shard">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.shard.html#datasets.Dataset.shard">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">shard</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_shards</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">contiguous</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">keep_in_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">indices_cache_file_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the `index`-nth shard from dataset split into `num_shards` pieces.</span>

<span class="sd">        This shards deterministically. `dataset.shard(n, i)` splits the dataset into contiguous chunks,</span>
<span class="sd">        so it can be easily concatenated back together after processing. If `len(dataset) % n == l`, then the</span>
<span class="sd">        first `l` dataset each have length `(len(dataset) // n) + 1`, and the remaining dataset have length `(len(dataset) // n)`.</span>
<span class="sd">        `datasets.concatenate_datasets([dset.shard(n, i) for i in range(n)])` returns a dataset with the same order as the original.</span>

<span class="sd">        Note: n should be less or equal to the number of elements in the dataset `len(dataset)`.</span>

<span class="sd">        On the other hand, `dataset.shard(n, i, contiguous=False)` contains all elements of the dataset whose index mod `n = i`.</span>

<span class="sd">        Be sure to shard before using any randomizing operator (such as `shuffle`).</span>
<span class="sd">        It is best if the shard operator is used early in the dataset pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_shards (`int`):</span>
<span class="sd">                How many shards to split the dataset into.</span>
<span class="sd">            index (`int`):</span>
<span class="sd">                Which shard to select and return.</span>
<span class="sd">            contiguous: (`bool`, defaults to `True`):</span>
<span class="sd">                Whether to select contiguous blocks of indices for shards.</span>
<span class="sd">            keep_in_memory (`bool`, defaults to `False`):</span>
<span class="sd">                Keep the dataset in memory instead of writing it to a cache file.</span>
<span class="sd">            indices_cache_file_name (`str`, *optional*):</span>
<span class="sd">                Provide the name of a path for the cache file. It is used to store the</span>
<span class="sd">                indices of each shard instead of the automatically generated cache file name.</span>
<span class="sd">            writer_batch_size (`int`, defaults to `1000`):</span>
<span class="sd">                This only concerns the indices mapping.</span>
<span class="sd">                Number of indices per write operation for the cache file writer.</span>
<span class="sd">                This value is a good trade-off between memory usage during the processing, and processing speed.</span>
<span class="sd">                Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.shard(num_shards=2, index=0)</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;],</span>
<span class="sd">            num_rows: 533</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="n">num_shards</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;index should be in [0, num_shards-1]&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">contiguous</span><span class="p">:</span>
            <span class="n">div</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_shards</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_shards</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">div</span> <span class="o">*</span> <span class="n">index</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">div</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="n">mod</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">num_shards</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">keep_in_memory</span><span class="o">=</span><span class="n">keep_in_memory</span><span class="p">,</span>
            <span class="n">indices_cache_file_name</span><span class="o">=</span><span class="n">indices_cache_file_name</span><span class="p">,</span>
            <span class="n">writer_batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_csv">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_csv.html#datasets.Dataset.to_csv">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_csv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path_or_buf</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">to_csv_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Exports the dataset to csv</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_buf (`PathLike` or `FileOrBuffer`):</span>
<span class="sd">                Either a path to a file (e.g. `file.csv`), a remote URI (e.g. `hf://datasets/username/my_dataset_name/data.csv`),</span>
<span class="sd">                or a BinaryIO, where the dataset will be saved to in the specified format.</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of the batch to load in memory and write at once.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            num_proc (`int`, *optional*):</span>
<span class="sd">                Number of processes for multiprocessing. By default it doesn&#39;t</span>
<span class="sd">                use multiprocessing. `batch_size` in this case defaults to</span>
<span class="sd">                `datasets.config.DEFAULT_MAX_BATCH_SIZE` but feel free to make it 5x or 10x of the default</span>
<span class="sd">                value if you have sufficient compute power.</span>
<span class="sd">            storage_options (`dict`, *optional*):</span>
<span class="sd">                Key/value pairs to be passed on to the file-system backend, if any.</span>

<span class="sd">                &lt;Added version=&quot;2.19.0&quot;/&gt;</span>
<span class="sd">            **to_csv_kwargs (additional keyword arguments):</span>
<span class="sd">                Parameters to pass to pandas&#39;s [`pandas.DataFrame.to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html).</span>

<span class="sd">                &lt;Changed version=&quot;2.10.0&quot;&gt;</span>

<span class="sd">                Now, `index` defaults to `False` if not specified.</span>

<span class="sd">                If you would like to write the index, pass `index=True` and also set a name for the index column by</span>
<span class="sd">                passing `index_label`.</span>

<span class="sd">                &lt;/Changed&gt;</span>

<span class="sd">        Returns:</span>
<span class="sd">            `int`: The number of characters or bytes written.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_csv(&quot;path/to/dataset/directory&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.csv</span><span class="w"> </span><span class="kn">import</span> <span class="n">CsvDatasetWriter</span>

        <span class="k">return</span> <span class="n">CsvDatasetWriter</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">path_or_buf</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span>
            <span class="o">**</span><span class="n">to_csv_kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.to_dict">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_dict.html#datasets.Dataset.to_dict">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dataset as a Python dict. Can also return a generator for large datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int`, *optional*): The size (number of rows) of the batches if `batched` is `True`.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            batched (`bool`):</span>
<span class="sd">                Set to `True` to return a generator that yields the dataset as batches</span>
<span class="sd">                of `batch_size` rows. Defaults to `False` (returns the whole datasets once).</span>

<span class="sd">        Returns:</span>
<span class="sd">            `dict` or `Iterator[dict]`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_dict()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">query_table</span><span class="p">(</span>
            <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
            <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to_pydict</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.to_list">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.to_list">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dataset as a Python list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `list`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_list()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">query_table</span><span class="p">(</span>
            <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
            <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.to_json">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_json.html#datasets.Dataset.to_json">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_json</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path_or_buf</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">to_json_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Export the dataset to JSON Lines or JSON.</span>

<span class="sd">        The default output format is [JSON Lines](https://jsonlines.org/).</span>
<span class="sd">        To export to [JSON](https://www.json.org), pass `lines=False` argument and the desired `orient`.</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_buf (`PathLike` or `FileOrBuffer`):</span>
<span class="sd">                Either a path to a file (e.g. `file.json`), a remote URI (e.g. `hf://datasets/username/my_dataset_name/data.json`),</span>
<span class="sd">                or a BinaryIO, where the dataset will be saved to in the specified format.</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of the batch to load in memory and write at once.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            num_proc (`int`, *optional*):</span>
<span class="sd">                Number of processes for multiprocessing. By default, it doesn&#39;t</span>
<span class="sd">                use multiprocessing. `batch_size` in this case defaults to</span>
<span class="sd">                `datasets.config.DEFAULT_MAX_BATCH_SIZE` but feel free to make it 5x or 10x of the default</span>
<span class="sd">                value if you have sufficient compute power.</span>
<span class="sd">            storage_options (`dict`, *optional*):</span>
<span class="sd">                Key/value pairs to be passed on to the file-system backend, if any.</span>

<span class="sd">                &lt;Added version=&quot;2.19.0&quot;/&gt;</span>
<span class="sd">            **to_json_kwargs (additional keyword arguments):</span>
<span class="sd">                Parameters to pass to pandas&#39;s [`pandas.DataFrame.to_json`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html).</span>
<span class="sd">                Default arguments are `lines=True` and `orient=&quot;records&quot;.</span>

<span class="sd">                &lt;Changed version=&quot;2.11.0&quot;&gt;</span>

<span class="sd">                The parameter `index` defaults to `False` if `orient` is `&quot;split&quot;` or `&quot;table&quot;`.</span>

<span class="sd">                If you would like to write the index, pass `index=True`.</span>

<span class="sd">                &lt;/Changed&gt;</span>

<span class="sd">        Returns:</span>
<span class="sd">            `int`: The number of characters or bytes written.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_json(&quot;path/to/dataset/directory/filename.jsonl&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.json</span><span class="w"> </span><span class="kn">import</span> <span class="n">JsonDatasetWriter</span>

        <span class="k">return</span> <span class="n">JsonDatasetWriter</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">path_or_buf</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
            <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span>
            <span class="o">**</span><span class="n">to_json_kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.to_pandas">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_pandas.html#datasets.Dataset.to_pandas">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_pandas</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dataset as a `pandas.DataFrame`. Can also return a generator for large datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                The size (number of rows) of the batches if `batched` is `True`.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            batched (`bool`):</span>
<span class="sd">                Set to `True` to return a generator that yields the dataset as batches</span>
<span class="sd">                of `batch_size` rows. Defaults to `False` (returns the whole datasets once).</span>

<span class="sd">        Returns:</span>
<span class="sd">            `pandas.DataFrame` or `Iterator[pandas.DataFrame]`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_pandas()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">batched</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">query_table</span><span class="p">(</span>
                <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
                <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
                <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">(</span><span class="n">types_mapper</span><span class="o">=</span><span class="n">pandas_types_mapper</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">DEFAULT_MAX_BATCH_SIZE</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">query_table</span><span class="p">(</span>
                    <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
                    <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">),</span>
                    <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">(</span><span class="n">types_mapper</span><span class="o">=</span><span class="n">pandas_types_mapper</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_polars">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.to_polars">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_polars</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">schema_overrides</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rechunk</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pl.DataFrame&quot;</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">[</span><span class="s2">&quot;pl.DataFrame&quot;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dataset as a `polars.DataFrame`. Can also return a generator for large datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                The size (number of rows) of the batches if `batched` is `True`.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            batched (`bool`):</span>
<span class="sd">                Set to `True` to return a generator that yields the dataset as batches</span>
<span class="sd">                of `batch_size` rows. Defaults to `False` (returns the whole datasets once).</span>
<span class="sd">            schema_overrides (`dict`, *optional*):</span>
<span class="sd">                Support type specification or override of one or more columns; note that</span>
<span class="sd">                any dtypes inferred from the schema param will be overridden.</span>
<span class="sd">            rechunk (`bool`):</span>
<span class="sd">                Make sure that all data is in contiguous memory. Defaults to `True`.</span>
<span class="sd">        Returns:</span>
<span class="sd">            `polars.DataFrame` or `Iterator[polars.DataFrame]`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_polars()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">POLARS_AVAILABLE</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">polars</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">batched</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">pl</span><span class="o">.</span><span class="n">from_arrow</span><span class="p">(</span>
                    <span class="n">query_table</span><span class="p">(</span>
                        <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span>
                        <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">schema_overrides</span><span class="o">=</span><span class="n">schema_overrides</span><span class="p">,</span>
                    <span class="n">rechunk</span><span class="o">=</span><span class="n">rechunk</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">DEFAULT_MAX_BATCH_SIZE</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">from_arrow</span><span class="p">(</span>
                        <span class="n">query_table</span><span class="p">(</span>
                            <span class="n">table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
                            <span class="n">key</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">),</span>
                            <span class="n">indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">schema_overrides</span><span class="o">=</span><span class="n">schema_overrides</span><span class="p">,</span>
                        <span class="n">rechunk</span><span class="o">=</span><span class="n">rechunk</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Polars needs to be installed to be able to return Polars dataframes.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_parquet">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_parquet.html#datasets.Dataset.to_parquet">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_parquet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path_or_buf</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">parquet_writer_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Exports the dataset to parquet</span>

<span class="sd">        Args:</span>
<span class="sd">            path_or_buf (`PathLike` or `FileOrBuffer`):</span>
<span class="sd">                Either a path to a file (e.g. `file.parquet`), a remote URI (e.g. `hf://datasets/username/my_dataset_name/data.parquet`),</span>
<span class="sd">                or a BinaryIO, where the dataset will be saved to in the specified format.</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of the batch to load in memory and write at once.</span>
<span class="sd">                By default it aims for row groups with maximum uncompressed byte size of &quot;100MB&quot;,</span>
<span class="sd">                defined by `datasets.config.MAX_ROW_GROUP_SIZE`.</span>
<span class="sd">            storage_options (`dict`, *optional*):</span>
<span class="sd">                Key/value pairs to be passed on to the file-system backend, if any.</span>

<span class="sd">                &lt;Added version=&quot;2.19.0&quot;/&gt;</span>
<span class="sd">            **parquet_writer_kwargs (additional keyword arguments):</span>
<span class="sd">                Parameters to pass to PyArrow&#39;s `pyarrow.parquet.ParquetWriter`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `int`: The number of characters or bytes written.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; ds.to_parquet(&quot;path/to/dataset/directory&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.parquet</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParquetDatasetWriter</span>

        <span class="k">return</span> <span class="n">ParquetDatasetWriter</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">path_or_buf</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">,</span> <span class="o">**</span><span class="n">parquet_writer_kwargs</span>
        <span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">()</span></div>


<div class="viewcode-block" id="Dataset.to_sql">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_sql.html#datasets.Dataset.to_sql">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_sql</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">con</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;sqlalchemy.engine.Connection&quot;</span><span class="p">,</span> <span class="s2">&quot;sqlalchemy.engine.Engine&quot;</span><span class="p">,</span> <span class="s2">&quot;sqlite3.Connection&quot;</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">sql_writer_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Exports the dataset to a SQL database.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (`str`):</span>
<span class="sd">                Name of SQL table.</span>
<span class="sd">            con (`str` or `sqlite3.Connection` or `sqlalchemy.engine.Connection` or `sqlalchemy.engine.Connection`):</span>
<span class="sd">                A [URI string](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls) or a SQLite3/SQLAlchemy connection object used to write to a database.</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of the batch to load in memory and write at once.</span>
<span class="sd">                Defaults to `datasets.config.DEFAULT_MAX_BATCH_SIZE`.</span>
<span class="sd">            **sql_writer_kwargs (additional keyword arguments):</span>
<span class="sd">                Parameters to pass to pandas&#39;s [`pandas.DataFrame.to_sql`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html).</span>

<span class="sd">                &lt;Changed version=&quot;2.11.0&quot;&gt;</span>

<span class="sd">                Now, `index` defaults to `False` if not specified.</span>

<span class="sd">                If you would like to write the index, pass `index=True` and also set a name for the index column by</span>
<span class="sd">                passing `index_label`.</span>

<span class="sd">                &lt;/Changed&gt;</span>

<span class="sd">        Returns:</span>
<span class="sd">            `int`: The number of records written.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; # con provided as a connection URI string</span>
<span class="sd">        &gt;&gt;&gt; ds.to_sql(&quot;data&quot;, &quot;sqlite:///my_own_db.sql&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # con provided as a sqlite3 connection object</span>
<span class="sd">        &gt;&gt;&gt; import sqlite3</span>
<span class="sd">        &gt;&gt;&gt; con = sqlite3.connect(&quot;my_own_db.sql&quot;)</span>
<span class="sd">        &gt;&gt;&gt; with con:</span>
<span class="sd">        ...     ds.to_sql(&quot;data&quot;, con)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Dynamic import to avoid circular dependency</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.io.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SqlDatasetWriter</span>

        <span class="k">return</span> <span class="n">SqlDatasetWriter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">con</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">sql_writer_kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_estimate_nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">nbytes</span>

        <span class="c1"># Find decodable columns, because if there are any, we need to</span>
        <span class="c1"># adjust the dataset size computation (needed for sharding) to account for possible external files</span>
        <span class="n">decodable_columns</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">require_decoding</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ignore_decode_attribute</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">decodable_columns</span><span class="p">:</span>
            <span class="c1"># Approximate the space needed to store the bytes from the external files by analyzing the first 1000 examples</span>
            <span class="n">extra_nbytes</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">extra_nbytes_visitor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
                <span class="k">nonlocal</span> <span class="n">extra_nbytes</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="p">(</span><span class="n">Audio</span><span class="p">,</span> <span class="n">Image</span><span class="p">,</span> <span class="n">Video</span><span class="p">)):</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">array</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;bytes&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">size</span> <span class="o">=</span> <span class="n">xgetsize</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">])</span>
                            <span class="n">extra_nbytes</span> <span class="o">+=</span> <span class="n">size</span>
                    <span class="n">extra_nbytes</span> <span class="o">-=</span> <span class="n">array</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="s2">&quot;path&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">nbytes</span>

            <span class="n">table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)[:</span><span class="mi">1000</span><span class="p">]</span>
            <span class="n">table_visitor</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">extra_nbytes_visitor</span><span class="p">)</span>

            <span class="n">extra_nbytes</span> <span class="o">=</span> <span class="n">extra_nbytes</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
            <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="n">dataset_nbytes</span> <span class="o">+</span> <span class="n">extra_nbytes</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="n">dataset_nbytes</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">)</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset_nbytes</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_tables_from_shards</span><span class="p">(</span><span class="n">shards</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">shard_idx</span><span class="p">,</span> <span class="n">shard</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shards</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">pa_table</span> <span class="ow">in</span> <span class="n">shard</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">shard_idx</span><span class="p">,</span> <span class="n">pa_table</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_tables_from_cache_file</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">_memory_mapped_record_batch_reader_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)):</span>
            <span class="k">yield</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_batches</span><span class="p">([</span><span class="n">batch</span><span class="p">])</span>

<div class="viewcode-block" id="Dataset.to_iterable_dataset">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.to_iterable_dataset.html#datasets.Dataset.to_iterable_dataset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_iterable_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;IterableDataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an [`datasets.IterableDataset`] from a map-style [`datasets.Dataset`].</span>
<span class="sd">        This is equivalent to loading a dataset in streaming mode with [`datasets.load_dataset`], but much faster since the data is streamed from local files.</span>

<span class="sd">        Contrary to map-style datasets, iterable datasets are lazy and can only be iterated over (e.g. using a for loop).</span>
<span class="sd">        Since they are read sequentially in training loops, iterable datasets are much faster than map-style datasets.</span>
<span class="sd">        All the transformations applied to iterable datasets like filtering or processing are done on-the-fly when you start iterating over the dataset.</span>

<span class="sd">        Still, it is possible to shuffle an iterable dataset using [`datasets.IterableDataset.shuffle`].</span>
<span class="sd">        This is a fast approximate shuffling that works best if you have multiple shards and if you specify a buffer size that is big enough.</span>

<span class="sd">        To get the best speed performance, make sure your dataset doesn&#39;t have an indices mapping.</span>
<span class="sd">        If this is the case, the data are not read contiguously, which can be slow sometimes.</span>
<span class="sd">        You can use `ds = ds.flatten_indices()` to write your dataset in contiguous chunks of data and have optimal speed before switching to an iterable dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_shards (`int`, default to `1`):</span>
<span class="sd">                Number of shards to define when instantiating the iterable dataset. This is especially useful for big datasets to be able to shuffle properly,</span>
<span class="sd">                and also to enable fast parallel loading using a PyTorch DataLoader or in distributed setups for example.</span>
<span class="sd">                Shards are defined using [`datasets.Dataset.shard`]: it simply slices the data without writing anything on disk.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`datasets.IterableDataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        Basic usage:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset()</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        With lazy filtering and processing:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset()</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.filter(filter_fn).map(process_fn)  # will filter and process on-the-fly when you start iterating over the iterable dataset</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        With sharding to enable efficient shuffling:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset(num_shards=64)  # the dataset is split into 64 shards to be iterated over</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.shuffle(buffer_size=10_000)  # will shuffle the shards order and use a shuffle buffer for fast approximate shuffling when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        With a PyTorch DataLoader:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset(num_shards=64)</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.filter(filter_fn).map(process_fn)</span>
<span class="sd">        &gt;&gt;&gt; dataloader = torch.utils.data.DataLoader(ids, num_workers=4)  # will assign 64 / 4 = 16 shards to each worker to load, filter and process when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        With a PyTorch DataLoader and shuffling:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset(num_shards=64)</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.shuffle(buffer_size=10_000)  # will shuffle the shards order and use a shuffle buffer when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; dataloader = torch.utils.data.DataLoader(ids, num_workers=4)  # will assign 64 / 4 = 16 shards from the shuffled list of shards to each worker when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        In a distributed setup like PyTorch DDP with a PyTorch DataLoader and shuffling</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from datasets.distributed import split_dataset_by_node</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset(num_shards=512)</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.shuffle(buffer_size=10_000, seed=42)  # will shuffle the shards order and use a shuffle buffer when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; ids = split_dataset_by_node(ds, world_size=8, rank=0)  # will keep only 512 / 8 = 64 shards from the shuffled lists of shards when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; dataloader = torch.utils.data.DataLoader(ids, num_workers=4)  # will assign 64 / 4 = 16 shards from this node&#39;s list of shards to each worker when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; for example in ids:</span>
<span class="sd">        ...     pass</span>
<span class="sd">        ```</span>

<span class="sd">        With shuffling and multiple epochs:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; ids = ds.to_iterable_dataset(num_shards=64)</span>
<span class="sd">        &gt;&gt;&gt; ids = ids.shuffle(buffer_size=10_000, seed=42)  # will shuffle the shards order and use a shuffle buffer when you start iterating</span>
<span class="sd">        &gt;&gt;&gt; for epoch in range(n_epochs):</span>
<span class="sd">        ...     ids.set_epoch(epoch)  # will use effective_seed = seed + epoch to shuffle the shards and for the shuffle buffer when you start iterating</span>
<span class="sd">        ...     for example in ids:</span>
<span class="sd">        ...         pass</span>
<span class="sd">        ```</span>
<span class="sd">        Feel free to also use [`IterableDataset.set_epoch`] when using a PyTorch DataLoader or in distributed setups.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.iterable_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArrowExamplesIterable</span><span class="p">,</span> <span class="n">IterableDataset</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_kwargs</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_columns</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Converting a formatted dataset with kwargs or selected columns to a formatted iterable dataset is not implemented yet. Please run `my_dataset = my_dataset.with_format(None)` before calling to_iterable_dataset&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">num_shards</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unable to shard a dataset of size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2"> into </span><span class="si">{</span><span class="n">num_shards</span><span class="si">}</span><span class="s2"> shards (the number of shards exceeds the number of samples).&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Converting an Arrow dataset to iterable but it has an indices mapping that can make it slower. &quot;</span>
                <span class="s2">&quot;You can use `ds = ds.flatten_indices()` to write your dataset in contiguous chunks of data and have optimal speed.&quot;</span>
            <span class="p">)</span>
        <span class="n">shards</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">num_shards</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">shard_idx</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">shard_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">ex_iterable</span> <span class="o">=</span> <span class="n">ArrowExamplesIterable</span><span class="p">(</span>
            <span class="n">Dataset</span><span class="o">.</span><span class="n">_generate_tables_from_shards</span><span class="p">,</span>
            <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shards&quot;</span><span class="p">:</span> <span class="n">shards</span><span class="p">,</span> <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">config</span><span class="o">.</span><span class="n">DEFAULT_MAX_BATCH_SIZE</span><span class="p">},</span>
        <span class="p">)</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">IterableDataset</span><span class="p">(</span><span class="n">ex_iterable</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">DatasetInfo</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_format_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ds</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_push_parquet_shards_to_hub_single</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">job_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_jobs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">revision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">create_pr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
        <span class="n">num_shards</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">embed_external_files</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">writer_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">div</span> <span class="o">=</span> <span class="n">num_shards</span> <span class="o">//</span> <span class="n">num_jobs</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">num_shards</span> <span class="o">%</span> <span class="n">num_jobs</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">div</span> <span class="o">*</span> <span class="n">job_id</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">job_id</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">div</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">job_id</span> <span class="o">&lt;</span> <span class="n">mod</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">index_shards</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">(</span><span class="n">endpoint</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">HF_ENDPOINT</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

        <span class="n">uploaded_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">additions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">CommitOperationAdd</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">shard</span> <span class="ow">in</span> <span class="n">index_shards</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">embed_external_files</span><span class="p">:</span>
                <span class="nb">format</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">format</span>
                <span class="n">shard</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="s2">&quot;arrow&quot;</span><span class="p">)</span>
                <span class="n">shard</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="n">embed_table_storage</span><span class="p">,</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">,</span>
                    <span class="n">keep_in_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">shard</span> <span class="o">=</span> <span class="n">shard</span><span class="o">.</span><span class="n">with_format</span><span class="p">(</span><span class="o">**</span><span class="nb">format</span><span class="p">)</span>
            <span class="n">shard_path_in_repo</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">index</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">-of-</span><span class="si">{</span><span class="n">num_shards</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">.parquet&quot;</span>
            <span class="n">buffer</span> <span class="o">=</span> <span class="n">BytesIO</span><span class="p">()</span>
            <span class="n">shard</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">writer_batch_size</span><span class="p">)</span>
            <span class="n">parquet_content</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
            <span class="n">uploaded_size</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parquet_content</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">buffer</span>
            <span class="n">shard_addition</span> <span class="o">=</span> <span class="n">CommitOperationAdd</span><span class="p">(</span><span class="n">path_in_repo</span><span class="o">=</span><span class="n">shard_path_in_repo</span><span class="p">,</span> <span class="n">path_or_fileobj</span><span class="o">=</span><span class="n">parquet_content</span><span class="p">)</span>
            <span class="n">api</span><span class="o">.</span><span class="n">preupload_lfs_files</span><span class="p">(</span>
                <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
                <span class="n">additions</span><span class="o">=</span><span class="p">[</span><span class="n">shard_addition</span><span class="p">],</span>
                <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                <span class="n">create_pr</span><span class="o">=</span><span class="n">create_pr</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">additions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shard_addition</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">job_id</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">1</span>

        <span class="k">yield</span> <span class="n">job_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">additions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_push_parquet_shards_to_hub</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">revision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">create_pr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
        <span class="n">max_shard_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
        <span class="n">num_shards</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">embed_external_files</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">CommitOperationAdd</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pushes the dataset shards as Parquet files to the hub.</span>

<span class="sd">        Returns:</span>
<span class="sd">            additions (`List[CommitOperation]`): list of the `CommitOperationAdd` of the uploaded shards</span>
<span class="sd">            uploaded_size (`int`): number of uploaded bytes to the repository</span>
<span class="sd">            dataset_nbytes (`int`): approximate size in bytes of the uploaded dataset after uncompression</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.arrow_writer</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_writer_batch_size_from_data_size</span><span class="p">,</span> <span class="n">get_writer_batch_size_from_features</span>

        <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_nbytes</span><span class="p">()</span>
        <span class="n">writer_batch_size</span> <span class="o">=</span> <span class="n">get_writer_batch_size_from_features</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span> <span class="ow">or</span> <span class="n">get_writer_batch_size_from_data_size</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">dataset_nbytes</span>
        <span class="p">)</span>

        <span class="c1"># Find decodable columns, because if there are any, we need to:</span>
        <span class="c1"># embed the bytes from the files in the shards</span>
        <span class="n">decodable_columns</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">require_decoding</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ignore_decode_attribute</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">embed_external_files</span>
            <span class="k">else</span> <span class="p">[]</span>
        <span class="p">)</span>
        <span class="n">embed_external_files</span> <span class="o">=</span> <span class="n">embed_external_files</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="n">decodable_columns</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_shards</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_shard_size</span> <span class="o">=</span> <span class="n">convert_file_size_to_int</span><span class="p">(</span><span class="n">max_shard_size</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">MAX_SHARD_SIZE</span><span class="p">)</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_nbytes</span> <span class="o">/</span> <span class="n">max_shard_size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">num_proc</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">additions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">CommitOperationAdd</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">num_jobs</span> <span class="o">=</span> <span class="n">num_proc</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="n">kwargs_iterable</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;self&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_jobs</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">job_id</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="s2">&quot;job_id&quot;</span><span class="p">:</span> <span class="n">job_id</span><span class="p">,</span>
                <span class="s2">&quot;num_jobs&quot;</span><span class="p">:</span> <span class="n">num_jobs</span><span class="p">,</span>
                <span class="s2">&quot;repo_id&quot;</span><span class="p">:</span> <span class="n">repo_id</span><span class="p">,</span>
                <span class="s2">&quot;data_dir&quot;</span><span class="p">:</span> <span class="n">data_dir</span><span class="p">,</span>
                <span class="s2">&quot;split&quot;</span><span class="p">:</span> <span class="n">split</span><span class="p">,</span>
                <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="n">token</span><span class="p">,</span>
                <span class="s2">&quot;revision&quot;</span><span class="p">:</span> <span class="n">revision</span><span class="p">,</span>
                <span class="s2">&quot;create_pr&quot;</span><span class="p">:</span> <span class="n">create_pr</span><span class="p">,</span>
                <span class="s2">&quot;num_shards&quot;</span><span class="p">:</span> <span class="n">num_shards</span><span class="p">,</span>
                <span class="s2">&quot;embed_external_files&quot;</span><span class="p">:</span> <span class="n">embed_external_files</span><span class="p">,</span>
                <span class="s2">&quot;writer_batch_size&quot;</span><span class="p">:</span> <span class="n">writer_batch_size</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">job_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_jobs</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="s2">&quot;Uploading the dataset shards&quot;</span>
        <span class="n">desc</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; (num_proc=</span><span class="si">{</span><span class="n">num_proc</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_proc</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">hf_tqdm</span><span class="p">(</span>
            <span class="n">unit</span><span class="o">=</span><span class="s2">&quot; shards&quot;</span><span class="p">,</span>
            <span class="n">total</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">num_proc</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">Pool</span><span class="p">(</span><span class="n">num_proc</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
            <span class="n">update_stream</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">Dataset</span><span class="o">.</span><span class="n">_push_parquet_shards_to_hub_single</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs_iterable</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">iflatmap_unordered</span><span class="p">(</span>
                    <span class="n">pool</span><span class="p">,</span>
                    <span class="n">Dataset</span><span class="o">.</span><span class="n">_push_parquet_shards_to_hub_single</span><span class="p">,</span>
                    <span class="n">kwargs_iterable</span><span class="o">=</span><span class="n">kwargs_iterable</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">update_stream</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
                    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">additions</span> <span class="o">+=</span> <span class="n">content</span>

        <span class="n">uploaded_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">addition</span><span class="o">.</span><span class="n">upload_info</span><span class="o">.</span><span class="n">size</span> <span class="k">for</span> <span class="n">addition</span> <span class="ow">in</span> <span class="n">additions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">additions</span><span class="p">,</span> <span class="n">uploaded_size</span><span class="p">,</span> <span class="n">dataset_nbytes</span>

<div class="viewcode-block" id="Dataset.push_to_hub">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.push_to_hub.html#datasets.Dataset.push_to_hub">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">push_to_hub</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">config_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">set_default</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">commit_message</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">commit_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">private</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">revision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">create_pr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_shard_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_shards</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embed_external_files</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">num_proc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CommitInfo</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pushes the dataset to the hub as a Parquet dataset.</span>
<span class="sd">        The dataset is pushed using HTTP requests and does not need to have neither git or git-lfs installed.</span>

<span class="sd">        The resulting Parquet files are self-contained by default. If your dataset contains [`Image`], [`Audio`] or [`Video`]</span>
<span class="sd">        data, the Parquet files will store the bytes of your images or audio files.</span>
<span class="sd">        You can disable this by setting `embed_external_files` to `False`.</span>

<span class="sd">        Args:</span>
<span class="sd">            repo_id (`str`):</span>
<span class="sd">                The ID of the repository to push to in the following format: `&lt;user&gt;/&lt;dataset_name&gt;` or</span>
<span class="sd">                `&lt;org&gt;/&lt;dataset_name&gt;`. Also accepts `&lt;dataset_name&gt;`, which will default to the namespace</span>
<span class="sd">                of the logged-in user.</span>
<span class="sd">            config_name (`str`, defaults to &quot;default&quot;):</span>
<span class="sd">                The configuration name (or subset) of a dataset. Defaults to &quot;default&quot;.</span>
<span class="sd">            set_default (`bool`, *optional*):</span>
<span class="sd">                Whether to set this configuration as the default one. Otherwise, the default configuration is the one</span>
<span class="sd">                named &quot;default&quot;.</span>
<span class="sd">            split (`str`, *optional*):</span>
<span class="sd">                The name of the split that will be given to that dataset. Defaults to `self.split`.</span>
<span class="sd">            data_dir (`str`, *optional*):</span>
<span class="sd">                Directory name that will contain the uploaded data files. Defaults to the `config_name` if different</span>
<span class="sd">                from &quot;default&quot;, else &quot;data&quot;.</span>

<span class="sd">                &lt;Added version=&quot;2.17.0&quot;/&gt;</span>
<span class="sd">            commit_message (`str`, *optional*):</span>
<span class="sd">                Message to commit while pushing. Will default to `&quot;Upload dataset&quot;`.</span>
<span class="sd">            commit_description (`str`, *optional*):</span>
<span class="sd">                Description of the commit that will be created.</span>
<span class="sd">                Additionally, description of the PR if a PR is created (`create_pr` is True).</span>

<span class="sd">                &lt;Added version=&quot;2.16.0&quot;/&gt;</span>
<span class="sd">            private (`bool`, *optional*):</span>
<span class="sd">                Whether to make the repo private. If `None` (default), the repo will be public unless the</span>
<span class="sd">                organization&#39;s default is private. This value is ignored if the repo already exists.</span>
<span class="sd">            token (`str`, *optional*):</span>
<span class="sd">                An optional authentication token for the Hugging Face Hub. If no token is passed, will default</span>
<span class="sd">                to the token saved locally when logging in with `huggingface-cli login`. Will raise an error</span>
<span class="sd">                if no token is passed and the user is not logged-in.</span>
<span class="sd">            revision (`str`, *optional*):</span>
<span class="sd">                Branch to push the uploaded files to. Defaults to the `&quot;main&quot;` branch.</span>

<span class="sd">                &lt;Added version=&quot;2.15.0&quot;/&gt;</span>
<span class="sd">            create_pr (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether to create a PR with the uploaded files or directly commit.</span>

<span class="sd">                &lt;Added version=&quot;2.15.0&quot;/&gt;</span>
<span class="sd">            max_shard_size (`int` or `str`, *optional*, defaults to `&quot;500MB&quot;`):</span>
<span class="sd">                The maximum size of the dataset shards to be uploaded to the hub. If expressed as a string, needs to be digits followed by</span>
<span class="sd">                a unit (like `&quot;5MB&quot;`).</span>
<span class="sd">            num_shards (`int`, *optional*):</span>
<span class="sd">                Number of shards to write. By default, the number of shards depends on `max_shard_size`.</span>

<span class="sd">                &lt;Added version=&quot;2.8.0&quot;/&gt;</span>
<span class="sd">            embed_external_files (`bool`, defaults to `True`):</span>
<span class="sd">                Whether to embed file bytes in the shards.</span>
<span class="sd">                In particular, this will do the following before the push for the fields of type:</span>

<span class="sd">                - [`Audio`] and [`Image`]: remove local path information and embed file content in the Parquet files.</span>
<span class="sd">            num_proc (`int`, *optional*, defaults to `None`):</span>
<span class="sd">                Number of processes when preparing and uploading the dataset.</span>
<span class="sd">                This is helpful if the dataset is made of many samples or media files to embed.</span>
<span class="sd">                Multiprocessing is disabled by default.</span>

<span class="sd">                &lt;Added version=&quot;4.0.0&quot;/&gt;</span>

<span class="sd">        Return:</span>
<span class="sd">            huggingface_hub.CommitInfo</span>

<span class="sd">        Example:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;)</span>
<span class="sd">        &gt;&gt;&gt; dataset_dict.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, private=True)</span>
<span class="sd">        &gt;&gt;&gt; dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, max_shard_size=&quot;1GB&quot;)</span>
<span class="sd">        &gt;&gt;&gt; dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, num_shards=1024)</span>
<span class="sd">        ```</span>

<span class="sd">        If your dataset has multiple splits (e.g. train/validation/test):</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; train_dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; val_dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # later</span>
<span class="sd">        &gt;&gt;&gt; dataset = load_dataset(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;)</span>
<span class="sd">        &gt;&gt;&gt; train_dataset = dataset[&quot;train&quot;]</span>
<span class="sd">        &gt;&gt;&gt; val_dataset = dataset[&quot;validation&quot;]</span>
<span class="sd">        ```</span>

<span class="sd">        If you want to add a new configuration (or subset) to a dataset (e.g. if the dataset has multiple tasks/versions/languages):</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; english_dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, &quot;en&quot;)</span>
<span class="sd">        &gt;&gt;&gt; french_dataset.push_to_hub(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, &quot;fr&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # later</span>
<span class="sd">        &gt;&gt;&gt; english_dataset = load_dataset(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, &quot;en&quot;)</span>
<span class="sd">        &gt;&gt;&gt; french_dataset = load_dataset(&quot;&lt;organization&gt;/&lt;dataset_id&gt;&quot;, &quot;fr&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;Video(&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;push_to_hub is not implemented for video datasets, instead you should upload the video files &quot;</span>
                <span class="s2">&quot;using e.g. the huggingface_hub library and optionally upload a metadata.csv or metadata.jsonl &quot;</span>
                <span class="s2">&quot;file containing other information like video captions, features or labels. More information &quot;</span>
                <span class="s2">&quot;at https://huggingface.co/docs/datasets/main/en/video_load#videofolder&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">config_name</span> <span class="o">==</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`config_name` cannot be &#39;data&#39;. Please, choose another name for configuration.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_shard_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_shards</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Failed to push_to_hub: please specify either max_shard_size or num_shards, but not both.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">split</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">split</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;train&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">_split_re</span><span class="p">,</span> <span class="n">split</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Split name should match &#39;</span><span class="si">{</span><span class="n">_split_re</span><span class="si">}</span><span class="s2">&#39; but got &#39;</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>

        <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">(</span><span class="n">endpoint</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">HF_ENDPOINT</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">repo_id</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">repo_info</span><span class="p">(</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">id</span>
        <span class="k">except</span> <span class="n">RepositoryNotFoundError</span><span class="p">:</span>
            <span class="n">repo_url</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">create_repo</span><span class="p">(</span>
                <span class="n">repo_id</span><span class="p">,</span>
                <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                <span class="n">private</span><span class="o">=</span><span class="n">private</span><span class="p">,</span>
                <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">repo_id</span> <span class="o">=</span> <span class="n">repo_url</span><span class="o">.</span><span class="n">repo_id</span>

        <span class="k">if</span> <span class="n">revision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">revision</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;refs/pr/&quot;</span><span class="p">):</span>
            <span class="c1"># We do not call create_branch for a PR reference: 400 Bad Request</span>
            <span class="n">api</span><span class="o">.</span><span class="n">create_branch</span><span class="p">(</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">branch</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">data_dir</span><span class="p">:</span>
            <span class="n">data_dir</span> <span class="o">=</span> <span class="n">config_name</span> <span class="k">if</span> <span class="n">config_name</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span> <span class="k">else</span> <span class="s2">&quot;data&quot;</span>  <span class="c1"># for backward compatibility</span>

        <span class="n">additions</span><span class="p">,</span> <span class="n">uploaded_size</span><span class="p">,</span> <span class="n">dataset_nbytes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_push_parquet_shards_to_hub</span><span class="p">(</span>
            <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
            <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
            <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
            <span class="n">max_shard_size</span><span class="o">=</span><span class="n">max_shard_size</span><span class="p">,</span>
            <span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span>
            <span class="n">create_pr</span><span class="o">=</span><span class="n">create_pr</span><span class="p">,</span>
            <span class="n">embed_external_files</span><span class="o">=</span><span class="n">embed_external_files</span><span class="p">,</span>
            <span class="n">num_proc</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_deletions_and_dataset_card</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">CommitOperationDelete</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
            <span class="n">parent_commit</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">repo_info</span><span class="p">(</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">)</span><span class="o">.</span><span class="n">sha</span>

            <span class="c1"># Check if the repo already has a README.md and/or a dataset_infos.json to update them with the new split info (size and pattern)</span>
            <span class="c1"># and delete old split shards (if they exist)</span>
            <span class="n">repo_with_dataset_card</span><span class="p">,</span> <span class="n">repo_with_dataset_infos</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span>
            <span class="n">deletions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">CommitOperationDelete</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">deleted_size</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">repo_splits</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># use a list to keep the order of the splits</span>
            <span class="n">repo_files_to_add</span> <span class="o">=</span> <span class="p">[</span><span class="n">addition</span><span class="o">.</span><span class="n">path_in_repo</span> <span class="k">for</span> <span class="n">addition</span> <span class="ow">in</span> <span class="n">additions</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">repo_file</span> <span class="ow">in</span> <span class="n">api</span><span class="o">.</span><span class="n">list_repo_tree</span><span class="p">(</span>
                <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">parent_commit</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">repo_file</span><span class="p">,</span> <span class="n">RepoFile</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span> <span class="o">==</span> <span class="n">config</span><span class="o">.</span><span class="n">REPOCARD_FILENAME</span><span class="p">:</span>
                    <span class="n">repo_with_dataset_card</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span> <span class="o">==</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASETDICT_INFOS_FILENAME</span><span class="p">:</span>
                    <span class="n">repo_with_dataset_infos</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="p">(</span>
                    <span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">-&quot;</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">repo_files_to_add</span>
                <span class="p">):</span>
                    <span class="n">deletions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">CommitOperationDelete</span><span class="p">(</span><span class="n">path_in_repo</span><span class="o">=</span><span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span><span class="p">))</span>
                    <span class="n">deleted_size</span> <span class="o">+=</span> <span class="n">repo_file</span><span class="o">.</span><span class="n">size</span>
                <span class="k">elif</span> <span class="n">fnmatch</span><span class="o">.</span><span class="n">fnmatch</span><span class="p">(</span>
                    <span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span><span class="p">,</span>
                    <span class="n">PUSH_TO_HUB_WITHOUT_METADATA_CONFIGS_SPLIT_PATTERN_SHARDED</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{split}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;*&quot;</span><span class="p">),</span>
                <span class="p">):</span>
                    <span class="n">pattern</span> <span class="o">=</span> <span class="n">glob_pattern_to_regex</span><span class="p">(</span><span class="n">PUSH_TO_HUB_WITHOUT_METADATA_CONFIGS_SPLIT_PATTERN_SHARDED</span><span class="p">)</span>
                    <span class="n">split_pattern_fields</span> <span class="o">=</span> <span class="n">string_to_dict</span><span class="p">(</span><span class="n">repo_file</span><span class="o">.</span><span class="n">rfilename</span><span class="p">,</span> <span class="n">pattern</span><span class="p">)</span>
                    <span class="k">assert</span> <span class="n">split_pattern_fields</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="n">repo_split</span> <span class="o">=</span> <span class="n">split_pattern_fields</span><span class="p">[</span><span class="s2">&quot;split&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">repo_split</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">repo_splits</span><span class="p">:</span>
                        <span class="n">repo_splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">repo_split</span><span class="p">)</span>

            <span class="n">organization</span><span class="p">,</span> <span class="n">dataset_name</span> <span class="o">=</span> <span class="n">repo_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">in</span> <span class="n">repo_id</span> <span class="k">else</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">repo_id</span><span class="p">)</span>
            <span class="n">info_to_dump</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">download_checksums</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">download_size</span> <span class="o">=</span> <span class="n">uploaded_size</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="n">dataset_nbytes</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">size_in_bytes</span> <span class="o">=</span> <span class="n">uploaded_size</span> <span class="o">+</span> <span class="n">dataset_nbytes</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">config_name</span> <span class="o">=</span> <span class="n">config_name</span>
            <span class="n">info_to_dump</span><span class="o">.</span><span class="n">splits</span> <span class="o">=</span> <span class="n">SplitDict</span><span class="p">(</span>
                <span class="p">{</span><span class="n">split</span><span class="p">:</span> <span class="n">SplitInfo</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">num_bytes</span><span class="o">=</span><span class="n">dataset_nbytes</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">dataset_name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">)}</span>
            <span class="p">)</span>
            <span class="c1"># get the info from the README to update them</span>
            <span class="k">if</span> <span class="n">repo_with_dataset_card</span><span class="p">:</span>
                <span class="n">dataset_card_path</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">hf_hub_download</span><span class="p">(</span>
                    <span class="n">repo_id</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">REPOCARD_FILENAME</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">parent_commit</span>
                <span class="p">)</span>
                <span class="n">dataset_card</span> <span class="o">=</span> <span class="n">DatasetCard</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">dataset_card_path</span><span class="p">))</span>
                <span class="n">dataset_card_data</span> <span class="o">=</span> <span class="n">dataset_card</span><span class="o">.</span><span class="n">data</span>
                <span class="n">metadata_configs</span> <span class="o">=</span> <span class="n">MetadataConfigs</span><span class="o">.</span><span class="n">from_dataset_card_data</span><span class="p">(</span><span class="n">dataset_card_data</span><span class="p">)</span>
                <span class="n">dataset_infos</span><span class="p">:</span> <span class="n">DatasetInfosDict</span> <span class="o">=</span> <span class="n">DatasetInfosDict</span><span class="o">.</span><span class="n">from_dataset_card_data</span><span class="p">(</span><span class="n">dataset_card_data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">dataset_infos</span> <span class="ow">and</span> <span class="n">config_name</span> <span class="ow">in</span> <span class="n">dataset_infos</span><span class="p">:</span>
                    <span class="n">repo_info</span> <span class="o">=</span> <span class="n">dataset_infos</span><span class="p">[</span><span class="n">config_name</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">repo_info</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># get the deprecated dataset_infos.json to update them</span>
            <span class="k">elif</span> <span class="n">repo_with_dataset_infos</span><span class="p">:</span>
                <span class="n">dataset_card</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">dataset_card_data</span> <span class="o">=</span> <span class="n">DatasetCardData</span><span class="p">()</span>
                <span class="n">metadata_configs</span> <span class="o">=</span> <span class="n">MetadataConfigs</span><span class="p">()</span>
                <span class="n">dataset_infos_path</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">hf_hub_download</span><span class="p">(</span>
                    <span class="n">repo_id</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASETDICT_INFOS_FILENAME</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">parent_commit</span>
                <span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset_infos_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">dataset_infos</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                    <span class="n">dataset_info</span> <span class="o">=</span> <span class="n">dataset_infos</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">config_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="n">dataset_infos</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="n">repo_info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">dataset_info</span><span class="p">)</span> <span class="k">if</span> <span class="n">dataset_info</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dataset_card</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">dataset_card_data</span> <span class="o">=</span> <span class="n">DatasetCardData</span><span class="p">()</span>
                <span class="n">metadata_configs</span> <span class="o">=</span> <span class="n">MetadataConfigs</span><span class="p">()</span>
                <span class="n">repo_info</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># update the total info to dump from existing info</span>
            <span class="k">if</span> <span class="n">repo_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Updating downloaded metadata with the new split.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span> <span class="ow">and</span> <span class="nb">list</span><span class="p">(</span><span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span><span class="p">)</span> <span class="o">!=</span> <span class="p">[</span><span class="n">split</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="o">!=</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">features</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Features of the new split don&#39;t match the features of the existing splits on the hub: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">repo_info</span><span class="o">.</span><span class="n">features</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>

                    <span class="k">if</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span><span class="p">:</span>
                        <span class="n">repo_info</span><span class="o">.</span><span class="n">download_size</span> <span class="o">-=</span> <span class="n">deleted_size</span>
                        <span class="n">repo_info</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">-=</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">SplitInfo</span><span class="p">())</span><span class="o">.</span><span class="n">num_bytes</span> <span class="ow">or</span> <span class="mi">0</span>

                    <span class="n">repo_info</span><span class="o">.</span><span class="n">download_checksums</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">repo_info</span><span class="o">.</span><span class="n">download_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">repo_info</span><span class="o">.</span><span class="n">download_size</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">uploaded_size</span>
                    <span class="n">repo_info</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">repo_info</span><span class="o">.</span><span class="n">dataset_size</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dataset_nbytes</span>
                    <span class="n">repo_info</span><span class="o">.</span><span class="n">size_in_bytes</span> <span class="o">=</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">download_size</span> <span class="o">+</span> <span class="n">repo_info</span><span class="o">.</span><span class="n">dataset_size</span>
                    <span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="n">repo_info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">SplitInfo</span><span class="p">(</span>
                        <span class="n">split</span><span class="p">,</span> <span class="n">num_bytes</span><span class="o">=</span><span class="n">dataset_nbytes</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">dataset_name</span><span class="o">=</span><span class="n">dataset_name</span>
                    <span class="p">)</span>
                    <span class="n">info_to_dump</span> <span class="o">=</span> <span class="n">repo_info</span>
            <span class="c1"># create the metadata configs if it was uploaded with push_to_hub before metadata configs existed</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata_configs</span> <span class="ow">and</span> <span class="n">repo_splits</span><span class="p">:</span>
                <span class="n">default_metadata_configs_to_dump</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;data_files&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;split&quot;</span><span class="p">:</span> <span class="n">split</span><span class="p">,</span> <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;data/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">-*&quot;</span><span class="p">}</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">repo_splits</span><span class="p">]</span>
                <span class="p">}</span>
                <span class="n">MetadataConfigs</span><span class="p">({</span><span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="n">default_metadata_configs_to_dump</span><span class="p">})</span><span class="o">.</span><span class="n">to_dataset_card_data</span><span class="p">(</span><span class="n">dataset_card_data</span><span class="p">)</span>
            <span class="c1"># update the metadata configs</span>
            <span class="k">if</span> <span class="n">config_name</span> <span class="ow">in</span> <span class="n">metadata_configs</span><span class="p">:</span>
                <span class="n">metadata_config</span> <span class="o">=</span> <span class="n">metadata_configs</span><span class="p">[</span><span class="n">config_name</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;data_files&quot;</span> <span class="ow">in</span> <span class="n">metadata_config</span><span class="p">:</span>
                    <span class="n">data_files_to_dump</span> <span class="o">=</span> <span class="n">sanitize_patterns</span><span class="p">(</span><span class="n">metadata_config</span><span class="p">[</span><span class="s2">&quot;data_files&quot;</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">data_files_to_dump</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="c1"># add the new split</span>
                <span class="n">data_files_to_dump</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">-*&quot;</span><span class="p">]</span>
                <span class="n">metadata_config_to_dump</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;data_files&quot;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;split&quot;</span><span class="p">:</span> <span class="n">_split</span><span class="p">,</span>
                            <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">_pattern</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_pattern</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">_pattern</span><span class="p">,</span>
                        <span class="p">}</span>
                        <span class="k">for</span> <span class="n">_split</span><span class="p">,</span> <span class="n">_pattern</span> <span class="ow">in</span> <span class="n">data_files_to_dump</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">]</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">metadata_config_to_dump</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;data_files&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;split&quot;</span><span class="p">:</span> <span class="n">split</span><span class="p">,</span> <span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">-*&quot;</span><span class="p">}]}</span>
            <span class="n">configs_to_dump</span> <span class="o">=</span> <span class="p">{</span><span class="n">config_name</span><span class="p">:</span> <span class="n">metadata_config_to_dump</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">set_default</span> <span class="ow">and</span> <span class="n">config_name</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">metadata_configs</span><span class="p">:</span>
                    <span class="n">current_default_config_name</span> <span class="o">=</span> <span class="n">metadata_configs</span><span class="o">.</span><span class="n">get_default_config_name</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">current_default_config_name</span> <span class="o">==</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;There exists a configuration named &#39;default&#39;. To set a different configuration as default, &quot;</span>
                            <span class="s2">&quot;rename the &#39;default&#39; one first.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">current_default_config_name</span><span class="p">:</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="n">metadata_configs</span><span class="p">[</span><span class="n">current_default_config_name</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>
                        <span class="n">configs_to_dump</span><span class="p">[</span><span class="n">current_default_config_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">metadata_configs</span><span class="p">[</span><span class="n">current_default_config_name</span><span class="p">]</span>
                <span class="n">metadata_config_to_dump</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># push to the deprecated dataset_infos.json</span>
            <span class="k">if</span> <span class="n">repo_with_dataset_infos</span><span class="p">:</span>
                <span class="n">dataset_infos_path</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">hf_hub_download</span><span class="p">(</span>
                    <span class="n">repo_id</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">DATASETDICT_INFOS_FILENAME</span><span class="p">,</span> <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">parent_commit</span>
                <span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset_infos_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">dataset_infos</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="n">dataset_infos</span><span class="p">[</span><span class="n">config_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="n">info_to_dump</span><span class="p">)</span>
                <span class="n">new_dataset_infos</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dataset_infos</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_dataset_infos</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># push to README</span>
            <span class="n">DatasetInfosDict</span><span class="p">({</span><span class="n">config_name</span><span class="p">:</span> <span class="n">info_to_dump</span><span class="p">})</span><span class="o">.</span><span class="n">to_dataset_card_data</span><span class="p">(</span><span class="n">dataset_card_data</span><span class="p">)</span>
            <span class="n">MetadataConfigs</span><span class="p">(</span><span class="n">configs_to_dump</span><span class="p">)</span><span class="o">.</span><span class="n">to_dataset_card_data</span><span class="p">(</span><span class="n">dataset_card_data</span><span class="p">)</span>
            <span class="n">new_dataset_card</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">DatasetCard</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;---</span><span class="se">\n</span><span class="si">{</span><span class="n">dataset_card_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">---</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">dataset_card</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dataset_card</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">parent_commit</span><span class="p">,</span> <span class="n">deletions</span><span class="p">,</span> <span class="n">new_dataset_card</span><span class="p">,</span> <span class="n">new_dataset_infos</span>

        <span class="n">commit_message</span> <span class="o">=</span> <span class="n">commit_message</span> <span class="k">if</span> <span class="n">commit_message</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;Upload dataset&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">additions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">config</span><span class="o">.</span><span class="n">UPLOADS_MAX_NUMBER_PER_COMMIT</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of files to upload is larger than </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">UPLOADS_MAX_NUMBER_PER_COMMIT</span><span class="si">}</span><span class="s2">. Splitting the push into multiple commits.&quot;</span>
            <span class="p">)</span>
            <span class="n">num_commits</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">additions</span><span class="p">)</span> <span class="o">/</span> <span class="n">config</span><span class="o">.</span><span class="n">UPLOADS_MAX_NUMBER_PER_COMMIT</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_commits</span><span class="p">):</span>
                <span class="n">operations</span> <span class="o">=</span> <span class="n">additions</span><span class="p">[</span>
                    <span class="n">i</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">UPLOADS_MAX_NUMBER_PER_COMMIT</span> <span class="p">:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">UPLOADS_MAX_NUMBER_PER_COMMIT</span>
                <span class="p">]</span>
                <span class="k">for</span> <span class="n">retry</span><span class="p">,</span> <span class="n">sleep_time</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">itertools</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">30</span><span class="p">)),</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
                    <span class="c1"># We need to retry if another commit happens at the same time</span>
                    <span class="n">sleep_time</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">commit_info</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">create_commit</span><span class="p">(</span>
                            <span class="n">repo_id</span><span class="p">,</span>
                            <span class="n">operations</span><span class="o">=</span><span class="n">operations</span><span class="p">,</span>
                            <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot; (part </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">-of-</span><span class="si">{</span><span class="n">num_commits</span><span class="si">:</span><span class="s2">05d</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
                            <span class="n">commit_description</span><span class="o">=</span><span class="n">commit_description</span><span class="p">,</span>
                            <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                            <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                            <span class="n">create_pr</span><span class="o">=</span><span class="n">create_pr</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">except</span> <span class="n">HfHubHTTPError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">err</span><span class="o">.</span><span class="n">__context__</span>
                            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="p">,</span> <span class="n">HfHubHTTPError</span><span class="p">)</span>
                            <span class="ow">and</span> <span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">409</span>
                        <span class="p">):</span>
                            <span class="c1"># 409 is Conflict (another commit is in progress)</span>
                            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">sleep_time</span><span class="p">)</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Retrying intermediate commit for </span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2">/n with status_code </span><span class="si">{</span><span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">)&quot;</span>
                            <span class="p">)</span>
                            <span class="k">continue</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span>
                    <span class="k">break</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Commit #</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> completed&quot;</span>
                    <span class="o">+</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot; (still </span><span class="si">{</span><span class="n">num_commits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> to go)&quot;</span> <span class="k">if</span> <span class="n">num_commits</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="o">+</span> <span class="s2">&quot;.&quot;</span>
                <span class="p">)</span>
            <span class="n">last_commit_additions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">last_commit_additions</span> <span class="o">=</span> <span class="n">additions</span>

        <span class="k">for</span> <span class="n">retry</span><span class="p">,</span> <span class="n">sleep_time</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">itertools</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">30</span><span class="p">)),</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># We need to retry if there was a commit in between in case it touched the dataset card data</span>
            <span class="n">sleep_time</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
            <span class="n">parent_commit</span><span class="p">,</span> <span class="n">deletions</span><span class="p">,</span> <span class="n">dataset_card</span><span class="p">,</span> <span class="n">dataset_infos</span> <span class="o">=</span> <span class="n">get_deletions_and_dataset_card</span><span class="p">()</span>
            <span class="n">dataset_card_additions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">dataset_infos</span><span class="p">:</span>
                <span class="n">dataset_card_additions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">CommitOperationAdd</span><span class="p">(</span>
                        <span class="n">path_in_repo</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">DATASETDICT_INFOS_FILENAME</span><span class="p">,</span>
                        <span class="n">path_or_fileobj</span><span class="o">=</span><span class="n">dataset_infos</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">dataset_card_additions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">CommitOperationAdd</span><span class="p">(</span><span class="n">path_in_repo</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">REPOCARD_FILENAME</span><span class="p">,</span> <span class="n">path_or_fileobj</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">dataset_card</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span>
            <span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">commit_info</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">create_commit</span><span class="p">(</span>
                    <span class="n">repo_id</span><span class="p">,</span>
                    <span class="n">operations</span><span class="o">=</span><span class="n">last_commit_additions</span> <span class="o">+</span> <span class="n">dataset_card_additions</span> <span class="o">+</span> <span class="n">deletions</span><span class="p">,</span>
                    <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">,</span>
                    <span class="n">commit_description</span><span class="o">=</span><span class="n">commit_description</span><span class="p">,</span>
                    <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span>
                    <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                    <span class="n">create_pr</span><span class="o">=</span><span class="n">create_pr</span><span class="p">,</span>
                    <span class="n">parent_commit</span><span class="o">=</span><span class="n">parent_commit</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="n">HfHubHTTPError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">err</span><span class="o">.</span><span class="n">__context__</span>
                    <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="p">,</span> <span class="n">HfHubHTTPError</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">412</span><span class="p">,</span> <span class="mi">409</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="c1"># 412 is Precondition failed (parent_commit isn&#39;t satisfied)</span>
                    <span class="c1"># 409 is Conflict (another commit is in progress)</span>
                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">sleep_time</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Retrying commit for </span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">retry</span><span class="si">}</span><span class="s2">/n with status_code </span><span class="si">{</span><span class="n">err</span><span class="o">.</span><span class="n">__context__</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">)&quot;</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>
            <span class="k">break</span>

        <span class="k">return</span> <span class="n">commit_info</span></div>


<div class="viewcode-block" id="Dataset.add_column">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.add_column.html#datasets.Dataset.add_column">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_column</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FeatureType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add column to Dataset.</span>

<span class="sd">        &lt;Added version=&quot;1.7&quot;/&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            name (`str`):</span>
<span class="sd">                Column name.</span>
<span class="sd">            column (`list` or `np.array`):</span>
<span class="sd">                Column data to be added.</span>
<span class="sd">            feature (`FeatureType` or `None`, defaults to `None`):</span>
<span class="sd">                Column datatype.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; more_text = ds[&quot;text&quot;]</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.add_column(name=&quot;text_2&quot;, column=more_text)</span>
<span class="sd">        &gt;&gt;&gt; ds</span>
<span class="sd">        Dataset({</span>
<span class="sd">            features: [&#39;text&#39;, &#39;label&#39;, &#39;text_2&#39;],</span>
<span class="sd">            num_rows: 1066</span>
<span class="sd">        })</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">feature</span><span class="p">:</span>
            <span class="n">pyarrow_schema</span> <span class="o">=</span> <span class="n">Features</span><span class="p">({</span><span class="n">name</span><span class="p">:</span> <span class="n">feature</span><span class="p">})</span><span class="o">.</span><span class="n">arrow_schema</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pyarrow_schema</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">column_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">({</span><span class="n">name</span><span class="p">:</span> <span class="n">column</span><span class="p">},</span> <span class="n">schema</span><span class="o">=</span><span class="n">pyarrow_schema</span><span class="p">)</span>
        <span class="n">_check_column_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span> <span class="o">+</span> <span class="n">column_table</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten_indices</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span>
        <span class="c1"># Concatenate tables horizontally</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">([</span><span class="n">dataset</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span> <span class="n">column_table</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Update features</span>
        <span class="n">info</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">Features</span><span class="o">.</span><span class="n">from_arrow_schema</span><span class="p">(</span><span class="n">column_table</span><span class="o">.</span><span class="n">schema</span><span class="p">))</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span> <span class="n">indices_table</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.add_faiss_index">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.add_faiss_index.html#datasets.Dataset.add_faiss_index">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_faiss_index</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">index_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">string_factory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">custom_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;faiss.Index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">train_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">faiss_verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add a dense index using Faiss for fast retrieval.</span>
<span class="sd">        By default the index is done over the vectors of the specified column.</span>
<span class="sd">        You can specify `device` if you want to run it on GPU (`device` must be the GPU index).</span>
<span class="sd">        You can find more information about Faiss here:</span>

<span class="sd">        - For [string factory](https://github.com/facebookresearch/faiss/wiki/The-index-factory)</span>

<span class="sd">        Args:</span>
<span class="sd">            column (`str`):</span>
<span class="sd">                The column of the vectors to add to the index.</span>
<span class="sd">            index_name (`str`, *optional*):</span>
<span class="sd">                The `index_name`/identifier of the index.</span>
<span class="sd">                This is the `index_name` that is used to call [`~datasets.Dataset.get_nearest_examples`] or [`~datasets.Dataset.search`].</span>
<span class="sd">                By default it corresponds to `column`.</span>
<span class="sd">            device (`Union[int, List[int]]`, *optional*):</span>
<span class="sd">                If positive integer, this is the index of the GPU to use. If negative integer, use all GPUs.</span>
<span class="sd">                If a list of positive integers is passed in, run only on those GPUs. By default it uses the CPU.</span>
<span class="sd">            string_factory (`str`, *optional*):</span>
<span class="sd">                This is passed to the index factory of Faiss to create the index.</span>
<span class="sd">                Default index class is `IndexFlat`.</span>
<span class="sd">            metric_type (`int`, *optional*):</span>
<span class="sd">                Type of metric. Ex: `faiss.METRIC_INNER_PRODUCT` or `faiss.METRIC_L2`.</span>
<span class="sd">            custom_index (`faiss.Index`, *optional*):</span>
<span class="sd">                Custom Faiss index that you already have instantiated and configured for your needs.</span>
<span class="sd">            batch_size (`int`):</span>
<span class="sd">                Size of the batch to use while adding vectors to the `FaissIndex`. Default value is `1000`.</span>
<span class="sd">                &lt;Added version=&quot;2.4.0&quot;/&gt;</span>
<span class="sd">            train_size (`int`, *optional*):</span>
<span class="sd">                If the index needs a training step, specifies how many vectors will be used to train the index.</span>
<span class="sd">            faiss_verbose (`bool`, defaults to `False`):</span>
<span class="sd">                Enable the verbosity of the Faiss index.</span>
<span class="sd">            dtype (`data-type`):</span>
<span class="sd">                The dtype of the numpy arrays that are indexed.</span>
<span class="sd">                Default is `np.float32`.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; ds = datasets.load_dataset(&#39;community-datasets/crime_and_punish&#39;, split=&#39;train&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds_with_embeddings = ds.map(lambda example: {&#39;embeddings&#39;: embed(example[&#39;line&#39;]}))</span>
<span class="sd">        &gt;&gt;&gt; ds_with_embeddings.add_faiss_index(column=&#39;embeddings&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # query</span>
<span class="sd">        &gt;&gt;&gt; scores, retrieved_examples = ds_with_embeddings.get_nearest_examples(&#39;embeddings&#39;, embed(&#39;my new query&#39;), k=10)</span>
<span class="sd">        &gt;&gt;&gt; # save index</span>
<span class="sd">        &gt;&gt;&gt; ds_with_embeddings.save_faiss_index(&#39;embeddings&#39;, &#39;my_index.faiss&#39;)</span>

<span class="sd">        &gt;&gt;&gt; ds = datasets.load_dataset(&#39;community-datasets/crime_and_punish&#39;, split=&#39;train&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # load index</span>
<span class="sd">        &gt;&gt;&gt; ds.load_faiss_index(&#39;embeddings&#39;, &#39;my_index.faiss&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # query</span>
<span class="sd">        &gt;&gt;&gt; scores, retrieved_examples = ds.get_nearest_examples(&#39;embeddings&#39;, embed(&#39;my new query&#39;), k=10)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">formatted_as</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">add_faiss_index</span><span class="p">(</span>
                <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="n">string_factory</span><span class="o">=</span><span class="n">string_factory</span><span class="p">,</span>
                <span class="n">metric_type</span><span class="o">=</span><span class="n">metric_type</span><span class="p">,</span>
                <span class="n">custom_index</span><span class="o">=</span><span class="n">custom_index</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
                <span class="n">faiss_verbose</span><span class="o">=</span><span class="n">faiss_verbose</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="Dataset.add_faiss_index_from_external_arrays">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.add_faiss_index_from_external_arrays.html#datasets.Dataset.add_faiss_index_from_external_arrays">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_faiss_index_from_external_arrays</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">external_arrays</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
        <span class="n">index_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">string_factory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">custom_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;faiss.Index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">train_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">faiss_verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add a dense index using Faiss for fast retrieval.</span>
<span class="sd">        The index is created using the vectors of `external_arrays`.</span>
<span class="sd">        You can specify `device` if you want to run it on GPU (`device` must be the GPU index).</span>
<span class="sd">        You can find more information about Faiss here:</span>

<span class="sd">        - For [string factory](https://github.com/facebookresearch/faiss/wiki/The-index-factory)</span>

<span class="sd">        Args:</span>
<span class="sd">            external_arrays (`np.array`):</span>
<span class="sd">                If you want to use arrays from outside the lib for the index, you can set `external_arrays`.</span>
<span class="sd">                It will use `external_arrays` to create the Faiss index instead of the arrays in the given `column`.</span>
<span class="sd">            index_name (`str`):</span>
<span class="sd">                The `index_name`/identifier of the index.</span>
<span class="sd">                This is the `index_name` that is used to call [`~datasets.Dataset.get_nearest_examples`] or [`~datasets.Dataset.search`].</span>
<span class="sd">            device (Optional `Union[int, List[int]]`, *optional*):</span>
<span class="sd">                If positive integer, this is the index of the GPU to use. If negative integer, use all GPUs.</span>
<span class="sd">                If a list of positive integers is passed in, run only on those GPUs. By default it uses the CPU.</span>
<span class="sd">            string_factory (`str`, *optional*):</span>
<span class="sd">                This is passed to the index factory of Faiss to create the index.</span>
<span class="sd">                Default index class is `IndexFlat`.</span>
<span class="sd">            metric_type (`int`, *optional*):</span>
<span class="sd">                Type of metric. Ex: `faiss.faiss.METRIC_INNER_PRODUCT` or `faiss.METRIC_L2`.</span>
<span class="sd">            custom_index (`faiss.Index`, *optional*):</span>
<span class="sd">                Custom Faiss index that you already have instantiated and configured for your needs.</span>
<span class="sd">            batch_size (`int`, *optional*):</span>
<span class="sd">                Size of the batch to use while adding vectors to the FaissIndex. Default value is 1000.</span>
<span class="sd">                &lt;Added version=&quot;2.4.0&quot;/&gt;</span>
<span class="sd">            train_size (`int`, *optional*):</span>
<span class="sd">                If the index needs a training step, specifies how many vectors will be used to train the index.</span>
<span class="sd">            faiss_verbose (`bool`, defaults to False):</span>
<span class="sd">                Enable the verbosity of the Faiss index.</span>
<span class="sd">            dtype (`numpy.dtype`):</span>
<span class="sd">                The dtype of the numpy arrays that are indexed. Default is np.float32.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">add_faiss_index_from_external_arrays</span><span class="p">(</span>
            <span class="n">external_arrays</span><span class="o">=</span><span class="n">external_arrays</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">string_factory</span><span class="o">=</span><span class="n">string_factory</span><span class="p">,</span>
            <span class="n">metric_type</span><span class="o">=</span><span class="n">metric_type</span><span class="p">,</span>
            <span class="n">custom_index</span><span class="o">=</span><span class="n">custom_index</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">faiss_verbose</span><span class="o">=</span><span class="n">faiss_verbose</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.add_elasticsearch_index">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.add_elasticsearch_index.html#datasets.Dataset.add_elasticsearch_index">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_elasticsearch_index</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">index_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">host</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">port</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">es_client</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;elasticsearch.Elasticsearch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
        <span class="n">es_index_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">es_index_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add a text index using ElasticSearch for fast retrieval. This is done in-place.</span>

<span class="sd">        Args:</span>
<span class="sd">            column (`str`):</span>
<span class="sd">                The column of the documents to add to the index.</span>
<span class="sd">            index_name (`str`, *optional*):</span>
<span class="sd">                The `index_name`/identifier of the index.</span>
<span class="sd">                This is the index name that is used to call [`~Dataset.get_nearest_examples`] or [`~Dataset.search`].</span>
<span class="sd">                By default it corresponds to `column`.</span>
<span class="sd">            host (`str`, *optional*, defaults to `localhost`):</span>
<span class="sd">                Host of where ElasticSearch is running.</span>
<span class="sd">            port (`str`, *optional*, defaults to `9200`):</span>
<span class="sd">                Port of where ElasticSearch is running.</span>
<span class="sd">            es_client (`elasticsearch.Elasticsearch`, *optional*):</span>
<span class="sd">                The elasticsearch client used to create the index if host and port are `None`.</span>
<span class="sd">            es_index_name (`str`, *optional*):</span>
<span class="sd">                The elasticsearch index name used to create the index.</span>
<span class="sd">            es_index_config (`dict`, *optional*):</span>
<span class="sd">                The configuration of the elasticsearch index.</span>
<span class="sd">                Default config is:</span>
<span class="sd">                    ```</span>
<span class="sd">                    {</span>
<span class="sd">                        &quot;settings&quot;: {</span>
<span class="sd">                            &quot;number_of_shards&quot;: 1,</span>
<span class="sd">                            &quot;analysis&quot;: {&quot;analyzer&quot;: {&quot;stop_standard&quot;: {&quot;type&quot;: &quot;standard&quot;, &quot; stopwords&quot;: &quot;_english_&quot;}}},</span>
<span class="sd">                        },</span>
<span class="sd">                        &quot;mappings&quot;: {</span>
<span class="sd">                            &quot;properties&quot;: {</span>
<span class="sd">                                &quot;text&quot;: {</span>
<span class="sd">                                    &quot;type&quot;: &quot;text&quot;,</span>
<span class="sd">                                    &quot;analyzer&quot;: &quot;standard&quot;,</span>
<span class="sd">                                    &quot;similarity&quot;: &quot;BM25&quot;</span>
<span class="sd">                                },</span>
<span class="sd">                            }</span>
<span class="sd">                        },</span>
<span class="sd">                    }</span>
<span class="sd">                    ```</span>
<span class="sd">        Example:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; es_client = elasticsearch.Elasticsearch()</span>
<span class="sd">        &gt;&gt;&gt; ds = datasets.load_dataset(&#39;community-datasets/crime_and_punish&#39;, split=&#39;train&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ds.add_elasticsearch_index(column=&#39;line&#39;, es_client=es_client, es_index_name=&quot;my_es_index&quot;)</span>
<span class="sd">        &gt;&gt;&gt; scores, retrieved_examples = ds.get_nearest_examples(&#39;line&#39;, &#39;my new query&#39;, k=10)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">formatted_as</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">column</span><span class="p">]):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">add_elasticsearch_index</span><span class="p">(</span>
                <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
                <span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span>
                <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">,</span>
                <span class="n">es_client</span><span class="o">=</span><span class="n">es_client</span><span class="p">,</span>
                <span class="n">es_index_name</span><span class="o">=</span><span class="n">es_index_name</span><span class="p">,</span>
                <span class="n">es_index_config</span><span class="o">=</span><span class="n">es_index_config</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="Dataset.add_item">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.html#datasets.Dataset.add_item">[docs]</a>
    <span class="nd">@transmit_format</span>
    <span class="nd">@fingerprint_transform</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">new_fingerprint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add item to Dataset.</span>

<span class="sd">        &lt;Added version=&quot;1.7&quot;/&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            item (`dict`):</span>
<span class="sd">                Item data to be added.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`Dataset`]</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from datasets import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;cornell-movie-review-data/rotten_tomatoes&quot;, split=&quot;validation&quot;)</span>
<span class="sd">        &gt;&gt;&gt; new_review = {&#39;label&#39;: 0, &#39;text&#39;: &#39;this movie is the absolute worst thing I have ever seen&#39;}</span>
<span class="sd">        &gt;&gt;&gt; ds = ds.add_item(new_review)</span>
<span class="sd">        &gt;&gt;&gt; ds[-1]</span>
<span class="sd">        {&#39;label&#39;: 0, &#39;text&#39;: &#39;this movie is the absolute worst thing I have ever seen&#39;}</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">item_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_pydict</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
        <span class="c1"># We don&#39;t call _check_if_features_can_be_aligned here so this cast is &quot;unsafe&quot;</span>
        <span class="n">dset_features</span><span class="p">,</span> <span class="n">item_features</span> <span class="o">=</span> <span class="n">_align_features</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">Features</span><span class="o">.</span><span class="n">from_arrow_schema</span><span class="p">(</span><span class="n">item_table</span><span class="o">.</span><span class="n">schema</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="c1"># Cast to align the schemas of the tables and concatenate the tables</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dset_features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span> <span class="o">!=</span> <span class="n">dset_features</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">,</span>
                <span class="n">item_table</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">item_features</span><span class="o">.</span><span class="n">arrow_schema</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">item_indices_array</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">)],</span> <span class="nb">type</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">uint64</span><span class="p">())</span>
            <span class="n">item_indices_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">([</span><span class="n">item_indices_array</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">])</span>
            <span class="n">indices_table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span> <span class="n">item_indices_table</span><span class="p">])</span>
        <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">item_features</span><span class="p">)</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">table</span><span class="p">,</span>
            <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
            <span class="n">indices_table</span><span class="o">=</span><span class="n">indices_table</span><span class="p">,</span>
            <span class="n">fingerprint</span><span class="o">=</span><span class="n">new_fingerprint</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.align_labels_with_mapping">
<a class="viewcode-back" href="../../api/generated/datasets.Dataset.align_labels_with_mapping.html#datasets.Dataset.align_labels_with_mapping">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">align_labels_with_mapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label2id</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">label_column</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Align the dataset&#39;s label ID and label name mapping to match an input `label2id` mapping.</span>
<span class="sd">        This is useful when you want to ensure that a model&#39;s predicted labels are aligned with the dataset.</span>
<span class="sd">        The alignment in done using the lowercase label names.</span>

<span class="sd">        Args:</span>
<span class="sd">            label2id (`dict`):</span>
<span class="sd">                The label name to ID mapping to align the dataset with.</span>
<span class="sd">            label_column (`str`):</span>
<span class="sd">                The column name of labels to align on.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; # dataset with mapping {&#39;entailment&#39;: 0, &#39;neutral&#39;: 1, &#39;contradiction&#39;: 2}</span>
<span class="sd">        &gt;&gt;&gt; ds = load_dataset(&quot;nyu-mll/glue&quot;, &quot;mnli&quot;, split=&quot;train&quot;)</span>
<span class="sd">        &gt;&gt;&gt; # mapping to align with</span>
<span class="sd">        &gt;&gt;&gt; label2id = {&#39;CONTRADICTION&#39;: 0, &#39;NEUTRAL&#39;: 1, &#39;ENTAILMENT&#39;: 2}</span>
<span class="sd">        &gt;&gt;&gt; ds_aligned = ds.align_labels_with_mapping(label2id, &quot;label&quot;)</span>
<span class="sd">        ```</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sanity checks</span>
        <span class="k">if</span> <span class="n">label_column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column (</span><span class="si">{</span><span class="n">label_column</span><span class="si">}</span><span class="s2">) not in table columns (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="n">label_feature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="o">.</span><span class="n">feature</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Aligning labels with a mapping is only supported for </span><span class="si">{</span><span class="n">ClassLabel</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> column or </span><span class="si">{</span><span class="n">Sequence</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> column with the inner type </span><span class="si">{</span><span class="n">ClassLabel</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, and column </span><span class="si">{</span><span class="n">label_feature</span><span class="si">}</span><span class="s2"> is of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">label_feature</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Sort input mapping by ID value to ensure the label names are aligned</span>
        <span class="n">label2id</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">label2id</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">label_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label2id</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="c1"># Some label mappings use uppercase label names so we lowercase them during alignment</span>
        <span class="n">label2id</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">label2id</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">int2str_function</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">label_feature</span><span class="o">.</span><span class="n">int2str</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">)</span> <span class="k">else</span> <span class="n">label_feature</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">int2str</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">):</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">process_label_ids</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="n">dset_label_names</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">int2str_function</span><span class="p">(</span><span class="n">label_id</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="n">label_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="k">for</span> <span class="n">label_id</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">label2id</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span> <span class="k">if</span> <span class="n">label_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">label_name</span> <span class="ow">in</span> <span class="n">dset_label_names</span>
                <span class="p">]</span>
                <span class="k">return</span> <span class="n">batch</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">process_label_ids</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="n">dset_label_names</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">[</span><span class="n">int2str_function</span><span class="p">(</span><span class="n">label_id</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="n">label_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">label_id</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">[</span><span class="n">label2id</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span> <span class="k">if</span> <span class="n">label_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">label_name</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">dset_label_names</span>
                <span class="p">]</span>
                <span class="k">return</span> <span class="n">batch</span>

        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>
        <span class="n">features</span><span class="p">[</span><span class="n">label_column</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ClassLabel</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">),</span> <span class="n">names</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_feature</span><span class="p">,</span> <span class="n">ClassLabel</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">List</span><span class="p">(</span><span class="n">ClassLabel</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">),</span> <span class="n">names</span><span class="o">=</span><span class="n">label_names</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">process_label_ids</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Aligning the labels&quot;</span><span class="p">)</span></div>
</div>



<span class="k">def</span><span class="w"> </span><span class="nf">_concatenate_map_style_datasets</span><span class="p">(</span>
    <span class="n">dsets</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span>
    <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a list of :class:`Dataset` with the same schema into a single :class:`Dataset`.</span>
<span class="sd">    When you concatenate on axis 0, missing data are filled with None values.</span>

<span class="sd">    Args:</span>
<span class="sd">        dsets (`List[datasets.Dataset]`): List of Datasets to concatenate.</span>
<span class="sd">        info (:class:`DatasetInfo`, optional): Dataset information, like description, citation, etc.</span>
<span class="sd">        split (:class:`NamedSplit`, optional): Name of the dataset split.</span>
<span class="sd">        axis (``{0, 1}``, default ``0``, meaning over rows):</span>
<span class="sd">            Axis to concatenate over, where ``0`` means over rows (vertically) and ``1`` means over columns</span>
<span class="sd">            (horizontally).</span>

<span class="sd">            *New in version 1.6.0*</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; ds3 = _concatenate_map_style_datasets([ds1, ds2])</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ignore datasets with no rows</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">):</span>
        <span class="n">dsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">dset</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span> <span class="k">if</span> <span class="n">dset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Return first dataset if all datasets are empty</span>
        <span class="k">return</span> <span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Perform checks (and a potential cast if axis=0)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">_check_if_features_can_be_aligned</span><span class="p">([</span><span class="n">dset</span><span class="o">.</span><span class="n">features</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">==</span> <span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_rows</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of rows must match for all datasets&quot;</span><span class="p">)</span>
        <span class="n">_check_column_names</span><span class="p">([</span><span class="n">col_name</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span> <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">dset</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">column_names</span><span class="p">])</span>

    <span class="c1"># Find common format or reset format</span>
    <span class="nb">format</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">format</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">format</span> <span class="o">!=</span> <span class="nb">format</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">):</span>
        <span class="nb">format</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Some of the datasets have disparate format. Resetting the format of the concatenated dataset.&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply_offset_to_indices_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">table</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">]</span>
            <span class="n">new_array</span> <span class="o">=</span> <span class="n">pc</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">uint64</span><span class="p">()))</span>
            <span class="k">return</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">([</span><span class="n">new_array</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">])</span>

    <span class="c1"># Concatenate indices if they exist</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Datasets with no indices tables are replaced with a dataset with an indices table in memory.</span>
            <span class="c1"># Applying an offset to an indices table also brings the table in memory.</span>
            <span class="n">indices_tables</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_select_with_indices_mapping</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                <span class="n">indices_tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_indices</span><span class="p">)</span>

            <span class="c1"># An offset needs to be applied to the indices before concatenating</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">)):</span>
                <span class="n">indices_tables</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">apply_offset_to_indices_table</span><span class="p">(</span><span class="n">indices_tables</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">offset</span><span class="p">)</span>
                <span class="n">offset</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_data</span><span class="p">)</span>

            <span class="c1"># Concatenate indices</span>
            <span class="n">indices_tables</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">indices_tables</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">indices_tables</span><span class="p">:</span>
                <span class="n">indices_table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">(</span><span class="n">indices_tables</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">indices_table</span> <span class="o">=</span> <span class="n">InMemoryTable</span><span class="o">.</span><span class="n">from_batches</span><span class="p">([],</span> <span class="n">schema</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">({</span><span class="s2">&quot;indices&quot;</span><span class="p">:</span> <span class="n">pa</span><span class="o">.</span><span class="n">int64</span><span class="p">()}))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">indices_table</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_indices</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">)):</span>
                    <span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">flatten_indices</span><span class="p">()</span>
                <span class="n">indices_table</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">indices_table</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">table</span> <span class="o">=</span> <span class="n">concat_tables</span><span class="p">([</span><span class="n">dset</span><span class="o">.</span><span class="n">_data</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">features_list</span> <span class="o">=</span> <span class="n">_align_features</span><span class="p">([</span><span class="n">dset</span><span class="o">.</span><span class="n">features</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">features_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">dset</span><span class="o">.</span><span class="n">features</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">]</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">update_metadata_with_features</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">features_list</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">features</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

    <span class="c1"># Concatenate infos</span>
    <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">info</span> <span class="o">=</span> <span class="n">DatasetInfo</span><span class="o">.</span><span class="n">from_merge</span><span class="p">([</span><span class="n">dset</span><span class="o">.</span><span class="n">info</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">])</span>
    <span class="n">fingerprint</span> <span class="o">=</span> <span class="n">update_fingerprint</span><span class="p">(</span>
        <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dset</span><span class="o">.</span><span class="n">_fingerprint</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">dsets</span><span class="p">),</span> <span class="n">_concatenate_map_style_datasets</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;info&quot;</span><span class="p">:</span> <span class="n">info</span><span class="p">,</span> <span class="s2">&quot;split&quot;</span><span class="p">:</span> <span class="n">split</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Make final concatenated dataset</span>
    <span class="n">concatenated_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
        <span class="n">table</span><span class="p">,</span>
        <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span>
        <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="n">indices_table</span><span class="o">=</span><span class="n">indices_table</span><span class="p">,</span>
        <span class="n">fingerprint</span><span class="o">=</span><span class="n">fingerprint</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">concatenated_dataset</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="o">**</span><span class="nb">format</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">concatenated_dataset</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_interleave_map_style_datasets</span><span class="p">(</span>
    <span class="n">datasets</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">],</span>
    <span class="n">probabilities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DatasetInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedSplit</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stopping_strategy</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span>
        <span class="s2">&quot;first_exhausted&quot;</span><span class="p">,</span> <span class="s2">&quot;all_exhausted&quot;</span><span class="p">,</span> <span class="s2">&quot;all_exhausted_without_replacement&quot;</span>
    <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;first_exhausted&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Interleave several map-style datasets (sources) into a single map-style dataset.</span>
<span class="sd">    The new dataset is constructed by alternating between the sources to get the examples.</span>
<span class="sd">    If `probabilities = None` (default) the new dataset is constructed by cycling between each source to get the examples.</span>
<span class="sd">    If `probabilities` is not `None, the new dataset is constructed by getting examples from a random source at a time according to the provided probabilities.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasets (`List[Dataset]`): list of datasets to interleave</span>
<span class="sd">        probabilities (`List[float]`, optional, default None): If specified, the new dataset is constructed by sampling</span>
<span class="sd">            examples from one source at a time according to these probabilities.</span>
<span class="sd">        seed (`int`, optional, default None): The random seed used to choose a source for each example.</span>
<span class="sd">        info (:class:`DatasetInfo`, optional): Dataset information, like description, citation, etc.</span>
<span class="sd">        split (:class:`NamedSplit`, optional): Name of the dataset split.</span>
<span class="sd">        stopping_strategy (`str`, defaults to `first_exhausted`):</span>
<span class="sd">            Two strategies are proposed right now.</span>
<span class="sd">            By default, `first_exhausted` is an undersampling strategy, i.e the dataset construction is stopped as soon as one dataset has ran out of samples.</span>
<span class="sd">            If the strategy is `all_exhausted`,  we use an oversampling strategy, i.e the dataset construction is stopped as soon as every samples of every dataset has been added at least once.</span>
<span class="sd">            When strategy is `all_exhausted_without_replacement` we make sure that each sample in each dataset is sampled only once.</span>
<span class="sd">            Note that if the strategy is `all_exhausted`, the interleaved dataset size can get enormous:</span>
<span class="sd">            - with no probabilities, the resulting dataset will have max_length_datasets*nb_dataset samples.</span>
<span class="sd">            - with given probabilities, the resulting dataset will have more samples if some datasets have really low probability of visiting.</span>
<span class="sd">        **kwargs (additional keyword arguments): Keyword arguments to be passed to :meth:`datasets.Datasets.select` when selecting the indices used to interleave the datasets.</span>

<span class="sd">    Output:</span>
<span class="sd">        :class:`datasets.Dataset`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">stopping_strategy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;first_exhausted&quot;</span><span class="p">,</span> <span class="s2">&quot;all_exhausted&quot;</span><span class="p">,</span> <span class="s2">&quot;all_exhausted_without_replacement&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">stopping_strategy</span><span class="si">}</span><span class="s2"> stopping strategy in `interleave_datasets` is not implemented yet with a list of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># To interleave the datasets, we concatenate them and then we re-order the indices</span>
    <span class="n">concatenated_datasets</span> <span class="o">=</span> <span class="n">_concatenate_map_style_datasets</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>

    <span class="c1"># Let&#39;s now build the indices to pass to .select()</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dset</span><span class="p">)</span> <span class="k">for</span> <span class="n">dset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">lengths</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># if stopping_strategy is &quot;first_exhausted&quot;, it is an undersampling situation whereas it is an oversampling situation if it is &quot;all_exhausted&quot;</span>
    <span class="n">oversampling</span> <span class="o">=</span> <span class="n">stopping_strategy</span> <span class="o">==</span> <span class="s2">&quot;all_exhausted&quot;</span>

    <span class="k">if</span> <span class="n">probabilities</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">oversampling</span><span class="p">:</span>
        <span class="c1"># Undersampling situation with cycling between each sources</span>
        <span class="c1"># Example:: If lengths of the datasets are [3, 4, 5]</span>
        <span class="c1"># Then the resulting indices should be [0, 3, 7, 1, 4, 8, 2, 6, 9]</span>
        <span class="c1"># Note that we only have 3 examples per dataset since the first dataset ran out of examples</span>

        <span class="c1"># Reasoning behind the following operation: keeping the min_length first indices of each dataset</span>
        <span class="c1"># while offsetting in order to correspond to the right indices of the concatenated dataset</span>
        <span class="c1"># and flattening to effectively interleave the datasets</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">offsets</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">probabilities</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Oversampling situation with cycling between each sources</span>
        <span class="c1"># Then the resulting indices should be [0, 3, 7, 1, 4, 8, 2, 5, 9, 0, 6, 10, 1, 3, 11]</span>
        <span class="c1"># Note that we have 5 examples per dataset with a rolling window since the longest dataset has 5 samples</span>

        <span class="c1"># Reasoning behind the following operation: for each dataset indices (i.e column) repeat the indices to have max_length indices per dataset</span>
        <span class="c1"># For example, if the max_length is 5 and the i-th dataset has 3 samples, the i-th column will be [0,1,2,0,1]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># We have to keep the indices to their respective dataset offsets and to flatten to effectively interleave the datasets</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">indices</span> <span class="o">+</span> <span class="n">offsets</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># boolean array indicating if at index i if the dataset_i has been fully exhausted</span>
        <span class="n">is_exhausted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">),</span> <span class="kc">False</span><span class="p">)</span>

        <span class="c1"># if undersampling (&quot;first_exhausted&quot;), we stop as soon as one dataset is exhausted</span>
        <span class="c1"># if oversampling (&quot;all_exhausted&quot;), we stop as soons as every dataset is exhausted, i.e as soon as every samples of every dataset has been visited at least once</span>
        <span class="n">bool_strategy_func</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">all</span> <span class="k">if</span> <span class="p">(</span><span class="n">oversampling</span> <span class="ow">or</span> <span class="n">stopping_strategy</span> <span class="o">==</span> <span class="s2">&quot;all_exhausted_without_replacement&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span>
        <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">iter_random_indices</span><span class="p">():</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Get an infinite iterator that randomly samples the index of the source to pick examples from.&quot;&quot;&quot;</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">yield from</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probabilities</span><span class="p">))</span>

        <span class="n">current_index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source_idx</span> <span class="ow">in</span> <span class="n">iter_random_indices</span><span class="p">():</span>
            <span class="c1"># If no oversampling, we stop as soon as a dataset has ran out of examples (np.any)</span>
            <span class="c1"># Otherwise, we stop as soon as every dataset has ran out of examples (np.all)</span>
            <span class="k">if</span> <span class="n">bool_strategy_func</span><span class="p">(</span><span class="n">is_exhausted</span><span class="p">):</span>
                <span class="c1"># the stopping condition was reached, let&#39;s stop</span>
                <span class="k">break</span>

            <span class="c1"># let&#39;s add the example at the current index of the `source_idx`-th dataset</span>
            <span class="c1"># For without replacement sampling we additionally need to make sure the current source is not exhausted to not oversample.</span>
            <span class="k">if</span> <span class="n">stopping_strategy</span> <span class="o">!=</span> <span class="s2">&quot;all_exhausted_without_replacement&quot;</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">is_exhausted</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]:</span>
                <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_index</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">offsets</span><span class="p">[</span><span class="n">source_idx</span><span class="p">])</span>
                <span class="n">current_index</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># we&#39;ve ran out of examples for the current dataset, let&#39;s update our boolean array and bring the current_index back to 0</span>
            <span class="k">if</span> <span class="n">current_index</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]:</span>
                <span class="n">is_exhausted</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="c1"># We don&#39;t want to reset the iterator when stopping strategy is without replacement.</span>
                <span class="k">if</span> <span class="n">stopping_strategy</span> <span class="o">!=</span> <span class="s2">&quot;all_exhausted_without_replacement&quot;</span><span class="p">:</span>
                    <span class="n">current_index</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">concatenated_datasets</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_split_by_node_map_style_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split a dataset for the node at rank `rank` in a pool of nodes of size `world_size`.</span>
<span class="sd">    Each node is assigned a chunk of data, e.g. rank 0 is given the first chunk of the dataset.</span>
<span class="sd">    To maximize data loading throughput, chunks are made of contiguous data on disk if possible.</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset ([`Dataset`]):</span>
<span class="sd">            The dataset to split by node.</span>
<span class="sd">        rank (`int`):</span>
<span class="sd">            Rank of the current node.</span>
<span class="sd">        world_size (`int`):</span>
<span class="sd">            Total number of nodes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`Dataset`]: The dataset to be used on the node at rank `rank`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">contiguous</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># This is outside Dataset.filter as it needs to be picklable for multiprocessing</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_indices_from_mask_function</span><span class="p">(</span>
    <span class="n">function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">with_indices</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">with_rank</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">input_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span>
    <span class="n">indices_mapping</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Table</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">if</span> <span class="n">batched</span><span class="p">:</span>
        <span class="c1"># we extract indices and rank from args</span>
        <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="n">args</span>
        <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
        <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
            <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
            <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">ChunkedArray</span><span class="p">)):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># we get batched data (to return less data than input) but `function` only accepts one example</span>
        <span class="c1"># therefore we need to call `function` on each example of the batch to get the mask</span>
        <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="n">args</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">input_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># inputs only contains a batch of examples</span>
            <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
                <span class="n">example</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">}</span>
                <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
                <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],)</span>
                <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
                <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># inputs is a list of columns</span>
            <span class="n">columns</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span>
            <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">]</span>
                <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
                <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],)</span>
                <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
                <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">))</span>
    <span class="n">indices_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">to_keep</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="n">to_keep</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">indices_mapping</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices_array</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">uint64</span><span class="p">())</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">indices_mapping</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices_array</span><span class="p">)</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">indices_array</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;indices&quot;</span><span class="p">:</span> <span class="n">indices_array</span><span class="p">}</span>


<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">async_get_indices_from_mask_function</span><span class="p">(</span>
    <span class="n">function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">batched</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">with_indices</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">with_rank</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">input_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span>
    <span class="n">indices_mapping</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Table</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;same function but async&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">batched</span><span class="p">:</span>
        <span class="c1"># we extract indices and rank from args</span>
        <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="n">args</span>
        <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
        <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
            <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
            <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="k">await</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">Array</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">ChunkedArray</span><span class="p">)):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># we get batched data (to return less data than input) but `function` only accepts one example</span>
        <span class="c1"># therefore we need to call `function` on each example of the batch to get the mask</span>
        <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="n">args</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">input_columns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># inputs only contains a batch of examples</span>
            <span class="n">batch</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
                <span class="n">example</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">}</span>
                <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
                <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],)</span>
                <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
                <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">await</span> <span class="n">function</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># inputs is a list of columns</span>
            <span class="n">columns</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span>
            <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">]</span>
                <span class="n">additional_args</span> <span class="o">=</span> <span class="p">()</span>
                <span class="k">if</span> <span class="n">with_indices</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],)</span>
                <span class="k">if</span> <span class="n">with_rank</span><span class="p">:</span>
                    <span class="n">additional_args</span> <span class="o">+=</span> <span class="p">(</span><span class="n">rank</span><span class="p">,)</span>
                <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="k">await</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">*</span><span class="n">additional_args</span><span class="p">,</span> <span class="o">**</span><span class="n">fn_kwargs</span><span class="p">))</span>
    <span class="n">indices_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">to_keep</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="k">if</span> <span class="n">to_keep</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">indices_mapping</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices_array</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">uint64</span><span class="p">())</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">indices_mapping</span><span class="o">.</span><span class="n">column</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices_array</span><span class="p">)</span>
        <span class="n">indices_array</span> <span class="o">=</span> <span class="n">indices_array</span><span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;indices&quot;</span><span class="p">:</span> <span class="n">indices_array</span><span class="p">}</span>
</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      Â© Copyright 2025, HuggingFace Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>